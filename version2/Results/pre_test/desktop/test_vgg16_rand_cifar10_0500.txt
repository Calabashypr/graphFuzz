
analyse the exceptions in iter:8
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[4.6952, 4.6950, 4.6955,  ..., 4.6950, 4.6946, 4.6947],
          [4.6947, 4.6946, 4.6941,  ..., 4.6950, 4.6945, 4.6945],
          [4.6945, 4.6945, 4.6946,  ..., 4.6946, 4.6945, 4.6945],
          ...,
          [4.6952, 4.6907, 4.6794,  ..., 4.6485, 4.6631, 4.6643],
          [4.6976, 4.6960, 4.6951,  ..., 4.6458, 4.6574, 4.6602],
          [4.6986, 4.6975, 4.6990,  ..., 4.6806, 4.6624, 4.6636]],

         [[4.6952, 4.6950, 4.6955,  ..., 4.6950, 4.6946, 4.6947],
          [4.6947, 4.6946, 4.6941,  ..., 4.6950, 4.6945, 4.6945],
          [4.6945, 4.6945, 4.6946,  ..., 4.6946, 4.6945, 4.6945],
          ...,
          [4.6952, 4.6907, 4.6794,  ..., 4.6485, 4.6631, 4.6643],
          [4.6976, 4.6960, 4.6951,  ..., 4.6458, 4.6574, 4.6602],
          [4.6986, 4.6975, 4.6990,  ..., 4.6806, 4.6624, 4.6636]],

         [[4.6952, 4.6950, 4.6955,  ..., 4.6950, 4.6946, 4.6947],
          [4.6947, 4.6946, 4.6941,  ..., 4.6950, 4.6945, 4.6945],
          [4.6945, 4.6945, 4.6946,  ..., 4.6946, 4.6945, 4.6945],
          ...,
          [4.6952, 4.6907, 4.6794,  ..., 4.6485, 4.6631, 4.6643],
          [4.6976, 4.6960, 4.6951,  ..., 4.6458, 4.6574, 4.6602],
          [4.6986, 4.6975, 4.6990,  ..., 4.6806, 4.6624, 4.6636]],

         ...,

         [[4.6952, 4.6950, 4.6955,  ..., 4.6950, 4.6946, 4.6947],
          [4.6947, 4.6946, 4.6941,  ..., 4.6950, 4.6945, 4.6945],
          [4.6945, 4.6945, 4.6946,  ..., 4.6946, 4.6945, 4.6945],
          ...,
          [4.6952, 4.6907, 4.6794,  ..., 4.6485, 4.6631, 4.6643],
          [4.6976, 4.6960, 4.6951,  ..., 4.6458, 4.6574, 4.6602],
          [4.6986, 4.6975, 4.6990,  ..., 4.6806, 4.6624, 4.6636]],

         [[4.6952, 4.6950, 4.6955,  ..., 4.6950, 4.6946, 4.6947],
          [4.6947, 4.6946, 4.6941,  ..., 4.6950, 4.6945, 4.6945],
          [4.6945, 4.6945, 4.6946,  ..., 4.6946, 4.6945, 4.6945],
          ...,
          [4.6952, 4.6907, 4.6794,  ..., 4.6485, 4.6631, 4.6643],
          [4.6976, 4.6960, 4.6951,  ..., 4.6458, 4.6574, 4.6602],
          [4.6986, 4.6975, 4.6990,  ..., 4.6806, 4.6624, 4.6636]],

         [[4.6952, 4.6950, 4.6955,  ..., 4.6950, 4.6946, 4.6947],
          [4.6947, 4.6946, 4.6941,  ..., 4.6950, 4.6945, 4.6945],
          [4.6945, 4.6945, 4.6946,  ..., 4.6946, 4.6945, 4.6945],
          ...,
          [4.6952, 4.6907, 4.6794,  ..., 4.6485, 4.6631, 4.6643],
          [4.6976, 4.6960, 4.6951,  ..., 4.6458, 4.6574, 4.6602],
          [4.6986, 4.6975, 4.6990,  ..., 4.6806, 4.6624, 4.6636]]]],
       grad_fn=<ConvolutionBackward0>)]}
Given groups=1, weight of size [128, 256, 3, 3], expected input[1, 512, 16, 16] to have 256 channels, but got 512 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 512, 16, 16], dtype=Float32, value=
[[[[4.69524956e+000, 4.69503021e+000, 4.69547367e+000 ... 4.69500065e+000, 4.69464779e+000, 4.69469738e+000],
   [4.69474649e+000, 4.69459820e+000, 4.69411612e+000 ... 4.69496346e+000, 4.69453621e+000, 4.69453621e+000],
   [4.69445515e+000, 4.69451618e+000, 4.69456673e+000 ... 4.69464779e+000, 4.69453621e+000, 4.69453621e+000],
   ...
   [4.69517279e+000, 4.69070101e+000, 4.67938328e+000 ... 4.64848709e+000, 4.66310024e+000, 4.66425562e+000],
   [4.69757891e+000, 4.69601679e+000, 4.69513607e+000 ... 4.64584589e+000, 4.65737820e+000, 4.66020441e+000],
   [4.69861126e+000, 4.69746256e+000, 4.69900703e+000 ... 4.68061209e+000, 4.66236973e+000, 4.66358995e+000]],
  [[4.69524956e+000, 4.69503021e+000, 4.69547367e+000 ... 4.69500065e+000, 4.69464779e+000, 4.69469738e+000],
   [4.69474649e+000, 4.69459820e+000, 4.69411612e+000 ... 4.69496346e+000, 4.69453621e+000, 4.69453621e+000],
   [4.69445515e+000, 4.69451618e+000, 4.69456673e+000 ... 4.69464779e+000, 4.69453621e+000, 4.69453621e+000],
   ...
   [4.69517279e+000, 4.69070101e+000, 4.67938328e+000 ... 4.64848709e+000, 4.66310024e+000, 4.66425562e+000],
   [4.69757891e+000, 4.69601679e+000, 4.69513607e+000 ... 4.64584589e+000, 4.65737820e+000, 4.66020441e+000],
   [4.69861126e+000, 4.69746256e+000, 4.69900703e+000 ... 4.68061209e+000, 4.66236973e+000, 4.66358995e+000]],
  [[4.69524956e+000, 4.69503021e+000, 4.69547367e+000 ... 4.69500065e+000, 4.69464779e+000, 4.69469738e+000],
   [4.69474649e+000, 4.69459820e+000, 4.69411612e+000 ... 4.69496346e+000, 4.69453621e+000, 4.69453621e+000],
   [4.69445515e+000, 4.69451618e+000, 4.69456673e+000 ... 4.69464779e+000, 4.69453621e+000, 4.69453621e+000],
   ...
   [4.69517279e+000, 4.69070101e+000, 4.67938328e+000 ... 4.64848709e+000, 4.66310024e+000, 4.66425562e+000],
   [4.69757891e+000, 4.69601679e+000, 4.69513607e+000 ... 4.64584589e+000, 4.65737820e+000, 4.66020441e+000],
   [4.69861126e+000, 4.69746256e+000, 4.69900703e+000 ... 4.68061209e+000, 4.66236973e+000, 4.66358995e+000]],
  ...
  [[4.69524956e+000, 4.69503021e+000, 4.69547367e+000 ... 4.69500065e+000, 4.69464779e+000, 4.69469738e+000],
   [4.69474649e+000, 4.69459820e+000, 4.69411612e+000 ... 4.69496346e+000, 4.69453621e+000, 4.69453621e+000],
   [4.69445515e+000, 4.69451618e+000, 4.69456673e+000 ... 4.69464779e+000, 4.69453621e+000, 4.69453621e+000],
   ...
   [4.69517279e+000, 4.69070101e+000, 4.67938328e+000 ... 4.64848709e+000, 4.66310024e+000, 4.66425562e+000],
   [4.69757891e+000, 4.69601679e+000, 4.69513607e+000 ... 4.64584589e+000, 4.65737820e+000, 4.66020441e+000],
   [4.69861126e+000, 4.69746256e+000, 4.69900703e+000 ... 4.68061209e+000, 4.66236973e+000, 4.66358995e+000]],
  [[4.69524956e+000, 4.69503021e+000, 4.69547367e+000 ... 4.69500065e+000, 4.69464779e+000, 4.69469738e+000],
   [4.69474649e+000, 4.69459820e+000, 4.69411612e+000 ... 4.69496346e+000, 4.69453621e+000, 4.69453621e+000],
   [4.69445515e+000, 4.69451618e+000, 4.69456673e+000 ... 4.69464779e+000, 4.69453621e+000, 4.69453621e+000],
   ...
   [4.69517279e+000, 4.69070101e+000, 4.67938328e+000 ... 4.64848709e+000, 4.66310024e+000, 4.66425562e+000],
   [4.69757891e+000, 4.69601679e+000, 4.69513607e+000 ... 4.64584589e+000, 4.65737820e+000, 4.66020441e+000],
   [4.69861126e+000, 4.69746256e+000, 4.69900703e+000 ... 4.68061209e+000, 4.66236973e+000, 4.66358995e+000]],
  [[4.69524956e+000, 4.69503021e+000, 4.69547367e+000 ... 4.69500065e+000, 4.69464779e+000, 4.69469738e+000],
   [4.69474649e+000, 4.69459820e+000, 4.69411612e+000 ... 4.69496346e+000, 4.69453621e+000, 4.69453621e+000],
   [4.69445515e+000, 4.69451618e+000, 4.69456673e+000 ... 4.69464779e+000, 4.69453621e+000, 4.69453621e+000],
   ...
   [4.69517279e+000, 4.69070101e+000, 4.67938328e+000 ... 4.64848709e+000, 4.66310024e+000, 4.66425562e+000],
   [4.69757891e+000, 4.69601679e+000, 4.69513607e+000 ... 4.64584589e+000, 4.65737820e+000, 4.66020441e+000],
   [4.69861126e+000, 4.69746256e+000, 4.69900703e+000 ... 4.68061209e+000, 4.66236973e+000, 4.66358995e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 512, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:7

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:1,distinct_bugs:1
torch --> nums:1,distinct_bugs:1
tensorflow --> 
mindspore --> 
conv2d:1
torch --> 
conv2d:1

generate models:8

analyse output arrays in iter:18

pre layer res:
3:conv2d
{'name': 'conv2d', 'output': array([[[[2647433., 4004361., 4079616., ..., 4357237., 4317568.,
          2867456.],
         [3765513., 5601289., 5563392., ..., 6556149., 6516224.,
          4333696.],
         [3797760., 5631232., 5495680., ..., 6632076., 6635764.,
          4421236.],
         ...,
         [3649032., 5508616., 5567352., ..., 2425216., 2041344.,
          1239808.],
         [3392128., 5152128., 5302150., ..., 2795776., 2488320.,
          1558272.],
         [2127872., 3261696., 3410566., ..., 1925248., 1817472.,
          1182464.]],

        [[2647433., 4004361., 4079616., ..., 4357237., 4317568.,
          2867456.],
         [3765513., 5601289., 5563392., ..., 6556149., 6516224.,
          4333696.],
         [3797760., 5631232., 5495680., ..., 6632076., 6635764.,
          4421236.],
         ...,
         [3649032., 5508616., 5567352., ..., 2425216., 2041344.,
          1239808.],
         [3392128., 5152128., 5302150., ..., 2795776., 2488320.,
          1558272.],
         [2127872., 3261696., 3410566., ..., 1925248., 1817472.,
          1182464.]],

        [[2647433., 4004361., 4079616., ..., 4357237., 4317568.,
          2867456.],
         [3765513., 5601289., 5563392., ..., 6556149., 6516224.,
          4333696.],
         [3797760., 5631232., 5495680., ..., 6632076., 6635764.,
          4421236.],
         ...,
         [3649032., 5508616., 5567352., ..., 2425216., 2041344.,
          1239808.],
         [3392128., 5152128., 5302150., ..., 2795776., 2488320.,
          1558272.],
         [2127872., 3261696., 3410566., ..., 1925248., 1817472.,
          1182464.]],

        ...,

        [[2647433., 4004361., 4079616., ..., 4357237., 4317568.,
          2867456.],
         [3765513., 5601289., 5563392., ..., 6556149., 6516224.,
          4333696.],
         [3797760., 5631232., 5495680., ..., 6632076., 6635764.,
          4421236.],
         ...,
         [3649032., 5508616., 5567352., ..., 2425216., 2041344.,
          1239808.],
         [3392128., 5152128., 5302150., ..., 2795776., 2488320.,
          1558272.],
         [2127872., 3261696., 3410566., ..., 1925248., 1817472.,
          1182464.]],

        [[2647433., 4004361., 4079616., ..., 4357237., 4317568.,
          2867456.],
         [3765513., 5601289., 5563392., ..., 6556149., 6516224.,
          4333696.],
         [3797760., 5631232., 5495680., ..., 6632076., 6635764.,
          4421236.],
         ...,
         [3649032., 5508616., 5567352., ..., 2425216., 2041344.,
          1239808.],
         [3392128., 5152128., 5302150., ..., 2795776., 2488320.,
          1558272.],
         [2127872., 3261696., 3410566., ..., 1925248., 1817472.,
          1182464.]],

        [[2647433., 4004361., 4079616., ..., 4357237., 4317568.,
          2867456.],
         [3765513., 5601289., 5563392., ..., 6556149., 6516224.,
          4333696.],
         [3797760., 5631232., 5495680., ..., 6632076., 6635764.,
          4421236.],
         ...,
         [3649032., 5508616., 5567352., ..., 2425216., 2041344.,
          1239808.],
         [3392128., 5152128., 5302150., ..., 2795776., 2488320.,
          1558272.],
         [2127872., 3261696., 3410566., ..., 1925248., 1817472.,
          1182464.]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 16]), 'from': [2], 'to': [9, 21]}
tf node:
{'name': 'cos', 'output': array([[[[ 0.9540122 ,  0.5728154 ,  0.9464576 , ...,  0.3491976 ,
          -0.24464305,  0.2880202 ],
         [ 0.99896926,  0.4929256 , -0.5206647 , ..., -0.9913101 ,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ..., -0.43507388,
          -0.6287119 , -0.92029124],
         ...,
         [-0.99234957, -0.9772616 , -0.8418527 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.6439744 , -0.73545045, ..., -0.9043512 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9242186 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[ 0.9540122 ,  0.5728154 ,  0.9464576 , ...,  0.3491976 ,
          -0.24464305,  0.2880202 ],
         [ 0.99896926,  0.4929256 , -0.5206647 , ..., -0.9913101 ,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ..., -0.43507388,
          -0.6287119 , -0.92029124],
         ...,
         [-0.99234957, -0.9772616 , -0.8418527 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.6439744 , -0.73545045, ..., -0.9043512 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9242186 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[ 0.9540122 ,  0.5728154 ,  0.9464576 , ...,  0.3491976 ,
          -0.24464305,  0.2880202 ],
         [ 0.99896926,  0.4929256 , -0.5206647 , ..., -0.9913101 ,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ..., -0.43507388,
          -0.6287119 , -0.92029124],
         ...,
         [-0.99234957, -0.9772616 , -0.8418527 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.6439744 , -0.73545045, ..., -0.9043512 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9242186 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        ...,

        [[ 0.9540122 ,  0.5728154 ,  0.9464576 , ...,  0.3491976 ,
          -0.24464305,  0.2880202 ],
         [ 0.99896926,  0.4929256 , -0.5206647 , ..., -0.9913101 ,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ..., -0.43507388,
          -0.6287119 , -0.92029124],
         ...,
         [-0.99234957, -0.9772616 , -0.8418527 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.6439744 , -0.73545045, ..., -0.9043512 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9242186 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[ 0.9540122 ,  0.5728154 ,  0.9464576 , ...,  0.3491976 ,
          -0.24464305,  0.2880202 ],
         [ 0.99896926,  0.4929256 , -0.5206647 , ..., -0.9913101 ,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ..., -0.43507388,
          -0.6287119 , -0.92029124],
         ...,
         [-0.99234957, -0.9772616 , -0.8418527 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.6439744 , -0.73545045, ..., -0.9043512 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9242186 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[ 0.9540122 ,  0.5728154 ,  0.9464576 , ...,  0.3491976 ,
          -0.24464305,  0.2880202 ],
         [ 0.99896926,  0.4929256 , -0.5206647 , ..., -0.9913101 ,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ..., -0.43507388,
          -0.6287119 , -0.92029124],
         ...,
         [-0.99234957, -0.9772616 , -0.8418527 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.6439744 , -0.73545045, ..., -0.9043512 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9242186 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 16]), 'from': [3], 'to': [11]}
ms node:
{'name': 'cos', 'output': array([[[[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        ...,

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]]]], dtype=float32), 'output_shape': (1, 512, 16, 16), 'from': [3], 'to': [11]}
torch node:
{'name': 'cos', 'output': array([[[[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        ...,

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]],

        [[-0.7456895 , -0.85971653,  0.9464576 , ..., -0.9354945 ,
          -0.24464305,  0.2880202 ],
         [-0.8914844 , -0.80769193, -0.52066463, ..., -0.13593154,
          -0.06212607,  0.63617617],
         [-0.16683076, -0.8392311 , -0.64872503, ...,  0.11598863,
          -0.9478007 , -0.98651695],
         ...,
         [ 0.26653284,  0.3519723 ,  0.6564535 , ...,  0.75232756,
           0.99722993, -0.900269  ],
         [ 0.9269755 , -0.64397436, -0.8954836 , ..., -0.9043511 ,
          -0.8993899 , -0.35945272],
         [-0.57277644,  0.9665791 , -0.9941059 , ..., -0.0886161 ,
          -0.5738166 ,  0.9982668 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [3], 'to': [11]}

generate models:14

analyse the exceptions in iter:28
torch exception:
{'id': 0, 'name': 'linear', 'frame_work': 'torch', 'input_datas': tensor([[[[[128., 121., 138.,  ..., 130., 101., 122.],
           [133., 125., 136.,  ..., 131., 106., 127.],
           [141., 126., 141.,  ..., 132., 114., 126.],
           ...,
           [191., 186., 175.,  ..., 190., 182., 195.],
           [210., 207., 198.,  ..., 194., 184., 192.],
           [209., 206., 207.,  ..., 201., 193., 196.]],

          [[141., 134., 151.,  ..., 150., 121., 141.],
           [146., 138., 149.,  ..., 151., 126., 147.],
           [155., 139., 154.,  ..., 152., 134., 146.],
           ...,
           [178., 174., 160.,  ..., 179., 175., 188.],
           [195., 197., 179.,  ..., 179., 178., 186.],
           [194., 195., 189.,  ..., 187., 187., 190.]],

          [[123., 116., 133.,  ..., 138., 109., 129.],
           [128., 120., 131.,  ..., 139., 114., 135.],
           [136., 121., 136.,  ..., 140., 122., 134.],
           ...,
           [126., 124., 112.,  ..., 138., 137., 145.],
           [143., 144., 129.,  ..., 138., 133., 142.],
           [142., 143., 138.,  ..., 145., 142., 146.]]]]])}
mat1 and mat2 shapes cannot be multiplied (96x32 and 25x100)
mindspore exception:
{'id': 0, 'name': 'linear', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.28000000e+002, 1.21000000e+002, 1.38000000e+002 ... 1.30000000e+002, 1.01000000e+002, 1.22000000e+002],
    [1.33000000e+002, 1.25000000e+002, 1.36000000e+002 ... 1.31000000e+002, 1.06000000e+002, 1.27000000e+002],
    [1.41000000e+002, 1.26000000e+002, 1.41000000e+002 ... 1.32000000e+002, 1.14000000e+002, 1.26000000e+002],
    ...
    [1.91000000e+002, 1.86000000e+002, 1.75000000e+002 ... 1.90000000e+002, 1.82000000e+002, 1.95000000e+002],
    [2.10000000e+002, 2.07000000e+002, 1.98000000e+002 ... 1.94000000e+002, 1.84000000e+002, 1.92000000e+002],
    [2.09000000e+002, 2.06000000e+002, 2.07000000e+002 ... 2.01000000e+002, 1.93000000e+002, 1.96000000e+002]],
   [[1.41000000e+002, 1.34000000e+002, 1.51000000e+002 ... 1.50000000e+002, 1.21000000e+002, 1.41000000e+002],
    [1.46000000e+002, 1.38000000e+002, 1.49000000e+002 ... 1.51000000e+002, 1.26000000e+002, 1.47000000e+002],
    [1.55000000e+002, 1.39000000e+002, 1.54000000e+002 ... 1.52000000e+002, 1.34000000e+002, 1.46000000e+002],
    ...
    [1.78000000e+002, 1.74000000e+002, 1.60000000e+002 ... 1.79000000e+002, 1.75000000e+002, 1.88000000e+002],
    [1.95000000e+002, 1.97000000e+002, 1.79000000e+002 ... 1.79000000e+002, 1.78000000e+002, 1.86000000e+002],
    [1.94000000e+002, 1.95000000e+002, 1.89000000e+002 ... 1.87000000e+002, 1.87000000e+002, 1.90000000e+002]],
   [[1.23000000e+002, 1.16000000e+002, 1.33000000e+002 ... 1.38000000e+002, 1.09000000e+002, 1.29000000e+002],
    [1.28000000e+002, 1.20000000e+002, 1.31000000e+002 ... 1.39000000e+002, 1.14000000e+002, 1.35000000e+002],
    [1.36000000e+002, 1.21000000e+002, 1.36000000e+002 ... 1.40000000e+002, 1.22000000e+002, 1.34000000e+002],
    ...
    [1.26000000e+002, 1.24000000e+002, 1.12000000e+002 ... 1.38000000e+002, 1.37000000e+002, 1.45000000e+002],
    [1.43000000e+002, 1.44000000e+002, 1.29000000e+002 ... 1.38000000e+002, 1.33000000e+002, 1.42000000e+002],
    [1.42000000e+002, 1.43000000e+002, 1.38000000e+002 ... 1.45000000e+002, 1.42000000e+002, 1.46000000e+002]]]]])}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 25. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 25](transpose_b=True).

generate models:23

analyse output arrays in iter:31

pre layer res:
8:exp
{'name': 'exp', 'output': array([[[[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf, 1.8586717e+31]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [7], 'to': [3]}
tf node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, 72.]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [8], 'to': [5]}
ms node:
{'name': 'log', 'output': array([[[[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          72.     ]]]], dtype=float32), 'output_shape': (1, 3, 32, 32), 'from': [8], 'to': [5]}
torch node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, 72.]]]], dtype=float32), 'output_shape': torch.Size([1, 3, 32, 32]), 'from': [8], 'to': [5]}

generate models:25

analyse output arrays in iter:36

pre layer res:
14:reshape
{'name': 'reshape', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        ...,

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [13], 'to': [1]}
tf node:
{'name': 'conv2d', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 32, 32]), 'from': [14], 'to': [2]}
ms node:
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': (1, 64, 32, 32), 'from': [14], 'to': [2]}
torch node:
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [14], 'to': [2]}

generate models:30

analyse the exceptions in iter:37
torch exception:
{'id': 0, 'name': 'linear', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 95.,  88.,  86.,  ..., 101.,  91., 105.],
           [ 82.,  75.,  76.,  ...,  94.,  51.,  84.],
           [ 77.,  74.,  71.,  ...,  71.,  47.,  88.],
           ...,
           [ 97.,  92.,  97.,  ...,  86.,  94.,  90.],
           [ 95.,  84.,  89.,  ...,  96., 102.,  97.],
           [ 91.,  83.,  82.,  ..., 100., 105., 108.]],

          [[105.,  97.,  96.,  ..., 116., 108., 124.],
           [ 90.,  83.,  84.,  ..., 102.,  61.,  97.],
           [ 85.,  81.,  78.,  ...,  74.,  52.,  95.],
           ...,
           [ 95.,  92.,  93.,  ...,  91.,  97.,  97.],
           [ 90.,  86.,  89.,  ...,  97.,  96.,  94.],
           [ 84.,  81.,  81.,  ...,  96.,  97., 102.]],

          [[127., 120., 118.,  ..., 144., 136., 157.],
           [110., 104., 104.,  ..., 123.,  80., 122.],
           [103.,  98.,  95.,  ...,  86.,  63., 111.],
           ...,
           [ 72.,  69.,  70.,  ...,  65.,  72.,  71.],
           [ 65.,  59.,  62.,  ...,  76.,  77.,  73.],
           [ 63.,  57.,  55.,  ...,  78.,  80.,  83.]]]]])}
mat1 and mat2 shapes cannot be multiplied (96x32 and 25x100)
mindspore exception:
{'id': 0, 'name': 'linear', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[9.50000000e+001, 8.80000000e+001, 8.60000000e+001 ... 1.01000000e+002, 9.10000000e+001, 1.05000000e+002],
    [8.20000000e+001, 7.50000000e+001, 7.60000000e+001 ... 9.40000000e+001, 5.10000000e+001, 8.40000000e+001],
    [7.70000000e+001, 7.40000000e+001, 7.10000000e+001 ... 7.10000000e+001, 4.70000000e+001, 8.80000000e+001],
    ...
    [9.70000000e+001, 9.20000000e+001, 9.70000000e+001 ... 8.60000000e+001, 9.40000000e+001, 9.00000000e+001],
    [9.50000000e+001, 8.40000000e+001, 8.90000000e+001 ... 9.60000000e+001, 1.02000000e+002, 9.70000000e+001],
    [9.10000000e+001, 8.30000000e+001, 8.20000000e+001 ... 1.00000000e+002, 1.05000000e+002, 1.08000000e+002]],
   [[1.05000000e+002, 9.70000000e+001, 9.60000000e+001 ... 1.16000000e+002, 1.08000000e+002, 1.24000000e+002],
    [9.00000000e+001, 8.30000000e+001, 8.40000000e+001 ... 1.02000000e+002, 6.10000000e+001, 9.70000000e+001],
    [8.50000000e+001, 8.10000000e+001, 7.80000000e+001 ... 7.40000000e+001, 5.20000000e+001, 9.50000000e+001],
    ...
    [9.50000000e+001, 9.20000000e+001, 9.30000000e+001 ... 9.10000000e+001, 9.70000000e+001, 9.70000000e+001],
    [9.00000000e+001, 8.60000000e+001, 8.90000000e+001 ... 9.70000000e+001, 9.60000000e+001, 9.40000000e+001],
    [8.40000000e+001, 8.10000000e+001, 8.10000000e+001 ... 9.60000000e+001, 9.70000000e+001, 1.02000000e+002]],
   [[1.27000000e+002, 1.20000000e+002, 1.18000000e+002 ... 1.44000000e+002, 1.36000000e+002, 1.57000000e+002],
    [1.10000000e+002, 1.04000000e+002, 1.04000000e+002 ... 1.23000000e+002, 8.00000000e+001, 1.22000000e+002],
    [1.03000000e+002, 9.80000000e+001, 9.50000000e+001 ... 8.60000000e+001, 6.30000000e+001, 1.11000000e+002],
    ...
    [7.20000000e+001, 6.90000000e+001, 7.00000000e+001 ... 6.50000000e+001, 7.20000000e+001, 7.10000000e+001],
    [6.50000000e+001, 5.90000000e+001, 6.20000000e+001 ... 7.60000000e+001, 7.70000000e+001, 7.30000000e+001],
    [6.30000000e+001, 5.70000000e+001, 5.50000000e+001 ... 7.80000000e+001, 8.00000000e+001, 8.30000000e+001]]]]])}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 25. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 25](transpose_b=True).

generate models:31

analyse the exceptions in iter:41
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[145., 145., 148.,  ..., 237., 230., 224.],
           [147., 150., 168.,  ..., 231., 221., 214.],
           [145., 150., 178.,  ..., 229., 230., 232.],
           ...,
           [231., 230., 227.,  ..., 235., 234., 231.],
           [224., 231., 231.,  ..., 240., 228., 223.],
           [125., 225., 232.,  ..., 224., 216., 228.]],

          [[125., 126., 130.,  ..., 210., 202., 199.],
           [126., 132., 147.,  ..., 203., 192., 190.],
           [124., 130., 155.,  ..., 201., 201., 205.],
           ...,
           [202., 202., 198.,  ..., 209., 207., 203.],
           [199., 200., 202.,  ..., 213., 201., 199.],
           [120., 200., 204.,  ..., 197., 189., 203.]],

          [[ 83.,  82.,  82.,  ..., 170., 161., 158.],
           [ 83.,  84., 107.,  ..., 163., 151., 149.],
           [ 79.,  84., 110.,  ..., 161., 160., 166.],
           ...,
           [169., 170., 166.,  ..., 172., 170., 167.],
           [163., 167., 170.,  ..., 177., 162., 162.],
           [ 98., 166., 170.,  ..., 160., 150., 167.]]]]])}
Given groups=1, weight of size [512, 512, 3, 3], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.45000000e+002, 1.45000000e+002, 1.48000000e+002 ... 2.37000000e+002, 2.30000000e+002, 2.24000000e+002],
    [1.47000000e+002, 1.50000000e+002, 1.68000000e+002 ... 2.31000000e+002, 2.21000000e+002, 2.14000000e+002],
    [1.45000000e+002, 1.50000000e+002, 1.78000000e+002 ... 2.29000000e+002, 2.30000000e+002, 2.32000000e+002],
    ...
    [2.31000000e+002, 2.30000000e+002, 2.27000000e+002 ... 2.35000000e+002, 2.34000000e+002, 2.31000000e+002],
    [2.24000000e+002, 2.31000000e+002, 2.31000000e+002 ... 2.40000000e+002, 2.28000000e+002, 2.23000000e+002],
    [1.25000000e+002, 2.25000000e+002, 2.32000000e+002 ... 2.24000000e+002, 2.16000000e+002, 2.28000000e+002]],
   [[1.25000000e+002, 1.26000000e+002, 1.30000000e+002 ... 2.10000000e+002, 2.02000000e+002, 1.99000000e+002],
    [1.26000000e+002, 1.32000000e+002, 1.47000000e+002 ... 2.03000000e+002, 1.92000000e+002, 1.90000000e+002],
    [1.24000000e+002, 1.30000000e+002, 1.55000000e+002 ... 2.01000000e+002, 2.01000000e+002, 2.05000000e+002],
    ...
    [2.02000000e+002, 2.02000000e+002, 1.98000000e+002 ... 2.09000000e+002, 2.07000000e+002, 2.03000000e+002],
    [1.99000000e+002, 2.00000000e+002, 2.02000000e+002 ... 2.13000000e+002, 2.01000000e+002, 1.99000000e+002],
    [1.20000000e+002, 2.00000000e+002, 2.04000000e+002 ... 1.97000000e+002, 1.89000000e+002, 2.03000000e+002]],
   [[8.30000000e+001, 8.20000000e+001, 8.20000000e+001 ... 1.70000000e+002, 1.61000000e+002, 1.58000000e+002],
    [8.30000000e+001, 8.40000000e+001, 1.07000000e+002 ... 1.63000000e+002, 1.51000000e+002, 1.49000000e+002],
    [7.90000000e+001, 8.40000000e+001, 1.10000000e+002 ... 1.61000000e+002, 1.60000000e+002, 1.66000000e+002],
    ...
    [1.69000000e+002, 1.70000000e+002, 1.66000000e+002 ... 1.72000000e+002, 1.70000000e+002, 1.67000000e+002],
    [1.63000000e+002, 1.67000000e+002, 1.70000000e+002 ... 1.77000000e+002, 1.62000000e+002, 1.62000000e+002],
    [9.80000000e+001, 1.66000000e+002, 1.70000000e+002 ... 1.60000000e+002, 1.50000000e+002, 1.67000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:34

analyse the exceptions in iter:48
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[191., 190., 190.,  ..., 135., 142., 146.],
           [187., 184., 179.,  ..., 147., 152., 153.],
           [181., 176., 165.,  ..., 154., 162., 158.],
           ...,
           [220., 221., 222.,  ..., 211., 214., 224.],
           [212., 220., 225.,  ..., 216., 216., 221.],
           [201., 212., 217.,  ..., 220., 217., 217.]],

          [[191., 192., 193.,  ..., 143., 149., 150.],
           [188., 187., 183.,  ..., 154., 158., 158.],
           [183., 178., 169.,  ..., 161., 167., 163.],
           ...,
           [245., 245., 244.,  ..., 238., 240., 248.],
           [238., 245., 247.,  ..., 242., 241., 244.],
           [226., 239., 243.,  ..., 242., 240., 238.]],

          [[168., 172., 174.,  ..., 123., 126., 127.],
           [165., 166., 163.,  ..., 134., 135., 134.],
           [160., 157., 148.,  ..., 140., 143., 139.],
           ...,
           [198., 199., 202.,  ..., 189., 193., 203.],
           [190., 198., 204.,  ..., 194., 195., 201.],
           [178., 190., 196.,  ..., 197., 196., 195.]]]]])}
Given groups=1, weight of size [512, 512, 3, 3], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.91000000e+002, 1.90000000e+002, 1.90000000e+002 ... 1.35000000e+002, 1.42000000e+002, 1.46000000e+002],
    [1.87000000e+002, 1.84000000e+002, 1.79000000e+002 ... 1.47000000e+002, 1.52000000e+002, 1.53000000e+002],
    [1.81000000e+002, 1.76000000e+002, 1.65000000e+002 ... 1.54000000e+002, 1.62000000e+002, 1.58000000e+002],
    ...
    [2.20000000e+002, 2.21000000e+002, 2.22000000e+002 ... 2.11000000e+002, 2.14000000e+002, 2.24000000e+002],
    [2.12000000e+002, 2.20000000e+002, 2.25000000e+002 ... 2.16000000e+002, 2.16000000e+002, 2.21000000e+002],
    [2.01000000e+002, 2.12000000e+002, 2.17000000e+002 ... 2.20000000e+002, 2.17000000e+002, 2.17000000e+002]],
   [[1.91000000e+002, 1.92000000e+002, 1.93000000e+002 ... 1.43000000e+002, 1.49000000e+002, 1.50000000e+002],
    [1.88000000e+002, 1.87000000e+002, 1.83000000e+002 ... 1.54000000e+002, 1.58000000e+002, 1.58000000e+002],
    [1.83000000e+002, 1.78000000e+002, 1.69000000e+002 ... 1.61000000e+002, 1.67000000e+002, 1.63000000e+002],
    ...
    [2.45000000e+002, 2.45000000e+002, 2.44000000e+002 ... 2.38000000e+002, 2.40000000e+002, 2.48000000e+002],
    [2.38000000e+002, 2.45000000e+002, 2.47000000e+002 ... 2.42000000e+002, 2.41000000e+002, 2.44000000e+002],
    [2.26000000e+002, 2.39000000e+002, 2.43000000e+002 ... 2.42000000e+002, 2.40000000e+002, 2.38000000e+002]],
   [[1.68000000e+002, 1.72000000e+002, 1.74000000e+002 ... 1.23000000e+002, 1.26000000e+002, 1.27000000e+002],
    [1.65000000e+002, 1.66000000e+002, 1.63000000e+002 ... 1.34000000e+002, 1.35000000e+002, 1.34000000e+002],
    [1.60000000e+002, 1.57000000e+002, 1.48000000e+002 ... 1.40000000e+002, 1.43000000e+002, 1.39000000e+002],
    ...
    [1.98000000e+002, 1.99000000e+002, 2.02000000e+002 ... 1.89000000e+002, 1.93000000e+002, 2.03000000e+002],
    [1.90000000e+002, 1.98000000e+002, 2.04000000e+002 ... 1.94000000e+002, 1.95000000e+002, 2.01000000e+002],
    [1.78000000e+002, 1.90000000e+002, 1.96000000e+002 ... 1.97000000e+002, 1.96000000e+002, 1.95000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:41

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:2
mindspore --> nums:6,distinct_bugs:3
torch --> nums:5,distinct_bugs:2
tensorflow --> 
cos:1
conv2d:1
mindspore --> 
conv2d:3
linear:2
log:1
torch --> 
conv2d:3
linear:2

generate models:42

analyse the exceptions in iter:57
torch exception:
{'id': 0, 'name': 'linear', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 66.,  71.,  88.,  ...,  85.,  86.,  79.],
           [ 75.,  79.,  95.,  ...,  85.,  87.,  78.],
           [ 80.,  84.,  97.,  ...,  81.,  82.,  74.],
           ...,
           [ 79.,  87.,  60.,  ...,  35.,  26.,  20.],
           [ 77.,  70.,  37.,  ...,  79.,  77.,  66.],
           [ 78.,  63.,  31.,  ..., 140., 135., 128.]],

          [[ 73.,  77.,  86.,  ...,  80.,  81.,  73.],
           [ 81.,  84.,  92.,  ...,  79.,  80.,  72.],
           [ 85.,  88.,  93.,  ...,  75.,  74.,  68.],
           ...,
           [ 74.,  84.,  58.,  ...,  35.,  26.,  21.],
           [ 74.,  68.,  37.,  ...,  68.,  66.,  55.],
           [ 74.,  61.,  32.,  ..., 122., 117., 113.]],

          [[ 33.,  40.,  62.,  ...,  55.,  62.,  54.],
           [ 40.,  45.,  66.,  ...,  56.,  62.,  54.],
           [ 44.,  50.,  68.,  ...,  48.,  53.,  51.],
           ...,
           [ 59.,  69.,  43.,  ...,  22.,  14.,  10.],
           [ 59.,  53.,  22.,  ...,  60.,  58.,  50.],
           [ 58.,  44.,  15.,  ..., 116., 113., 111.]]]]])}
mat1 and mat2 shapes cannot be multiplied (96x32 and 100x100)
mindspore exception:
{'id': 0, 'name': 'linear', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[6.60000000e+001, 7.10000000e+001, 8.80000000e+001 ... 8.50000000e+001, 8.60000000e+001, 7.90000000e+001],
    [7.50000000e+001, 7.90000000e+001, 9.50000000e+001 ... 8.50000000e+001, 8.70000000e+001, 7.80000000e+001],
    [8.00000000e+001, 8.40000000e+001, 9.70000000e+001 ... 8.10000000e+001, 8.20000000e+001, 7.40000000e+001],
    ...
    [7.90000000e+001, 8.70000000e+001, 6.00000000e+001 ... 3.50000000e+001, 2.60000000e+001, 2.00000000e+001],
    [7.70000000e+001, 7.00000000e+001, 3.70000000e+001 ... 7.90000000e+001, 7.70000000e+001, 6.60000000e+001],
    [7.80000000e+001, 6.30000000e+001, 3.10000000e+001 ... 1.40000000e+002, 1.35000000e+002, 1.28000000e+002]],
   [[7.30000000e+001, 7.70000000e+001, 8.60000000e+001 ... 8.00000000e+001, 8.10000000e+001, 7.30000000e+001],
    [8.10000000e+001, 8.40000000e+001, 9.20000000e+001 ... 7.90000000e+001, 8.00000000e+001, 7.20000000e+001],
    [8.50000000e+001, 8.80000000e+001, 9.30000000e+001 ... 7.50000000e+001, 7.40000000e+001, 6.80000000e+001],
    ...
    [7.40000000e+001, 8.40000000e+001, 5.80000000e+001 ... 3.50000000e+001, 2.60000000e+001, 2.10000000e+001],
    [7.40000000e+001, 6.80000000e+001, 3.70000000e+001 ... 6.80000000e+001, 6.60000000e+001, 5.50000000e+001],
    [7.40000000e+001, 6.10000000e+001, 3.20000000e+001 ... 1.22000000e+002, 1.17000000e+002, 1.13000000e+002]],
   [[3.30000000e+001, 4.00000000e+001, 6.20000000e+001 ... 5.50000000e+001, 6.20000000e+001, 5.40000000e+001],
    [4.00000000e+001, 4.50000000e+001, 6.60000000e+001 ... 5.60000000e+001, 6.20000000e+001, 5.40000000e+001],
    [4.40000000e+001, 5.00000000e+001, 6.80000000e+001 ... 4.80000000e+001, 5.30000000e+001, 5.10000000e+001],
    ...
    [5.90000000e+001, 6.90000000e+001, 4.30000000e+001 ... 2.20000000e+001, 1.40000000e+001, 1.00000000e+001],
    [5.90000000e+001, 5.30000000e+001, 2.20000000e+001 ... 6.00000000e+001, 5.80000000e+001, 5.00000000e+001],
    [5.80000000e+001, 4.40000000e+001, 1.50000000e+001 ... 1.16000000e+002, 1.13000000e+002, 1.11000000e+002]]]]])}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 100. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 100](transpose_b=True).

generate models:48

analyse the exceptions in iter:59
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[252., 255., 194.,  ..., 255., 255., 253.],
          [251., 255., 211.,  ..., 246., 249., 251.],
          [251., 255., 218.,  ..., 249., 250., 252.],
          ...,
          [ 57.,  30.,  73.,  ...,  23.,  26., 112.],
          [ 89.,  16.,  26.,  ...,  21.,  32., 149.],
          [185.,  94.,  54.,  ...,  60., 129., 221.]],

         [[251., 255., 212.,  ..., 254., 253., 252.],
          [249., 255., 234.,  ..., 255., 255., 252.],
          [250., 255., 235.,  ..., 255., 254., 253.],
          ...,
          [111.,  86.,  88.,  ...,  60.,  81., 149.],
          [134.,  77.,  74.,  ...,  75.,  83., 174.],
          [208., 134.,  99.,  ..., 104., 159., 232.]],

         [[249., 255., 224.,  ..., 253., 252., 252.],
          [246., 254., 240.,  ..., 251., 252., 251.],
          [249., 255., 240.,  ..., 254., 252., 252.],
          ...,
          [159., 138., 110.,  ..., 100., 139., 186.],
          [177., 144., 136.,  ..., 140., 145., 198.],
          [229., 182., 159.,  ..., 159., 197., 240.]]]])]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[2.52000000e+002, 2.55000000e+002, 1.94000000e+002 ... 2.55000000e+002, 2.55000000e+002, 2.53000000e+002],
   [2.51000000e+002, 2.55000000e+002, 2.11000000e+002 ... 2.46000000e+002, 2.49000000e+002, 2.51000000e+002],
   [2.51000000e+002, 2.55000000e+002, 2.18000000e+002 ... 2.49000000e+002, 2.50000000e+002, 2.52000000e+002],
   ...
   [5.70000000e+001, 3.00000000e+001, 7.30000000e+001 ... 2.30000000e+001, 2.60000000e+001, 1.12000000e+002],
   [8.90000000e+001, 1.60000000e+001, 2.60000000e+001 ... 2.10000000e+001, 3.20000000e+001, 1.49000000e+002],
   [1.85000000e+002, 9.40000000e+001, 5.40000000e+001 ... 6.00000000e+001, 1.29000000e+002, 2.21000000e+002]],
  [[2.51000000e+002, 2.55000000e+002, 2.12000000e+002 ... 2.54000000e+002, 2.53000000e+002, 2.52000000e+002],
   [2.49000000e+002, 2.55000000e+002, 2.34000000e+002 ... 2.55000000e+002, 2.55000000e+002, 2.52000000e+002],
   [2.50000000e+002, 2.55000000e+002, 2.35000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.53000000e+002],
   ...
   [1.11000000e+002, 8.60000000e+001, 8.80000000e+001 ... 6.00000000e+001, 8.10000000e+001, 1.49000000e+002],
   [1.34000000e+002, 7.70000000e+001, 7.40000000e+001 ... 7.50000000e+001, 8.30000000e+001, 1.74000000e+002],
   [2.08000000e+002, 1.34000000e+002, 9.90000000e+001 ... 1.04000000e+002, 1.59000000e+002, 2.32000000e+002]],
  [[2.49000000e+002, 2.55000000e+002, 2.24000000e+002 ... 2.53000000e+002, 2.52000000e+002, 2.52000000e+002],
   [2.46000000e+002, 2.54000000e+002, 2.40000000e+002 ... 2.51000000e+002, 2.52000000e+002, 2.51000000e+002],
   [2.49000000e+002, 2.55000000e+002, 2.40000000e+002 ... 2.54000000e+002, 2.52000000e+002, 2.52000000e+002],
   ...
   [1.59000000e+002, 1.38000000e+002, 1.10000000e+002 ... 1.00000000e+002, 1.39000000e+002, 1.86000000e+002],
   [1.77000000e+002, 1.44000000e+002, 1.36000000e+002 ... 1.40000000e+002, 1.45000000e+002, 1.98000000e+002],
   [2.29000000e+002, 1.82000000e+002, 1.59000000e+002 ... 1.59000000e+002, 1.97000000e+002, 2.40000000e+002]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:50

analyse the exceptions in iter:62
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 76.,  73.,  69.,  ...,  75.,  72.,  70.],
           [ 76.,  71.,  66.,  ...,  79.,  76.,  75.],
           [ 71.,  65.,  62.,  ...,  80.,  77.,  76.],
           ...,
           [ 11.,   9.,   6.,  ...,  31.,  32.,  29.],
           [  0.,   0.,   0.,  ...,  12.,  12.,  13.],
           [ 87.,  83.,  81.,  ...,  99.,  99., 102.]],

          [[118., 118., 116.,  ..., 135., 134., 135.],
           [122., 119., 117.,  ..., 136., 135., 137.],
           [120., 117., 116.,  ..., 133., 132., 135.],
           ...,
           [ 36.,  32.,  32.,  ...,  61.,  62.,  59.],
           [ 19.,  13.,   7.,  ...,  38.,  37.,  38.],
           [100.,  92.,  86.,  ..., 116., 115., 119.]],

          [[167., 164., 162.,  ..., 180., 178., 179.],
           [170., 166., 163.,  ..., 178., 177., 179.],
           [170., 165., 164.,  ..., 173., 172., 174.],
           ...,
           [ 66.,  61.,  61.,  ...,  79.,  80.,  77.],
           [ 46.,  40.,  36.,  ...,  55.,  55.,  56.],
           [115., 108., 103.,  ..., 127., 127., 130.]]]]])}
Given groups=1, weight of size [512, 512, 3, 3], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[7.60000000e+001, 7.30000000e+001, 6.90000000e+001 ... 7.50000000e+001, 7.20000000e+001, 7.00000000e+001],
    [7.60000000e+001, 7.10000000e+001, 6.60000000e+001 ... 7.90000000e+001, 7.60000000e+001, 7.50000000e+001],
    [7.10000000e+001, 6.50000000e+001, 6.20000000e+001 ... 8.00000000e+001, 7.70000000e+001, 7.60000000e+001],
    ...
    [1.10000000e+001, 9.00000000e+000, 6.00000000e+000 ... 3.10000000e+001, 3.20000000e+001, 2.90000000e+001],
    [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 1.20000000e+001, 1.20000000e+001, 1.30000000e+001],
    [8.70000000e+001, 8.30000000e+001, 8.10000000e+001 ... 9.90000000e+001, 9.90000000e+001, 1.02000000e+002]],
   [[1.18000000e+002, 1.18000000e+002, 1.16000000e+002 ... 1.35000000e+002, 1.34000000e+002, 1.35000000e+002],
    [1.22000000e+002, 1.19000000e+002, 1.17000000e+002 ... 1.36000000e+002, 1.35000000e+002, 1.37000000e+002],
    [1.20000000e+002, 1.17000000e+002, 1.16000000e+002 ... 1.33000000e+002, 1.32000000e+002, 1.35000000e+002],
    ...
    [3.60000000e+001, 3.20000000e+001, 3.20000000e+001 ... 6.10000000e+001, 6.20000000e+001, 5.90000000e+001],
    [1.90000000e+001, 1.30000000e+001, 7.00000000e+000 ... 3.80000000e+001, 3.70000000e+001, 3.80000000e+001],
    [1.00000000e+002, 9.20000000e+001, 8.60000000e+001 ... 1.16000000e+002, 1.15000000e+002, 1.19000000e+002]],
   [[1.67000000e+002, 1.64000000e+002, 1.62000000e+002 ... 1.80000000e+002, 1.78000000e+002, 1.79000000e+002],
    [1.70000000e+002, 1.66000000e+002, 1.63000000e+002 ... 1.78000000e+002, 1.77000000e+002, 1.79000000e+002],
    [1.70000000e+002, 1.65000000e+002, 1.64000000e+002 ... 1.73000000e+002, 1.72000000e+002, 1.74000000e+002],
    ...
    [6.60000000e+001, 6.10000000e+001, 6.10000000e+001 ... 7.90000000e+001, 8.00000000e+001, 7.70000000e+001],
    [4.60000000e+001, 4.00000000e+001, 3.60000000e+001 ... 5.50000000e+001, 5.50000000e+001, 5.60000000e+001],
    [1.15000000e+002, 1.08000000e+002, 1.03000000e+002 ... 1.27000000e+002, 1.27000000e+002, 1.30000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:52

analyse output arrays in iter:68

pre layer res:
3:conv2d
{'name': 'conv2d', 'output': array([[[[20062396., 32099852., 36112344., ..., 36112344., 32099852.,
          20062396.],
         [31371192., 50193928., 56468184., ..., 56468184., 50193928.,
          31371192.],
         [33303060., 53284876., 59945516., ..., 59945516., 53284876.,
          33303060.],
         ...,
         [21679974., 34687984., 39023992., ..., 39023992., 34687984.,
          21679974.],
         [19247360., 30795776., 34645248., ..., 34645248., 30795776.,
          19247360.],
         [12387846., 19820550., 22298112., ..., 22298112., 19820550.,
          12387846.]],

        [[20062396., 32099852., 36112344., ..., 36112344., 32099852.,
          20062396.],
         [31371192., 50193928., 56468184., ..., 56468184., 50193928.,
          31371192.],
         [33303060., 53284876., 59945516., ..., 59945516., 53284876.,
          33303060.],
         ...,
         [21679974., 34687984., 39023992., ..., 39023992., 34687984.,
          21679974.],
         [19247360., 30795776., 34645248., ..., 34645248., 30795776.,
          19247360.],
         [12387846., 19820550., 22298112., ..., 22298112., 19820550.,
          12387846.]],

        [[20062396., 32099852., 36112344., ..., 36112344., 32099852.,
          20062396.],
         [31371192., 50193928., 56468184., ..., 56468184., 50193928.,
          31371192.],
         [33303060., 53284876., 59945516., ..., 59945516., 53284876.,
          33303060.],
         ...,
         [21679974., 34687984., 39023992., ..., 39023992., 34687984.,
          21679974.],
         [19247360., 30795776., 34645248., ..., 34645248., 30795776.,
          19247360.],
         [12387846., 19820550., 22298112., ..., 22298112., 19820550.,
          12387846.]],

        ...,

        [[20062396., 32099852., 36112344., ..., 36112344., 32099852.,
          20062396.],
         [31371192., 50193928., 56468184., ..., 56468184., 50193928.,
          31371192.],
         [33303060., 53284876., 59945516., ..., 59945516., 53284876.,
          33303060.],
         ...,
         [21679974., 34687984., 39023992., ..., 39023992., 34687984.,
          21679974.],
         [19247360., 30795776., 34645248., ..., 34645248., 30795776.,
          19247360.],
         [12387846., 19820550., 22298112., ..., 22298112., 19820550.,
          12387846.]],

        [[20062396., 32099852., 36112344., ..., 36112344., 32099852.,
          20062396.],
         [31371192., 50193928., 56468184., ..., 56468184., 50193928.,
          31371192.],
         [33303060., 53284876., 59945516., ..., 59945516., 53284876.,
          33303060.],
         ...,
         [21679974., 34687984., 39023992., ..., 39023992., 34687984.,
          21679974.],
         [19247360., 30795776., 34645248., ..., 34645248., 30795776.,
          19247360.],
         [12387846., 19820550., 22298112., ..., 22298112., 19820550.,
          12387846.]],

        [[20062396., 32099852., 36112344., ..., 36112344., 32099852.,
          20062396.],
         [31371192., 50193928., 56468184., ..., 56468184., 50193928.,
          31371192.],
         [33303060., 53284876., 59945516., ..., 59945516., 53284876.,
          33303060.],
         ...,
         [21679974., 34687984., 39023992., ..., 39023992., 34687984.,
          21679974.],
         [19247360., 30795776., 34645248., ..., 34645248., 30795776.,
          19247360.],
         [12387846., 19820550., 22298112., ..., 22298112., 19820550.,
          12387846.]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 100]), 'from': [2], 'to': [14, 15]}
tf node:
{'name': 'cos', 'output': array([[[[-0.99920845,  0.7361612 ,  0.9424982 , ...,  0.9424982 ,
           0.7361612 , -0.99920845],
         [-0.17183578,  0.02763428, -0.7664015 , ..., -0.7664015 ,
           0.02763428, -0.17183578],
         [-0.7328879 , -0.83559585,  0.38213596, ...,  0.38213596,
          -0.83559585, -0.7328879 ],
         ...,
         [ 0.9843394 ,  0.73114747,  0.15035866, ...,  0.15035866,
           0.73114747,  0.9843394 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.8914658 , -0.9989483 , -0.02251258, ..., -0.02251258,
          -0.9989483 ,  0.8914658 ]],

        [[-0.99920845,  0.7361612 ,  0.9424982 , ...,  0.9424982 ,
           0.7361612 , -0.99920845],
         [-0.17183578,  0.02763428, -0.7664015 , ..., -0.7664015 ,
           0.02763428, -0.17183578],
         [-0.7328879 , -0.83559585,  0.38213596, ...,  0.38213596,
          -0.83559585, -0.7328879 ],
         ...,
         [ 0.9843394 ,  0.73114747,  0.15035866, ...,  0.15035866,
           0.73114747,  0.9843394 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.8914658 , -0.9989483 , -0.02251258, ..., -0.02251258,
          -0.9989483 ,  0.8914658 ]],

        [[-0.99920845,  0.7361612 ,  0.9424982 , ...,  0.9424982 ,
           0.7361612 , -0.99920845],
         [-0.17183578,  0.02763428, -0.7664015 , ..., -0.7664015 ,
           0.02763428, -0.17183578],
         [-0.7328879 , -0.83559585,  0.38213596, ...,  0.38213596,
          -0.83559585, -0.7328879 ],
         ...,
         [ 0.9843394 ,  0.73114747,  0.15035866, ...,  0.15035866,
           0.73114747,  0.9843394 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.8914658 , -0.9989483 , -0.02251258, ..., -0.02251258,
          -0.9989483 ,  0.8914658 ]],

        ...,

        [[-0.99920845,  0.7361612 ,  0.9424982 , ...,  0.9424982 ,
           0.7361612 , -0.99920845],
         [-0.17183578,  0.02763428, -0.7664015 , ..., -0.7664015 ,
           0.02763428, -0.17183578],
         [-0.7328879 , -0.83559585,  0.38213596, ...,  0.38213596,
          -0.83559585, -0.7328879 ],
         ...,
         [ 0.9843394 ,  0.73114747,  0.15035866, ...,  0.15035866,
           0.73114747,  0.9843394 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.8914658 , -0.9989483 , -0.02251258, ..., -0.02251258,
          -0.9989483 ,  0.8914658 ]],

        [[-0.99920845,  0.7361612 ,  0.9424982 , ...,  0.9424982 ,
           0.7361612 , -0.99920845],
         [-0.17183578,  0.02763428, -0.7664015 , ..., -0.7664015 ,
           0.02763428, -0.17183578],
         [-0.7328879 , -0.83559585,  0.38213596, ...,  0.38213596,
          -0.83559585, -0.7328879 ],
         ...,
         [ 0.9843394 ,  0.73114747,  0.15035866, ...,  0.15035866,
           0.73114747,  0.9843394 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.8914658 , -0.9989483 , -0.02251258, ..., -0.02251258,
          -0.9989483 ,  0.8914658 ]],

        [[-0.99920845,  0.7361612 ,  0.9424982 , ...,  0.9424982 ,
           0.7361612 , -0.99920845],
         [-0.17183578,  0.02763428, -0.7664015 , ..., -0.7664015 ,
           0.02763428, -0.17183578],
         [-0.7328879 , -0.83559585,  0.38213596, ...,  0.38213596,
          -0.83559585, -0.7328879 ],
         ...,
         [ 0.9843394 ,  0.73114747,  0.15035866, ...,  0.15035866,
           0.73114747,  0.9843394 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.8914658 , -0.9989483 , -0.02251258, ..., -0.02251258,
          -0.9989483 ,  0.8914658 ]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 100]), 'from': [3], 'to': [4]}
ms node:
{'name': 'cos', 'output': array([[[[ 0.6832322 ,  0.2580566 ,  0.09713348, ...,  0.09713348,
           0.2580566 ,  0.6832322 ],
         [-0.94964004, -0.9930012 ,  0.25661758, ...,  0.25661758,
          -0.9930012 , -0.94964004],
         [-0.92020017, -0.99988437,  0.39843455, ...,  0.39843455,
          -0.99988437, -0.92020017],
         ...,
         [ 0.5023618 , -0.503777  , -0.99998796, ..., -0.99998796,
          -0.503777  ,  0.5023618 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9463488 , -0.02251258, ..., -0.02251258,
          -0.9463488 ,  0.9825588 ]],

        [[ 0.6832322 ,  0.2580566 ,  0.09713348, ...,  0.09713348,
           0.2580566 ,  0.6832322 ],
         [-0.94964004, -0.9930012 ,  0.25661758, ...,  0.25661758,
          -0.9930012 , -0.94964004],
         [-0.92020017, -0.99988437,  0.39843455, ...,  0.39843455,
          -0.99988437, -0.92020017],
         ...,
         [ 0.5023618 , -0.503777  , -0.99998796, ..., -0.99998796,
          -0.503777  ,  0.5023618 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9463488 , -0.02251258, ..., -0.02251258,
          -0.9463488 ,  0.9825588 ]],

        [[ 0.6832322 ,  0.2580566 ,  0.09713348, ...,  0.09713348,
           0.2580566 ,  0.6832322 ],
         [-0.94964004, -0.9930012 ,  0.25661758, ...,  0.25661758,
          -0.9930012 , -0.94964004],
         [-0.92020017, -0.99988437,  0.39843455, ...,  0.39843455,
          -0.99988437, -0.92020017],
         ...,
         [ 0.5023618 , -0.503777  , -0.99998796, ..., -0.99998796,
          -0.503777  ,  0.5023618 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9463488 , -0.02251258, ..., -0.02251258,
          -0.9463488 ,  0.9825588 ]],

        ...,

        [[ 0.6832322 ,  0.2580566 ,  0.09713348, ...,  0.09713348,
           0.2580566 ,  0.6832322 ],
         [-0.94964004, -0.9930012 ,  0.25661758, ...,  0.25661758,
          -0.9930012 , -0.94964004],
         [-0.92020017, -0.99988437,  0.39843455, ...,  0.39843455,
          -0.99988437, -0.92020017],
         ...,
         [ 0.5023618 , -0.503777  , -0.99998796, ..., -0.99998796,
          -0.503777  ,  0.5023618 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9463488 , -0.02251258, ..., -0.02251258,
          -0.9463488 ,  0.9825588 ]],

        [[ 0.6832322 ,  0.2580566 ,  0.09713348, ...,  0.09713348,
           0.2580566 ,  0.6832322 ],
         [-0.94964004, -0.9930012 ,  0.25661758, ...,  0.25661758,
          -0.9930012 , -0.94964004],
         [-0.92020017, -0.99988437,  0.39843455, ...,  0.39843455,
          -0.99988437, -0.92020017],
         ...,
         [ 0.5023618 , -0.503777  , -0.99998796, ..., -0.99998796,
          -0.503777  ,  0.5023618 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9463488 , -0.02251258, ..., -0.02251258,
          -0.9463488 ,  0.9825588 ]],

        [[ 0.6832322 ,  0.2580566 ,  0.09713348, ...,  0.09713348,
           0.2580566 ,  0.6832322 ],
         [-0.94964004, -0.9930012 ,  0.25661758, ...,  0.25661758,
          -0.9930012 , -0.94964004],
         [-0.92020017, -0.99988437,  0.39843455, ...,  0.39843455,
          -0.99988437, -0.92020017],
         ...,
         [ 0.5023618 , -0.503777  , -0.99998796, ..., -0.99998796,
          -0.503777  ,  0.5023618 ],
         [-0.99583507,  0.98934937, -0.98652667, ..., -0.98652667,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9463488 , -0.02251258, ..., -0.02251258,
          -0.9463488 ,  0.9825588 ]]]], dtype=float32), 'output_shape': (1, 512, 32, 100), 'from': [3], 'to': [4]}
torch node:
{'name': 'cos', 'output': array([[[[-0.8218409 ,  0.04871016,  0.601961  , ...,  0.601961  ,
          -0.99527115, -0.8218409 ],
         [-0.686574  ,  0.5449299 ,  0.98410505, ...,  0.98410505,
           0.7502713 , -0.686574  ],
         [-0.92020017,  0.92938346, -0.2564963 , ..., -0.2564963 ,
           0.2299623 , -0.92020017],
         ...,
         [-0.24933563,  0.9913906 ,  0.7213959 , ...,  0.7213959 ,
          -0.9117172 , -0.5699239 ],
         [-0.99583507,  0.98934937, -0.74470085, ..., -0.74470085,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9719721 , -0.02251258, ..., -0.02251258,
           0.37401643,  0.9825588 ]],

        [[-0.8218409 ,  0.04871016,  0.601961  , ...,  0.601961  ,
          -0.99527115, -0.8218409 ],
         [-0.686574  ,  0.5449299 ,  0.98410505, ...,  0.98410505,
           0.7502713 , -0.686574  ],
         [-0.92020017,  0.92938346, -0.2564963 , ..., -0.2564963 ,
           0.2299623 , -0.92020017],
         ...,
         [-0.24933563,  0.9913906 ,  0.7213959 , ...,  0.7213959 ,
          -0.9117172 , -0.5699239 ],
         [-0.99583507,  0.98934937, -0.74470085, ..., -0.74470085,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9719721 , -0.02251258, ..., -0.02251258,
           0.37401643,  0.9825588 ]],

        [[-0.8218409 ,  0.04871016,  0.601961  , ...,  0.601961  ,
          -0.99527115, -0.8218409 ],
         [-0.686574  ,  0.5449299 ,  0.98410505, ...,  0.98410505,
           0.7502713 , -0.686574  ],
         [-0.92020017,  0.92938346, -0.2564963 , ..., -0.2564963 ,
           0.2299623 , -0.92020017],
         ...,
         [-0.24933563,  0.9913906 ,  0.7213959 , ...,  0.7213959 ,
          -0.9117172 , -0.5699239 ],
         [-0.99583507,  0.98934937, -0.74470085, ..., -0.74470085,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9719721 , -0.02251258, ..., -0.02251258,
           0.37401643,  0.9825588 ]],

        ...,

        [[-0.8218409 ,  0.04871016,  0.601961  , ...,  0.601961  ,
          -0.99527115, -0.8218409 ],
         [-0.686574  ,  0.5449299 ,  0.98410505, ...,  0.98410505,
           0.7502713 , -0.686574  ],
         [-0.92020017,  0.92938346, -0.2564963 , ..., -0.2564963 ,
           0.2299623 , -0.92020017],
         ...,
         [-0.24933563,  0.9913906 ,  0.7213959 , ...,  0.7213959 ,
          -0.9117172 , -0.5699239 ],
         [-0.99583507,  0.98934937, -0.74470085, ..., -0.74470085,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9719721 , -0.02251258, ..., -0.02251258,
           0.37401643,  0.9825588 ]],

        [[-0.8218409 ,  0.04871016,  0.601961  , ...,  0.601961  ,
          -0.99527115, -0.8218409 ],
         [-0.686574  ,  0.5449299 ,  0.98410505, ...,  0.98410505,
           0.7502713 , -0.686574  ],
         [-0.92020017,  0.92938346, -0.2564963 , ..., -0.2564963 ,
           0.2299623 , -0.92020017],
         ...,
         [-0.24933563,  0.9913906 ,  0.7213959 , ...,  0.7213959 ,
          -0.9117172 , -0.5699239 ],
         [-0.99583507,  0.98934937, -0.74470085, ..., -0.74470085,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9719721 , -0.02251258, ..., -0.02251258,
           0.37401643,  0.9825588 ]],

        [[-0.8218409 ,  0.04871016,  0.601961  , ...,  0.601961  ,
          -0.99527115, -0.8218409 ],
         [-0.686574  ,  0.5449299 ,  0.98410505, ...,  0.98410505,
           0.7502713 , -0.686574  ],
         [-0.92020017,  0.92938346, -0.2564963 , ..., -0.2564963 ,
           0.2299623 , -0.92020017],
         ...,
         [-0.24933563,  0.9913906 ,  0.7213959 , ...,  0.7213959 ,
          -0.9117172 , -0.5699239 ],
         [-0.99583507,  0.98934937, -0.74470085, ..., -0.74470085,
           0.98934937, -0.99583507],
         [ 0.9825588 , -0.9719721 , -0.02251258, ..., -0.02251258,
           0.37401643,  0.9825588 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 100]), 'from': [3], 'to': [4]}

generate models:57

analyse the exceptions in iter:84
torch exception:
{'id': 2, 'name': 'linear', 'frame_work': 'torch', 'input_datas': [tensor([[[[ 0.6230,  0.8601,  0.5140,  ..., -0.8900, -0.9957, -0.4910],
          [ 0.6833,  0.5661,  0.9866,  ...,  0.3300,  0.9726,  0.6090],
          [ 0.5140,  0.7739, -0.1586,  ...,  0.2194,  0.9965,  0.7958],
          ...,
          [-0.7024, -0.0619, -0.8733,  ...,  0.9988,  0.5806, -0.3714],
          [-0.9957,  0.4987,  0.7210,  ..., -0.6160,  0.6961, -0.9746],
          [-0.5878, -0.4910, -0.9983,  ...,  0.7958,  0.9978,  0.7087]],

         [[-0.9483,  0.7332, -0.4441,  ...,  0.7850,  0.5806,  0.3300],
          [-0.6299, -0.8555, -0.2624,  ..., -0.3714,  0.7850,  0.9988],
          [-0.1148,  0.9200, -0.6435,  ...,  0.7958, -0.5878,  0.9802],
          ...,
          [ 0.0708, -0.2108, -0.2108,  ...,  0.3632, -0.7904,  0.3300],
          [-0.9983,  0.6090,  0.2021,  ..., -0.9301, -0.9983, -0.9746],
          [-0.2281, -0.4910, -0.5878,  ...,  0.2194, -0.9972, -0.8011]],

         [[-0.8979,  0.6367,  0.6367,  ..., -0.4441,  0.1060, -0.8900],
          [ 0.6367,  0.9866,  0.0177,  ..., -0.6299,  0.3132,  0.8167],
          [ 0.9929, -0.7392,  0.0177,  ...,  0.6230,  0.1060,  0.8167],
          ...,
          [-0.9705,  0.9836,  0.3796,  ..., -0.9235, -0.1761,  0.3132],
          [ 0.8601, -0.8218, -0.5734,  ..., -0.4441,  0.1060, -0.5734],
          [ 0.8940, -0.7795, -0.9483,  ..., -0.9705, -0.8646, -0.0972]]]])]}
mat1 and mat2 shapes cannot be multiplied (96x32 and 100x100)
mindspore exception:
{'id': 2, 'name': 'linear', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[6.22988641e-001, 8.60069394e-001, 5.13978481e-001 ... -8.89995575e-001, -9.95687008e-001, -4.91021603e-001],
   [6.83261693e-001, 5.66107631e-001, 9.86627579e-001 ... 3.29990834e-001, 9.72630084e-001, 6.09044015e-001],
   [5.13978481e-001, 7.73890674e-001, -1.58622667e-001 ... 2.19425261e-001, 9.96469200e-001, 7.95824111e-001],
   ...
   [-7.02407777e-001, -6.19203374e-002, -8.73311996e-001 ... 9.98815238e-001, 5.80611169e-001, -3.71404111e-001],
   [-9.95687008e-001, 4.98713166e-001, 7.21037686e-001 ... -6.16040468e-001, 6.96080148e-001, -9.74648654e-001],
   [-5.87795019e-001, -4.91021603e-001, -9.98345375e-001 ... 7.95824111e-001, 9.97797251e-001, 7.08659112e-001]],
  [[-9.48282123e-001, 7.33190298e-001, -4.44112659e-001 ... 7.84980416e-001, 5.80611169e-001, 3.29990834e-001],
   [-6.29887998e-001, -8.55519950e-001, -2.62374848e-001 ... -3.71404111e-001, 7.84980416e-001, 9.98815238e-001],
   [-1.14784814e-001, 9.20026064e-001, -6.43538117e-001 ... 7.95824111e-001, -5.87795019e-001, 9.80239630e-001],
   ...
   [7.07522333e-002, -2.10810527e-001, -2.10810527e-001 ... 3.63171369e-001, -7.90433228e-001, 3.29990834e-001],
   [-9.98345375e-001, 6.09044015e-001, 2.02149883e-001 ... -9.30105925e-001, -9.98345375e-001, -9.74648654e-001],
   [-2.28052258e-001, -4.91021603e-001, -5.87795019e-001 ... 2.19425261e-001, -9.97173309e-001, -8.01134586e-001]],
  [[-8.97927701e-001, 6.36738002e-001, 6.36738002e-001 ... -4.44112659e-001, 1.05987512e-001, -8.89995575e-001],
   [6.36738002e-001, 9.86627579e-001, 1.77019257e-002 ... -6.29887998e-001, 3.13228786e-001, 8.16742599e-001],
   [9.92872655e-001, -7.39180684e-001, 1.77019257e-002 ... 6.22988641e-001, 1.05987512e-001, 8.16742599e-001],
   ...
   [-9.70535278e-001, 9.83587742e-001, 3.79607737e-001 ... -9.23458457e-001, -1.76075622e-001, 3.13228786e-001],
   [8.60069394e-001, -8.21817815e-001, -5.73381901e-001 ... -4.44112659e-001, 1.05987512e-001, -5.73381901e-001],
   [8.93996656e-001, -7.79466093e-001, -9.48282123e-001 ... -9.70535278e-001, -8.64551425e-001, -9.71819088e-002]]]])]}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 100. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 100](transpose_b=True).

generate models:71

analyse output arrays in iter:88

pre layer res:
7:linear
{'name': 'linear', 'output': array([[[[    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         ...,
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf]],

        [[    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         ...,
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf]],

        [[    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         ...,
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf],
         [    inf,     inf,     inf, ...,     inf,     inf,     inf]],

        ...,

        [[18894. , 18894. , 18894. , ..., 18894. , 18894. , 18894. ],
         [28341. , 28341. , 28341. , ..., 28341. , 28341. , 28341. ],
         [28341. , 28341. , 28341. , ..., 28341. , 28341. , 28341. ],
         ...,
         [28334.5, 28334.5, 28334.5, ..., 28334.5, 28334.5, 28334.5],
         [28331.5, 28331.5, 28331.5, ..., 28331.5, 28331.5, 28331.5],
         [18886. , 18886. , 18886. , ..., 18886. , 18886. , 18886. ]],

        [[18894. , 18894. , 18894. , ..., 18894. , 18894. , 18894. ],
         [28341. , 28341. , 28341. , ..., 28341. , 28341. , 28341. ],
         [28341. , 28341. , 28341. , ..., 28341. , 28341. , 28341. ],
         ...,
         [28334.5, 28334.5, 28334.5, ..., 28334.5, 28334.5, 28334.5],
         [28331.5, 28331.5, 28331.5, ..., 28331.5, 28331.5, 28331.5],
         [18886. , 18886. , 18886. , ..., 18886. , 18886. , 18886. ]],

        [[18894. , 18894. , 18894. , ..., 18894. , 18894. , 18894. ],
         [28341. , 28341. , 28341. , ..., 28341. , 28341. , 28341. ],
         [28341. , 28341. , 28341. , ..., 28341. , 28341. , 28341. ],
         ...,
         [28334.5, 28334.5, 28334.5, ..., 28334.5, 28334.5, 28334.5],
         [28331.5, 28331.5, 28331.5, ..., 28331.5, 28331.5, 28331.5],
         [18886. , 18886. , 18886. , ..., 18886. , 18886. , 18886. ]]]],
      dtype=float32), 'output_shape': TensorShape([1, 256, 32, 100]), 'from': [21], 'to': [8]}
tf node:
{'name': 'conv2d', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 100]), 'from': [7], 'to': []}
ms node:
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': (1, 512, 32, 100), 'from': [7], 'to': []}
torch node:
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 100]), 'from': [7], 'to': []}

generate models:75

analyse output arrays in iter:89

pre layer res:
2:conv2d
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [10], 'to': [3]}
tf node:
{'name': 'conv2d', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [2], 'to': [4, 22]}
ms node:
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [2], 'to': [4, 22]}
torch node:
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [2], 'to': [4, 22]}

generate models:76

analyse the exceptions in iter:95
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[246., 252., 249.,  ..., 252., 250., 254.],
           [244., 253., 253.,  ..., 250., 249., 253.],
           [237., 251., 255.,  ..., 251., 251., 255.],
           ...,
           [ 50.,  46.,  93.,  ..., 246., 244., 251.],
           [ 61.,  58., 103.,  ..., 241., 245., 247.],
           [ 80.,  81., 120.,  ..., 244., 245., 243.]],

          [[254., 250., 252.,  ..., 250., 251., 254.],
           [254., 249., 248.,  ..., 251., 250., 254.],
           [255., 251., 249.,  ..., 252., 253., 255.],
           ...,
           [246., 239., 247.,  ..., 229., 215., 214.],
           [247., 239., 248.,  ..., 219., 222., 226.],
           [248., 243., 249.,  ..., 218., 226., 231.]],

          [[119., 170., 189.,  ...,  71.,  73.,  95.],
           [121., 173., 197.,  ...,  57.,  64.,  88.],
           [118., 169., 196.,  ...,  52.,  67.,  93.],
           ...,
           [117., 108., 100.,  ..., 146., 137., 137.],
           [122., 111., 113.,  ..., 140., 143., 146.],
           [124., 115., 124.,  ..., 143., 149., 150.]]]]])}
Given groups=1, weight of size [256, 512, 3, 3], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[2.46000000e+002, 2.52000000e+002, 2.49000000e+002 ... 2.52000000e+002, 2.50000000e+002, 2.54000000e+002],
    [2.44000000e+002, 2.53000000e+002, 2.53000000e+002 ... 2.50000000e+002, 2.49000000e+002, 2.53000000e+002],
    [2.37000000e+002, 2.51000000e+002, 2.55000000e+002 ... 2.51000000e+002, 2.51000000e+002, 2.55000000e+002],
    ...
    [5.00000000e+001, 4.60000000e+001, 9.30000000e+001 ... 2.46000000e+002, 2.44000000e+002, 2.51000000e+002],
    [6.10000000e+001, 5.80000000e+001, 1.03000000e+002 ... 2.41000000e+002, 2.45000000e+002, 2.47000000e+002],
    [8.00000000e+001, 8.10000000e+001, 1.20000000e+002 ... 2.44000000e+002, 2.45000000e+002, 2.43000000e+002]],
   [[2.54000000e+002, 2.50000000e+002, 2.52000000e+002 ... 2.50000000e+002, 2.51000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.49000000e+002, 2.48000000e+002 ... 2.51000000e+002, 2.50000000e+002, 2.54000000e+002],
    [2.55000000e+002, 2.51000000e+002, 2.49000000e+002 ... 2.52000000e+002, 2.53000000e+002, 2.55000000e+002],
    ...
    [2.46000000e+002, 2.39000000e+002, 2.47000000e+002 ... 2.29000000e+002, 2.15000000e+002, 2.14000000e+002],
    [2.47000000e+002, 2.39000000e+002, 2.48000000e+002 ... 2.19000000e+002, 2.22000000e+002, 2.26000000e+002],
    [2.48000000e+002, 2.43000000e+002, 2.49000000e+002 ... 2.18000000e+002, 2.26000000e+002, 2.31000000e+002]],
   [[1.19000000e+002, 1.70000000e+002, 1.89000000e+002 ... 7.10000000e+001, 7.30000000e+001, 9.50000000e+001],
    [1.21000000e+002, 1.73000000e+002, 1.97000000e+002 ... 5.70000000e+001, 6.40000000e+001, 8.80000000e+001],
    [1.18000000e+002, 1.69000000e+002, 1.96000000e+002 ... 5.20000000e+001, 6.70000000e+001, 9.30000000e+001],
    ...
    [1.17000000e+002, 1.08000000e+002, 1.00000000e+002 ... 1.46000000e+002, 1.37000000e+002, 1.37000000e+002],
    [1.22000000e+002, 1.11000000e+002, 1.13000000e+002 ... 1.40000000e+002, 1.43000000e+002, 1.46000000e+002],
    [1.24000000e+002, 1.15000000e+002, 1.24000000e+002 ... 1.43000000e+002, 1.49000000e+002, 1.50000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:81

analyse the exceptions in iter:96
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[106., 107., 108.,  ..., 125., 122., 100.],
           [107., 108., 108.,  ..., 134., 118.,  74.],
           [106., 107., 107.,  ..., 130., 106.,  72.],
           ...,
           [ 97.,  93.,  82.,  ...,  94.,  95.,  99.],
           [ 99.,  82.,  73.,  ...,  91.,  89.,  93.],
           [ 95.,  89.,  76.,  ...,  91.,  88.,  82.]],

          [[109., 110., 113.,  ..., 160., 153., 124.],
           [110., 111., 113.,  ..., 165., 144.,  92.],
           [108., 109., 112.,  ..., 154., 125.,  85.],
           ...,
           [ 86.,  82.,  74.,  ..., 101., 102., 106.],
           [ 87.,  74.,  66.,  ...,  98.,  97., 103.],
           [ 84.,  81.,  69.,  ...,  98.,  96.,  95.]],

          [[116., 117., 119.,  ..., 201., 191., 146.],
           [117., 118., 119.,  ..., 203., 171.,  92.],
           [115., 116., 118.,  ..., 181., 141.,  83.],
           ...,
           [ 72.,  65.,  61.,  ...,  59.,  59.,  62.],
           [ 72.,  61.,  55.,  ...,  54.,  55.,  58.],
           [ 71.,  68.,  56.,  ...,  54.,  53.,  52.]]]]])}
Given groups=1, weight of size [64, 64, 3, 3], expected input[1, 3, 32, 32] to have 64 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.06000000e+002, 1.07000000e+002, 1.08000000e+002 ... 1.25000000e+002, 1.22000000e+002, 1.00000000e+002],
    [1.07000000e+002, 1.08000000e+002, 1.08000000e+002 ... 1.34000000e+002, 1.18000000e+002, 7.40000000e+001],
    [1.06000000e+002, 1.07000000e+002, 1.07000000e+002 ... 1.30000000e+002, 1.06000000e+002, 7.20000000e+001],
    ...
    [9.70000000e+001, 9.30000000e+001, 8.20000000e+001 ... 9.40000000e+001, 9.50000000e+001, 9.90000000e+001],
    [9.90000000e+001, 8.20000000e+001, 7.30000000e+001 ... 9.10000000e+001, 8.90000000e+001, 9.30000000e+001],
    [9.50000000e+001, 8.90000000e+001, 7.60000000e+001 ... 9.10000000e+001, 8.80000000e+001, 8.20000000e+001]],
   [[1.09000000e+002, 1.10000000e+002, 1.13000000e+002 ... 1.60000000e+002, 1.53000000e+002, 1.24000000e+002],
    [1.10000000e+002, 1.11000000e+002, 1.13000000e+002 ... 1.65000000e+002, 1.44000000e+002, 9.20000000e+001],
    [1.08000000e+002, 1.09000000e+002, 1.12000000e+002 ... 1.54000000e+002, 1.25000000e+002, 8.50000000e+001],
    ...
    [8.60000000e+001, 8.20000000e+001, 7.40000000e+001 ... 1.01000000e+002, 1.02000000e+002, 1.06000000e+002],
    [8.70000000e+001, 7.40000000e+001, 6.60000000e+001 ... 9.80000000e+001, 9.70000000e+001, 1.03000000e+002],
    [8.40000000e+001, 8.10000000e+001, 6.90000000e+001 ... 9.80000000e+001, 9.60000000e+001, 9.50000000e+001]],
   [[1.16000000e+002, 1.17000000e+002, 1.19000000e+002 ... 2.01000000e+002, 1.91000000e+002, 1.46000000e+002],
    [1.17000000e+002, 1.18000000e+002, 1.19000000e+002 ... 2.03000000e+002, 1.71000000e+002, 9.20000000e+001],
    [1.15000000e+002, 1.16000000e+002, 1.18000000e+002 ... 1.81000000e+002, 1.41000000e+002, 8.30000000e+001],
    ...
    [7.20000000e+001, 6.50000000e+001, 6.10000000e+001 ... 5.90000000e+001, 5.90000000e+001, 6.20000000e+001],
    [7.20000000e+001, 6.10000000e+001, 5.50000000e+001 ... 5.40000000e+001, 5.50000000e+001, 5.80000000e+001],
    [7.10000000e+001, 6.80000000e+001, 5.60000000e+001 ... 5.40000000e+001, 5.30000000e+001, 5.20000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 64, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:82

analyse output arrays in iter:99

pre layer res:
5:dropout
{'name': 'dropout', 'output': array([[[[141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         ...,
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.]],

        [[141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         ...,
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.]],

        [[141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         ...,
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.],
         [141432., 141432., 141432., ..., 141432., 141432., 141432.]],

        ...,

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         ...,
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         ...,
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         ...,
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]]]],
      dtype=float32), 'output_shape': TensorShape([1, 512, 16, 100]), 'from': [4], 'to': [10]}
tf node:
{'name': 'cos', 'output': array([[[[-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         ...,
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998]],

        [[-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         ...,
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998]],

        [[-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         ...,
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998],
         [-0.8018998, -0.8018998, -0.8018998, ..., -0.8018998,
          -0.8018998, -0.8018998]],

        ...,

        [[ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         ...,
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ]],

        [[ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         ...,
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ]],

        [[ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         ...,
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ],
         [ 1.       ,  1.       ,  1.       , ...,  1.       ,
           1.       ,  1.       ]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 100]), 'from': [5], 'to': [6]}
ms node:
{'name': 'cos', 'output': array([[[[0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         ...,
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646]],

        [[0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         ...,
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646]],

        [[0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         ...,
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646]],

        ...,

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]]]], dtype=float32), 'output_shape': (1, 512, 16, 100), 'from': [5], 'to': [6]}
torch node:
{'name': 'cos', 'output': array([[[[0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         ...,
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646]],

        [[0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         ...,
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646]],

        [[0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         ...,
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646],
         [0.20089646, 0.20089646, 0.20089646, ..., 0.20089646,
          0.20089646, 0.20089646]],

        ...,

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 100]), 'from': [5], 'to': [6]}

generate models:85

final statics:
total operators:28
tensorflow --> nums:6,distinct_bugs:2
mindspore --> nums:13,distinct_bugs:4
torch --> nums:12,distinct_bugs:3
tensorflow --> 
cos:3
conv2d:3
mindspore --> 
conv2d:7
linear:4
log:1
cos:1
torch --> 
conv2d:7
linear:4
cos:1

generate models:85

analyse output arrays in iter:101

pre layer res:
3:flatten
{'name': 'flatten', 'output': array([[-0.6256894 , -0.0589503 , -3.1572227 ,  2.788826  , -3.0226765 ,
         0.2797209 , -3.2291002 , -3.1207452 ,  3.3804073 ,  4.506706  ,
         0.49285114, -5.058323  ,  0.7725512 ,  6.2694483 , -1.6292851 ,
        -0.95236135,  1.4261798 ,  1.5687133 ,  1.5145221 ,  1.9281433 ,
         2.7220867 ,  3.7762315 , -1.7737021 , -0.2998538 ,  2.2682786 ,
         2.5712776 ,  5.3956265 , -0.07501888,  0.8515316 , -0.38239193,
        -0.13680089,  4.800723  ,  3.8400526 , -1.1220657 ,  3.378046  ,
         1.3551297 ,  3.3456478 ,  2.1345725 , -0.6969445 , -1.497095  ,
         1.035939  ,  1.0501219 ,  2.2558184 , -3.480681  , -0.70242774,
         3.915829  , -1.474335  , -0.6954902 ]], dtype=float32), 'output_shape': TensorShape([1, 48]), 'from': [2], 'to': [7]}
tf node:
{'name': 'log', 'output': array([[        nan,         nan,         nan,  1.0256207 ,         nan,
        -1.273963  ,         nan,         nan,  1.2179962 ,  1.5055666 ,
        -0.7075481 ,         nan, -0.25805703,  1.8356884 ,         nan,
                nan,  0.35499936,  0.45025575,  0.41509992,  0.6565575 ,
         1.0013988 ,  1.3287265 ,         nan,         nan,  0.8190212 ,
         0.94440293,  1.6855887 ,         nan, -0.16071863,         nan,
                nan,  1.5687666 ,  1.345486  ,         nan,  1.2172974 ,
         0.30389717,  1.2076603 ,  0.7582664 ,         nan,         nan,
         0.03530824,  0.04890626,  0.8135128 ,         nan,         nan,
         1.3650271 ,         nan,         nan]], dtype=float32), 'output_shape': TensorShape([1, 48]), 'from': [3], 'to': [4]}
ms node:
{'name': 'log', 'output': array([[        nan,         nan,         nan,  1.0256234 ,         nan,
        -1.2739627 ,         nan,         nan,  1.2179929 ,  1.5055633 ,
        -0.7075495 ,         nan, -0.2580594 ,  1.835686  ,         nan,
                nan,  0.35500214,  0.4502531 ,  0.4150977 ,  0.6565577 ,
         1.0013969 ,  1.3287265 ,         nan,         nan,  0.81901824,
         0.9444056 ,  1.6855867 ,         nan, -0.16072172,         nan,
                nan,  1.568765  ,  1.345486  ,         nan,  1.2172942 ,
         0.30389544,  1.2076571 ,  0.7582634 ,         nan,         nan,
         0.03531154,  0.04890921,  0.8135096 ,         nan,         nan,
         1.3650255 ,         nan,         nan]], dtype=float32), 'output_shape': (1, 48), 'from': [3], 'to': [4]}
torch node:
{'name': 'log', 'output': array([[        nan,         nan,         nan,  1.0256206 ,         nan,
        -1.2739625 ,         nan,         nan,  1.2179961 ,  1.5055664 ,
        -0.70754784,         nan, -0.25805733,  1.8356884 ,         nan,
                nan,  0.35499945,  0.4502555 ,  0.41509977,  0.6565577 ,
         1.0013987 ,  1.3287264 ,         nan,         nan,  0.8190215 ,
         0.9444028 ,  1.6855886 ,         nan, -0.16071822,         nan,
                nan,  1.5687666 ,  1.345486  ,         nan,  1.2172974 ,
         0.30389726,  1.2076602 ,  0.75826615,         nan,         nan,
         0.03530824,  0.04890592,  0.8135129 ,         nan,         nan,
         1.365027  ,         nan,         nan]], dtype=float32), 'output_shape': torch.Size([1, 48]), 'from': [3], 'to': [4]}

generate models:86

analyse the exceptions in iter:104
torch exception:
{'id': 4, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])]}
Given groups=1, weight of size [64, 256, 3, 3], expected input[1, 16, 28, 28] to have 256 channels, but got 16 channels instead
mindspore exception:
{'id': 4, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 16, 28, 28], dtype=Float32, value=
[[[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  ...
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 16, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:89

analyse the exceptions in iter:105
torch exception:
{'id': 0, 'name': 'linear', 'frame_work': 'torch', 'input_datas': tensor([[[[[254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           ...,
           [254., 253., 253.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.]],

          [[254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           ...,
           [254., 253., 253.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.]],

          [[254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           ...,
           [254., 253., 253.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.],
           [254., 254., 254.,  ..., 254., 254., 254.]]]]])}
mat1 and mat2 shapes cannot be multiplied (96x32 and 100x100)
mindspore exception:
{'id': 0, 'name': 'linear', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    ...
    [2.54000000e+002, 2.53000000e+002, 2.53000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002]],
   [[2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    ...
    [2.54000000e+002, 2.53000000e+002, 2.53000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002]],
   [[2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    ...
    [2.54000000e+002, 2.53000000e+002, 2.53000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002],
    [2.54000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.54000000e+002]]]]])}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 100. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 100](transpose_b=True).

generate models:90

analyse the exceptions in iter:108
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[198., 198., 193.,  ..., 189., 188., 187.],
           [191., 190., 202.,  ..., 193., 192., 191.],
           [184., 178., 193.,  ..., 192., 191., 190.],
           ...,
           [209., 209., 209.,  ..., 193., 192., 191.],
           [211., 207., 209.,  ..., 192., 189., 189.],
           [210., 208., 210.,  ..., 192., 189., 188.]],

          [[193., 191., 190.,  ..., 187., 186., 185.],
           [181., 175., 187.,  ..., 191., 190., 189.],
           [165., 150., 163.,  ..., 190., 189., 188.],
           ...,
           [207., 207., 207.,  ..., 191., 190., 189.],
           [209., 205., 206.,  ..., 190., 187., 187.],
           [208., 206., 207.,  ..., 190., 187., 186.]],

          [[196., 193., 194.,  ..., 192., 191., 190.],
           [185., 174., 185.,  ..., 196., 195., 194.],
           [162., 141., 151.,  ..., 195., 194., 193.],
           ...,
           [212., 211., 209.,  ..., 196., 195., 194.],
           [214., 210., 212.,  ..., 195., 192., 192.],
           [213., 212., 214.,  ..., 195., 192., 191.]]]]])}
Given groups=1, weight of size [512, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.98000000e+002, 1.98000000e+002, 1.93000000e+002 ... 1.89000000e+002, 1.88000000e+002, 1.87000000e+002],
    [1.91000000e+002, 1.90000000e+002, 2.02000000e+002 ... 1.93000000e+002, 1.92000000e+002, 1.91000000e+002],
    [1.84000000e+002, 1.78000000e+002, 1.93000000e+002 ... 1.92000000e+002, 1.91000000e+002, 1.90000000e+002],
    ...
    [2.09000000e+002, 2.09000000e+002, 2.09000000e+002 ... 1.93000000e+002, 1.92000000e+002, 1.91000000e+002],
    [2.11000000e+002, 2.07000000e+002, 2.09000000e+002 ... 1.92000000e+002, 1.89000000e+002, 1.89000000e+002],
    [2.10000000e+002, 2.08000000e+002, 2.10000000e+002 ... 1.92000000e+002, 1.89000000e+002, 1.88000000e+002]],
   [[1.93000000e+002, 1.91000000e+002, 1.90000000e+002 ... 1.87000000e+002, 1.86000000e+002, 1.85000000e+002],
    [1.81000000e+002, 1.75000000e+002, 1.87000000e+002 ... 1.91000000e+002, 1.90000000e+002, 1.89000000e+002],
    [1.65000000e+002, 1.50000000e+002, 1.63000000e+002 ... 1.90000000e+002, 1.89000000e+002, 1.88000000e+002],
    ...
    [2.07000000e+002, 2.07000000e+002, 2.07000000e+002 ... 1.91000000e+002, 1.90000000e+002, 1.89000000e+002],
    [2.09000000e+002, 2.05000000e+002, 2.06000000e+002 ... 1.90000000e+002, 1.87000000e+002, 1.87000000e+002],
    [2.08000000e+002, 2.06000000e+002, 2.07000000e+002 ... 1.90000000e+002, 1.87000000e+002, 1.86000000e+002]],
   [[1.96000000e+002, 1.93000000e+002, 1.94000000e+002 ... 1.92000000e+002, 1.91000000e+002, 1.90000000e+002],
    [1.85000000e+002, 1.74000000e+002, 1.85000000e+002 ... 1.96000000e+002, 1.95000000e+002, 1.94000000e+002],
    [1.62000000e+002, 1.41000000e+002, 1.51000000e+002 ... 1.95000000e+002, 1.94000000e+002, 1.93000000e+002],
    ...
    [2.12000000e+002, 2.11000000e+002, 2.09000000e+002 ... 1.96000000e+002, 1.95000000e+002, 1.94000000e+002],
    [2.14000000e+002, 2.10000000e+002, 2.12000000e+002 ... 1.95000000e+002, 1.92000000e+002, 1.92000000e+002],
    [2.13000000e+002, 2.12000000e+002, 2.14000000e+002 ... 1.95000000e+002, 1.92000000e+002, 1.91000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:93

analyse the exceptions in iter:118
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[185., 182., 228.,  ..., 252., 248., 245.],
           [212., 199., 208.,  ..., 250., 242., 242.],
           [191., 191., 190.,  ..., 242., 234., 238.],
           ...,
           [248., 252., 252.,  ..., 254., 253., 253.],
           [246., 250., 254.,  ..., 254., 253., 252.],
           [250., 251., 253.,  ..., 252., 251., 250.]],

          [[185., 180., 226.,  ..., 254., 252., 250.],
           [213., 197., 207.,  ..., 250., 243., 245.],
           [192., 189., 190.,  ..., 241., 233., 240.],
           ...,
           [252., 252., 250.,  ..., 251., 251., 251.],
           [250., 251., 253.,  ..., 251., 252., 249.],
           [251., 251., 252.,  ..., 249., 250., 248.]],

          [[225., 225., 246.,  ..., 255., 254., 252.],
           [248., 240., 235.,  ..., 254., 252., 252.],
           [230., 236., 224.,  ..., 251., 250., 253.],
           ...,
           [241., 240., 238.,  ..., 231., 226., 223.],
           [239., 239., 241.,  ..., 231., 227., 221.],
           [242., 241., 240.,  ..., 230., 225., 220.]]]]])}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.85000000e+002, 1.82000000e+002, 2.28000000e+002 ... 2.52000000e+002, 2.48000000e+002, 2.45000000e+002],
    [2.12000000e+002, 1.99000000e+002, 2.08000000e+002 ... 2.50000000e+002, 2.42000000e+002, 2.42000000e+002],
    [1.91000000e+002, 1.91000000e+002, 1.90000000e+002 ... 2.42000000e+002, 2.34000000e+002, 2.38000000e+002],
    ...
    [2.48000000e+002, 2.52000000e+002, 2.52000000e+002 ... 2.54000000e+002, 2.53000000e+002, 2.53000000e+002],
    [2.46000000e+002, 2.50000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.53000000e+002, 2.52000000e+002],
    [2.50000000e+002, 2.51000000e+002, 2.53000000e+002 ... 2.52000000e+002, 2.51000000e+002, 2.50000000e+002]],
   [[1.85000000e+002, 1.80000000e+002, 2.26000000e+002 ... 2.54000000e+002, 2.52000000e+002, 2.50000000e+002],
    [2.13000000e+002, 1.97000000e+002, 2.07000000e+002 ... 2.50000000e+002, 2.43000000e+002, 2.45000000e+002],
    [1.92000000e+002, 1.89000000e+002, 1.90000000e+002 ... 2.41000000e+002, 2.33000000e+002, 2.40000000e+002],
    ...
    [2.52000000e+002, 2.52000000e+002, 2.50000000e+002 ... 2.51000000e+002, 2.51000000e+002, 2.51000000e+002],
    [2.50000000e+002, 2.51000000e+002, 2.53000000e+002 ... 2.51000000e+002, 2.52000000e+002, 2.49000000e+002],
    [2.51000000e+002, 2.51000000e+002, 2.52000000e+002 ... 2.49000000e+002, 2.50000000e+002, 2.48000000e+002]],
   [[2.25000000e+002, 2.25000000e+002, 2.46000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.52000000e+002],
    [2.48000000e+002, 2.40000000e+002, 2.35000000e+002 ... 2.54000000e+002, 2.52000000e+002, 2.52000000e+002],
    [2.30000000e+002, 2.36000000e+002, 2.24000000e+002 ... 2.51000000e+002, 2.50000000e+002, 2.53000000e+002],
    ...
    [2.41000000e+002, 2.40000000e+002, 2.38000000e+002 ... 2.31000000e+002, 2.26000000e+002, 2.23000000e+002],
    [2.39000000e+002, 2.39000000e+002, 2.41000000e+002 ... 2.31000000e+002, 2.27000000e+002, 2.21000000e+002],
    [2.42000000e+002, 2.41000000e+002, 2.40000000e+002 ... 2.30000000e+002, 2.25000000e+002, 2.20000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:100

analyse the exceptions in iter:119
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[239., 238., 237.,  ..., 132., 151., 155.],
          [234., 238., 238.,  ..., 131., 149., 153.],
          [231., 236., 239.,  ..., 125., 146., 150.],
          ...,
          [213., 212., 198.,  ..., 121., 126., 121.],
          [216., 212., 194.,  ..., 123., 128., 122.],
          [214., 207., 187.,  ..., 123., 127., 123.]],

         [[239., 238., 237.,  ..., 135., 155., 158.],
          [234., 238., 238.,  ..., 134., 153., 156.],
          [231., 236., 239.,  ..., 128., 149., 154.],
          ...,
          [214., 213., 199.,  ..., 125., 132., 126.],
          [217., 213., 195.,  ..., 127., 132., 126.],
          [215., 208., 188.,  ..., 127., 131., 126.]],

         [[239., 238., 237.,  ..., 142., 159., 164.],
          [234., 238., 238.,  ..., 141., 157., 161.],
          [231., 236., 239.,  ..., 135., 153., 159.],
          ...,
          [218., 217., 203.,  ..., 134., 141., 134.],
          [221., 217., 199.,  ..., 136., 141., 135.],
          [219., 212., 192.,  ..., 136., 140., 135.]]]])]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[2.39000000e+002, 2.38000000e+002, 2.37000000e+002 ... 1.32000000e+002, 1.51000000e+002, 1.55000000e+002],
   [2.34000000e+002, 2.38000000e+002, 2.38000000e+002 ... 1.31000000e+002, 1.49000000e+002, 1.53000000e+002],
   [2.31000000e+002, 2.36000000e+002, 2.39000000e+002 ... 1.25000000e+002, 1.46000000e+002, 1.50000000e+002],
   ...
   [2.13000000e+002, 2.12000000e+002, 1.98000000e+002 ... 1.21000000e+002, 1.26000000e+002, 1.21000000e+002],
   [2.16000000e+002, 2.12000000e+002, 1.94000000e+002 ... 1.23000000e+002, 1.28000000e+002, 1.22000000e+002],
   [2.14000000e+002, 2.07000000e+002, 1.87000000e+002 ... 1.23000000e+002, 1.27000000e+002, 1.23000000e+002]],
  [[2.39000000e+002, 2.38000000e+002, 2.37000000e+002 ... 1.35000000e+002, 1.55000000e+002, 1.58000000e+002],
   [2.34000000e+002, 2.38000000e+002, 2.38000000e+002 ... 1.34000000e+002, 1.53000000e+002, 1.56000000e+002],
   [2.31000000e+002, 2.36000000e+002, 2.39000000e+002 ... 1.28000000e+002, 1.49000000e+002, 1.54000000e+002],
   ...
   [2.14000000e+002, 2.13000000e+002, 1.99000000e+002 ... 1.25000000e+002, 1.32000000e+002, 1.26000000e+002],
   [2.17000000e+002, 2.13000000e+002, 1.95000000e+002 ... 1.27000000e+002, 1.32000000e+002, 1.26000000e+002],
   [2.15000000e+002, 2.08000000e+002, 1.88000000e+002 ... 1.27000000e+002, 1.31000000e+002, 1.26000000e+002]],
  [[2.39000000e+002, 2.38000000e+002, 2.37000000e+002 ... 1.42000000e+002, 1.59000000e+002, 1.64000000e+002],
   [2.34000000e+002, 2.38000000e+002, 2.38000000e+002 ... 1.41000000e+002, 1.57000000e+002, 1.61000000e+002],
   [2.31000000e+002, 2.36000000e+002, 2.39000000e+002 ... 1.35000000e+002, 1.53000000e+002, 1.59000000e+002],
   ...
   [2.18000000e+002, 2.17000000e+002, 2.03000000e+002 ... 1.34000000e+002, 1.41000000e+002, 1.34000000e+002],
   [2.21000000e+002, 2.17000000e+002, 1.99000000e+002 ... 1.36000000e+002, 1.41000000e+002, 1.35000000e+002],
   [2.19000000e+002, 2.12000000e+002, 1.92000000e+002 ... 1.36000000e+002, 1.40000000e+002, 1.35000000e+002]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:101

analyse output arrays in iter:121

pre layer res:
4:exp
{'name': 'exp', 'output': array([[[[         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         ...,
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf]],

        [[         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         ...,
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf]],

        [[         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         ...,
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
                   inf,          inf],
         [         inf,          inf,          inf, ...,          inf,
          4.093997e+35,          inf]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [2], 'to': [8]}
tf node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [4], 'to': [5]}
ms node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan,  0., nan]]]], dtype=float32), 'output_shape': (1, 3, 32, 32), 'from': [4], 'to': [5]}
torch node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 3, 32, 32]), 'from': [4], 'to': [5]}

generate models:102

analyse the exceptions in iter:147
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[4800., 4720., 4744.,  ..., 4760., 4496., 3728.],
          [4768., 4688., 4704.,  ..., 3320., 2960., 2128.],
          [4792., 4728., 4760.,  ..., 1944., 2064., 2032.],
          ...,
          [2784., 2736., 2720.,  ..., 2616., 2656., 2744.],
          [2776., 2784., 2752.,  ..., 2712., 2664., 2624.],
          [2864., 2792., 2744.,  ..., 2752., 2784., 3032.]],

         [[   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          ...,
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]],

         [[   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          ...,
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]],

         ...,

         [[   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          ...,
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]],

         [[   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          ...,
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]],

         [[   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          ...,
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],
          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]]]],
       grad_fn=<ReluBackward0>)]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 512, 32, 32] to have 256 channels, but got 512 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 512, 32, 32], dtype=Float32, value=
[[[[4.80000000e+003, 4.72000000e+003, 4.74400000e+003 ... 4.76000000e+003, 4.49600000e+003, 3.72800000e+003],
   [4.76800000e+003, 4.68800000e+003, 4.70400000e+003 ... 3.32000000e+003, 2.96000000e+003, 2.12800000e+003],
   [4.79200000e+003, 4.72800000e+003, 4.76000000e+003 ... 1.94400000e+003, 2.06400000e+003, 2.03200000e+003],
   ...
   [2.78400000e+003, 2.73600000e+003, 2.72000000e+003 ... 2.61600000e+003, 2.65600000e+003, 2.74400000e+003],
   [2.77600000e+003, 2.78400000e+003, 2.75200000e+003 ... 2.71200000e+003, 2.66400000e+003, 2.62400000e+003],
   [2.86400000e+003, 2.79200000e+003, 2.74400000e+003 ... 2.75200000e+003, 2.78400000e+003, 3.03200000e+003]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  ...
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 512, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:123

analyse the exceptions in iter:153
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 50.,  70.,  61.,  ..., 103., 114., 108.],
           [ 50.,  49.,  53.,  ..., 131., 124., 107.],
           [ 57.,  57.,  60.,  ..., 128., 125., 109.],
           ...,
           [117., 120., 125.,  ..., 144., 143., 140.],
           [114., 115., 117.,  ..., 142., 139., 137.],
           [120., 120., 122.,  ..., 142., 141., 135.]],

          [[ 59.,  83.,  71.,  ..., 109., 128., 128.],
           [ 59.,  63.,  64.,  ..., 135., 141., 133.],
           [ 65.,  70.,  71.,  ..., 140., 148., 138.],
           ...,
           [138., 141., 146.,  ..., 190., 190., 181.],
           [135., 136., 138.,  ..., 186., 184., 177.],
           [140., 140., 142.,  ..., 184., 185., 172.]],

          [[ 53.,  75.,  65.,  ..., 110., 130., 134.],
           [ 49.,  51.,  53.,  ..., 134., 143., 141.],
           [ 58.,  61.,  63.,  ..., 141., 150., 146.],
           ...,
           [141., 143., 148.,  ..., 187., 186., 180.],
           [139., 140., 142.,  ..., 184., 181., 175.],
           [147., 147., 149.,  ..., 182., 182., 172.]]]]])}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[5.00000000e+001, 7.00000000e+001, 6.10000000e+001 ... 1.03000000e+002, 1.14000000e+002, 1.08000000e+002],
    [5.00000000e+001, 4.90000000e+001, 5.30000000e+001 ... 1.31000000e+002, 1.24000000e+002, 1.07000000e+002],
    [5.70000000e+001, 5.70000000e+001, 6.00000000e+001 ... 1.28000000e+002, 1.25000000e+002, 1.09000000e+002],
    ...
    [1.17000000e+002, 1.20000000e+002, 1.25000000e+002 ... 1.44000000e+002, 1.43000000e+002, 1.40000000e+002],
    [1.14000000e+002, 1.15000000e+002, 1.17000000e+002 ... 1.42000000e+002, 1.39000000e+002, 1.37000000e+002],
    [1.20000000e+002, 1.20000000e+002, 1.22000000e+002 ... 1.42000000e+002, 1.41000000e+002, 1.35000000e+002]],
   [[5.90000000e+001, 8.30000000e+001, 7.10000000e+001 ... 1.09000000e+002, 1.28000000e+002, 1.28000000e+002],
    [5.90000000e+001, 6.30000000e+001, 6.40000000e+001 ... 1.35000000e+002, 1.41000000e+002, 1.33000000e+002],
    [6.50000000e+001, 7.00000000e+001, 7.10000000e+001 ... 1.40000000e+002, 1.48000000e+002, 1.38000000e+002],
    ...
    [1.38000000e+002, 1.41000000e+002, 1.46000000e+002 ... 1.90000000e+002, 1.90000000e+002, 1.81000000e+002],
    [1.35000000e+002, 1.36000000e+002, 1.38000000e+002 ... 1.86000000e+002, 1.84000000e+002, 1.77000000e+002],
    [1.40000000e+002, 1.40000000e+002, 1.42000000e+002 ... 1.84000000e+002, 1.85000000e+002, 1.72000000e+002]],
   [[5.30000000e+001, 7.50000000e+001, 6.50000000e+001 ... 1.10000000e+002, 1.30000000e+002, 1.34000000e+002],
    [4.90000000e+001, 5.10000000e+001, 5.30000000e+001 ... 1.34000000e+002, 1.43000000e+002, 1.41000000e+002],
    [5.80000000e+001, 6.10000000e+001, 6.30000000e+001 ... 1.41000000e+002, 1.50000000e+002, 1.46000000e+002],
    ...
    [1.41000000e+002, 1.43000000e+002, 1.48000000e+002 ... 1.87000000e+002, 1.86000000e+002, 1.80000000e+002],
    [1.39000000e+002, 1.40000000e+002, 1.42000000e+002 ... 1.84000000e+002, 1.81000000e+002, 1.75000000e+002],
    [1.47000000e+002, 1.47000000e+002, 1.49000000e+002 ... 1.82000000e+002, 1.82000000e+002, 1.72000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:128

analyse output arrays in iter:165

pre layer res:
4:relu
{'name': 'relu', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 100]), 'from': [16], 'to': [10]}
tf node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]],

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]],

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 100]), 'from': [4], 'to': [6]}
ms node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]],

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]],

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]]]], dtype=float32), 'output_shape': (1, 512, 32, 100), 'from': [4], 'to': [6]}
torch node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]],

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]],

        [[ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         ...,
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.],
         [ 1.,  1.,  1., ...,  1.,  1.,  1.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 100]), 'from': [4], 'to': [6]}

generate models:137

analyse the exceptions in iter:168
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[163., 171., 164.,  ...,  17.,  13.,  31.],
           [247., 243., 246.,  ...,  17.,  13.,  24.],
           [242., 235., 248.,  ...,  17.,  13.,  21.],
           ...,
           [ 67.,  51.,  49.,  ...,  91., 101., 114.],
           [ 78.,  67.,  65.,  ..., 110., 116., 114.],
           [ 95.,  97.,  94.,  ..., 126., 129., 131.]],

          [[152., 159., 156.,  ...,  18.,  18.,  32.],
           [237., 231., 240.,  ...,  18.,  18.,  26.],
           [233., 223., 242.,  ...,  19.,  17.,  23.],
           ...,
           [ 66.,  50.,  48.,  ...,  67.,  79.,  94.],
           [ 79.,  68.,  66.,  ...,  83.,  90.,  91.],
           [ 97.,  99.,  96.,  ...,  97., 102., 106.]],

          [[143., 150., 150.,  ...,  20.,  20.,  29.],
           [236., 229., 241.,  ...,  20.,  19.,  22.],
           [232., 221., 243.,  ...,  20.,  19.,  19.],
           ...,
           [ 72.,  56.,  54.,  ...,  50.,  61.,  75.],
           [ 84.,  73.,  71.,  ...,  62.,  69.,  69.],
           [104., 106., 102.,  ...,  74.,  78.,  82.]]]]])}
Given groups=1, weight of size [64, 128, 1, 1], expected input[1, 3, 32, 32] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.63000000e+002, 1.71000000e+002, 1.64000000e+002 ... 1.70000000e+001, 1.30000000e+001, 3.10000000e+001],
    [2.47000000e+002, 2.43000000e+002, 2.46000000e+002 ... 1.70000000e+001, 1.30000000e+001, 2.40000000e+001],
    [2.42000000e+002, 2.35000000e+002, 2.48000000e+002 ... 1.70000000e+001, 1.30000000e+001, 2.10000000e+001],
    ...
    [6.70000000e+001, 5.10000000e+001, 4.90000000e+001 ... 9.10000000e+001, 1.01000000e+002, 1.14000000e+002],
    [7.80000000e+001, 6.70000000e+001, 6.50000000e+001 ... 1.10000000e+002, 1.16000000e+002, 1.14000000e+002],
    [9.50000000e+001, 9.70000000e+001, 9.40000000e+001 ... 1.26000000e+002, 1.29000000e+002, 1.31000000e+002]],
   [[1.52000000e+002, 1.59000000e+002, 1.56000000e+002 ... 1.80000000e+001, 1.80000000e+001, 3.20000000e+001],
    [2.37000000e+002, 2.31000000e+002, 2.40000000e+002 ... 1.80000000e+001, 1.80000000e+001, 2.60000000e+001],
    [2.33000000e+002, 2.23000000e+002, 2.42000000e+002 ... 1.90000000e+001, 1.70000000e+001, 2.30000000e+001],
    ...
    [6.60000000e+001, 5.00000000e+001, 4.80000000e+001 ... 6.70000000e+001, 7.90000000e+001, 9.40000000e+001],
    [7.90000000e+001, 6.80000000e+001, 6.60000000e+001 ... 8.30000000e+001, 9.00000000e+001, 9.10000000e+001],
    [9.70000000e+001, 9.90000000e+001, 9.60000000e+001 ... 9.70000000e+001, 1.02000000e+002, 1.06000000e+002]],
   [[1.43000000e+002, 1.50000000e+002, 1.50000000e+002 ... 2.00000000e+001, 2.00000000e+001, 2.90000000e+001],
    [2.36000000e+002, 2.29000000e+002, 2.41000000e+002 ... 2.00000000e+001, 1.90000000e+001, 2.20000000e+001],
    [2.32000000e+002, 2.21000000e+002, 2.43000000e+002 ... 2.00000000e+001, 1.90000000e+001, 1.90000000e+001],
    ...
    [7.20000000e+001, 5.60000000e+001, 5.40000000e+001 ... 5.00000000e+001, 6.10000000e+001, 7.50000000e+001],
    [8.40000000e+001, 7.30000000e+001, 7.10000000e+001 ... 6.20000000e+001, 6.90000000e+001, 6.90000000e+001],
    [1.04000000e+002, 1.06000000e+002, 1.02000000e+002 ... 7.40000000e+001, 7.80000000e+001, 8.20000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:140

analyse output arrays in iter:171

pre layer res:
5:transpose
{'name': 'transpose', 'output': array([[[[           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 9.25378162e+29,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf, 3.02507734e+36, 1.73927498e+18,
          4.72783953e+18,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf, 1.65163627e+38, 4.72783953e+18,
          2.90488498e+13, 4.31123180e+15,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 1.04137590e+23,
          4.31123180e+15, 1.44625710e+12,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 3.10429778e+26,
          5.18470546e+21, 2.90488498e+13, 6.39843474e+17,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf, 3.02507734e+36, 2.29378327e+27,
          4.60718655e+28, 9.25378162e+29, 1.14200740e+26,
          1.58601345e+15, 1.06864742e+13, 5.54062248e+34,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
          3.73324224e+32,            inf,            inf,
          1.11286373e+36, 1.25236328e+29, 1.40934904e+22,
          1.95729621e+11, 2.41549520e+07, 4.60718655e+28,
                     inf]],

        [[           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 4.20121045e+25,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 5.18470546e+21,
          1.73927498e+18,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 9.49611953e+19,
          7.89629653e+13, 1.58601345e+15,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 7.69478547e+23,
          1.17191425e+16, 5.32048216e+11,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 1.25236328e+29,
          7.69478547e+23, 2.14643591e+14, 1.73927498e+18,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 9.25378162e+29,
          1.85867171e+31, 1.01480034e+33, 1.25236328e+29,
          2.35385253e+17, 7.89629653e+13, 1.50609736e+35,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
          3.02507734e+36,            inf,            inf,
                     inf, 2.75851355e+33, 1.54553889e+25,
          7.89629653e+13, 4.85165216e+08, 3.40427617e+29,
                     inf]],

        [[           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 6.83767114e+30,
                     inf,            inf,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 4.20121045e+25,
          1.28515999e+19,            inf,            inf,
                     inf],
         [8.22301239e+36,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 1.54553889e+25,
          4.31123180e+15, 1.17191425e+16,            inf,
                     inf],
         [6.07603035e+37,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 2.51543870e+30,
          4.72783953e+18, 1.58601345e+15,            inf,
                     inf],
         [           inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 1.11286373e+36,
          4.60718655e+28, 6.39843474e+17, 2.58131289e+20,
                     inf],
         [2.03828115e+34, 2.75851355e+33, 3.02507734e+36,
                     inf,            inf,            inf,
                     inf,            inf, 4.09399685e+35,
          8.22301239e+36,            inf, 1.50609736e+35,
          5.18470546e+21, 1.17191425e+16, 4.09399685e+35,
                     inf],
         [1.37338306e+32, 1.50609736e+35,            inf,
                     inf,            inf,            inf,
                     inf,            inf,            inf,
                     inf,            inf, 9.25378162e+29,
          8.65934040e+16, 9.74480282e+09, 1.25236328e+29,
                     inf]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 16, 16]), 'from': [2], 'to': [7]}
tf node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan]],

        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan]],

        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 16, 16]), 'from': [5], 'to': [4]}
ms node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,  0.,
           0., nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,  0.,
           0.,  0., nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0., nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0.,  0., nan],
         [nan, nan, nan, nan, nan, nan, nan,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0., nan],
         [nan, nan, nan, nan, nan, nan,  0., nan, nan,  0.,  0.,  0.,
           0.,  0.,  0., nan]],

        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0., nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0., nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0., nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0.,  0., nan],
         [nan, nan, nan, nan, nan, nan, nan, nan,  0.,  0.,  0.,  0.,
           0.,  0.,  0., nan],
         [nan, nan, nan, nan, nan, nan,  0., nan, nan, nan,  0.,  0.,
           0.,  0.,  0., nan]],

        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0., nan, nan, nan],
         [ 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0., nan, nan],
         [ 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0., nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0.,  0., nan],
         [ 0.,  0.,  0., nan, nan, nan, nan, nan,  0.,  0., nan,  0.,
           0.,  0.,  0., nan],
         [ 0.,  0., nan, nan, nan, nan, nan, nan, nan, nan, nan,  0.,
           0.,  0.,  0., nan]]]], dtype=float32), 'output_shape': (1, 3, 16, 16), 'from': [5], 'to': [4]}
torch node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan]],

        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan]],

        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 3, 16, 16]), 'from': [5], 'to': [4]}

generate models:142

analyse output arrays in iter:172

pre layer res:
21:cos
{'name': 'cos', 'output': array([[[[ 0.98111135, -0.58418435,  0.36731938, ..., -0.4948984 ,
          -0.4948984 , -0.99859166],
         [-0.99859166, -0.4948984 ,  0.46380216, ...,  0.6125721 ,
          -0.33413696, -0.973642  ],
         [-0.973642  , -0.973642  , -0.973642  , ..., -0.35907242,
           0.07516615, -0.97752696],
         ...,
         [-0.99964744, -0.7361927 , -0.7361927 , ...,  0.9933904 ,
           0.39185724,  0.44014302],
         [ 0.92175126, -0.7361927 ,  0.44014302, ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 100]), 'from': [10], 'to': [22]}
tf node:
{'name': 'log', 'output': array([[[[-0.01906932,         nan, -1.0015236 , ...,         nan,
                  nan,         nan],
         [        nan,         nan, -0.7682972 , ..., -0.49008867,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
          -2.5880542 ,         nan],
         ...,
         [        nan,         nan,         nan, ..., -0.00663156,
          -0.9368577 , -0.8206556 ],
         [-0.08147987,         nan, -0.8206556 , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 100]), 'from': [21], 'to': [7]}
ms node:
{'name': 'log', 'output': array([[[[-1.9070752e-02,            nan, -1.0015236e+00, ...,
                     nan,            nan,            nan],
         [           nan,            nan, -7.6829720e-01, ...,
          -4.9008787e-01,            nan,            nan],
         [           nan,            nan,            nan, ...,
                     nan, -2.5880558e+00,            nan],
         ...,
         [           nan,            nan,            nan, ...,
          -6.6329897e-03, -9.3686008e-01, -8.2065654e-01],
         [-8.1480861e-02,            nan, -8.2065654e-01, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]]]],
      dtype=float32), 'output_shape': (1, 3, 32, 100), 'from': [21], 'to': [7]}
torch node:
{'name': 'log', 'output': array([[[[-0.01906932,         nan, -1.0015236 , ...,         nan,
                  nan,         nan],
         [        nan,         nan, -0.7682972 , ..., -0.49008867,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
          -2.5880542 ,         nan],
         ...,
         [        nan,         nan,         nan, ..., -0.00663156,
          -0.9368577 , -0.8206556 ],
         [-0.08147988,         nan, -0.8206556 , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 3, 32, 100]), 'from': [21], 'to': [7]}

generate models:143

analyse the exceptions in iter:178
torch exception:
{'id': 0, 'name': 'linear', 'frame_work': 'torch', 'input_datas': tensor([[[[[147., 153., 162.,  ..., 177., 163., 134.],
           [139., 142., 153.,  ..., 153., 141., 104.],
           [128., 140., 155.,  ..., 147., 136., 124.],
           ...,
           [140., 111.,  79.,  ..., 116., 123., 129.],
           [134.,  94., 110.,  ...,  90.,  98., 105.],
           [164., 153., 165.,  ..., 111., 104.,  97.]],

          [[122., 125., 136.,  ..., 176., 162., 133.],
           [121., 117., 127.,  ..., 151., 140., 104.],
           [113., 117., 129.,  ..., 143., 134., 121.],
           ...,
           [133., 110.,  81.,  ..., 117., 116., 120.],
           [125.,  92., 110.,  ...,  95., 100., 106.],
           [143., 137., 150.,  ..., 116., 111., 104.]],

          [[ 30.,  43.,  62.,  ..., 155., 138.,  98.],
           [ 43.,  40.,  50.,  ..., 118.,  99.,  52.],
           [ 49.,  44.,  52.,  ..., 110.,  89.,  70.],
           ...,
           [ 53.,  44.,  27.,  ...,  43.,  42.,  48.],
           [ 50.,  29.,  53.,  ...,  27.,  33.,  37.],
           [ 63.,  66.,  82.,  ...,  45.,  39.,  31.]]]]])}
mat1 and mat2 shapes cannot be multiplied (96x32 and 25x100)
mindspore exception:
{'id': 0, 'name': 'linear', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.47000000e+002, 1.53000000e+002, 1.62000000e+002 ... 1.77000000e+002, 1.63000000e+002, 1.34000000e+002],
    [1.39000000e+002, 1.42000000e+002, 1.53000000e+002 ... 1.53000000e+002, 1.41000000e+002, 1.04000000e+002],
    [1.28000000e+002, 1.40000000e+002, 1.55000000e+002 ... 1.47000000e+002, 1.36000000e+002, 1.24000000e+002],
    ...
    [1.40000000e+002, 1.11000000e+002, 7.90000000e+001 ... 1.16000000e+002, 1.23000000e+002, 1.29000000e+002],
    [1.34000000e+002, 9.40000000e+001, 1.10000000e+002 ... 9.00000000e+001, 9.80000000e+001, 1.05000000e+002],
    [1.64000000e+002, 1.53000000e+002, 1.65000000e+002 ... 1.11000000e+002, 1.04000000e+002, 9.70000000e+001]],
   [[1.22000000e+002, 1.25000000e+002, 1.36000000e+002 ... 1.76000000e+002, 1.62000000e+002, 1.33000000e+002],
    [1.21000000e+002, 1.17000000e+002, 1.27000000e+002 ... 1.51000000e+002, 1.40000000e+002, 1.04000000e+002],
    [1.13000000e+002, 1.17000000e+002, 1.29000000e+002 ... 1.43000000e+002, 1.34000000e+002, 1.21000000e+002],
    ...
    [1.33000000e+002, 1.10000000e+002, 8.10000000e+001 ... 1.17000000e+002, 1.16000000e+002, 1.20000000e+002],
    [1.25000000e+002, 9.20000000e+001, 1.10000000e+002 ... 9.50000000e+001, 1.00000000e+002, 1.06000000e+002],
    [1.43000000e+002, 1.37000000e+002, 1.50000000e+002 ... 1.16000000e+002, 1.11000000e+002, 1.04000000e+002]],
   [[3.00000000e+001, 4.30000000e+001, 6.20000000e+001 ... 1.55000000e+002, 1.38000000e+002, 9.80000000e+001],
    [4.30000000e+001, 4.00000000e+001, 5.00000000e+001 ... 1.18000000e+002, 9.90000000e+001, 5.20000000e+001],
    [4.90000000e+001, 4.40000000e+001, 5.20000000e+001 ... 1.10000000e+002, 8.90000000e+001, 7.00000000e+001],
    ...
    [5.30000000e+001, 4.40000000e+001, 2.70000000e+001 ... 4.30000000e+001, 4.20000000e+001, 4.80000000e+001],
    [5.00000000e+001, 2.90000000e+001, 5.30000000e+001 ... 2.70000000e+001, 3.30000000e+001, 3.70000000e+001],
    [6.30000000e+001, 6.60000000e+001, 8.20000000e+001 ... 4.50000000e+001, 3.90000000e+001, 3.10000000e+001]]]]])}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 25. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 25](transpose_b=True).

generate models:148

analyse output arrays in iter:184

pre layer res:
5:log
{'name': 'log', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 16]), 'from': [7], 'to': [4]}
tf node:
{'name': 'maxpool2d', 'output': array([[[[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        ...,

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]]]],
      dtype=float32), 'output_shape': TensorShape([1, 512, 8, 8]), 'from': [5], 'to': []}
ms node:
{'name': 'maxpool2d', 'output': array([[[[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        ...,

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]]]],
      dtype=float32), 'output_shape': (1, 512, 8, 8), 'from': [5], 'to': []}
torch node:
{'name': 'maxpool2d', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 8, 8]), 'from': [5], 'to': []}

generate models:153

analyse the exceptions in iter:186
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[224., 216., 177., 121., 142., 139., 134., 156., 181., 190., 156.,
           152., 178., 109., 197., 195.],
          [177., 207., 186., 177., 111., 100., 124., 152., 107., 141.,  61.,
           134., 174., 130., 158., 172.],
          [163., 165., 207., 187., 142., 151., 176., 174., 149., 195., 188.,
           115., 158., 114., 158., 178.],
          [167., 168., 161., 165., 123.,  80.,  59.,  56.,  43., 125., 103.,
           127., 166., 133., 154., 124.],
          [247., 169., 118., 122.,  83., 109., 113., 104., 129., 200., 165.,
           119., 164., 142., 167., 168.],
          [249., 196., 144., 138., 151., 209., 158., 137., 149., 233., 243.,
            27.,  60., 115., 145., 177.],
          [247., 188., 156., 143., 168., 228., 236., 225., 226., 229., 245.,
            37.,  63.,  47., 124., 178.],
          [211., 162., 147., 149., 158., 227., 238., 234., 221., 235., 234.,
            39.,  61.,  89., 128., 144.],
          [201., 170., 160., 164., 167., 212., 216., 215., 233., 213., 195.,
            62.,  84., 182., 136., 138.],
          [204., 148., 146., 151., 153., 213., 239., 239., 238., 152., 189.,
            92., 100., 134., 157., 155.],
          [182., 170., 164., 141., 169., 198., 233., 229., 215., 140., 183.,
            67.,  98., 140., 163., 176.],
          [176., 171., 165., 164., 167., 194., 197., 205., 186., 191., 173.,
            60.,  75., 164., 188., 196.],
          [150., 136., 136., 140., 145., 158., 163., 169., 166., 185., 157.,
           115.,  63., 133., 194., 191.],
          [147., 131.,  17.,  37.,  45.,  67.,  98.,  61.,  51., 182., 163.,
           167., 178., 189., 195., 195.],
          [105.,  83.,  37.,  26.,  24.,  27.,  28.,  34.,  48., 131., 183.,
           186., 193., 197., 191., 196.],
          [152., 151., 134., 129., 112., 125., 158., 177., 187., 188., 190.,
           195., 198., 203., 210., 206.]],

         [[219., 217., 171., 113., 140., 138., 140., 152., 187., 198., 162.,
           159., 184., 109., 202., 199.],
          [168., 205., 182., 177., 105.,  95., 120., 122.,  85., 121.,  59.,
           136., 178., 130., 163., 179.],
          [159., 161., 203., 183., 136., 133., 141., 141., 129., 177., 170.,
           116., 159., 116., 164., 183.],
          [167., 162., 157., 161., 123.,  87.,  61.,  58.,  53., 134.,  87.,
           126., 173., 135., 157., 130.],
          [245., 161., 110., 115.,  75., 115., 120., 112., 115., 191., 147.,
           120., 173., 144., 175., 176.],
          [242., 169., 110.,  99., 111., 174., 142., 127., 109., 216., 222.,
            18.,  66., 114., 149., 184.],
          [242., 157., 120., 103., 121., 195., 204., 191., 182., 202., 221.,
            21.,  59.,  47., 126., 184.],
          [208., 119.,  95.,  96., 108., 188., 198., 199., 174., 196., 202.,
            25.,  59.,  87., 131., 150.],
          [185., 125., 110., 114., 117., 171., 170., 180., 201., 173., 164.,
            43.,  74., 184., 140., 147.],
          [189., 125.,  97.,  99., 103., 178., 200., 201., 197., 145., 153.,
            72.,  94., 130., 164., 162.],
          [148., 122., 118.,  96., 122., 156., 193., 194., 189., 138., 163.,
            55.,  91., 112., 165., 182.],
          [127., 122., 117., 117., 118., 142., 146., 151., 154., 163., 155.,
            46.,  62., 154., 190., 197.],
          [122., 105.,  84.,  83.,  87., 109., 114., 118., 134., 153., 146.,
           105.,  54., 130., 192., 191.],
          [132., 117.,  11.,  20.,  29.,  38.,  70.,  37.,  42., 164., 160.,
           166., 178., 188., 194., 195.],
          [ 95.,  74.,  33.,  20.,  16.,  24.,  25.,  27.,  40., 126., 184.,
           185., 192., 197., 190., 196.],
          [150., 148., 129., 125., 106., 121., 154., 175., 185., 186., 191.,
           195., 199., 204., 208., 207.]],

         [[221., 224., 179., 121., 152., 150., 160., 165., 199., 217., 180.,
           177., 200., 125., 217., 215.],
          [169., 216., 189., 191., 113., 109., 132., 100.,  82., 103.,  67.,
           150., 193., 145., 178., 195.],
          [161., 167., 210., 189., 140., 100.,  97.,  98., 103., 157., 157.,
           128., 172., 123., 177., 197.],
          [164., 161., 164., 170., 133., 105.,  87.,  89.,  88., 153.,  85.,
           143., 185., 144., 171., 143.],
          [239., 164., 115., 128.,  82., 129., 141., 129., 107., 149., 119.,
           135., 190., 159., 192., 192.],
          [234., 128.,  60.,  54.,  65., 120., 127., 122.,  93., 167., 179.,
            25.,  82., 129., 166., 200.],
          [236., 106.,  74.,  64.,  75., 106., 113., 108.,  93., 139., 168.,
            27.,  73.,  60., 143., 200.],
          [197.,  72.,  52.,  40.,  46.,  80., 102.,  94.,  79., 117., 133.,
            26.,  68., 101., 148., 168.],
          [156.,  73.,  47.,  56.,  57.,  86.,  86.,  95., 121., 117., 110.,
            41.,  76., 192., 149., 167.],
          [161., 104.,  43.,  44.,  44., 111., 111., 114., 116., 137., 102.,
            63., 100., 134., 178., 179.],
          [113.,  80.,  55.,  50.,  51., 113., 123., 131., 123., 146., 151.,
            65., 100., 107., 179., 198.],
          [ 88.,  51.,  48.,  54.,  49.,  58.,  63.,  67., 101., 127., 146.,
            47.,  73., 147., 199., 207.],
          [116.,  86.,  33.,  31.,  34.,  45.,  51.,  47.,  77., 108., 147.,
           109.,  66., 136., 198., 197.],
          [135., 117.,  16.,  21.,  33.,  27.,  55.,  39.,  53., 154., 165.,
           174., 186., 196., 202., 203.],
          [111.,  89.,  47.,  33.,  27.,  32.,  34.,  33.,  47., 137., 185.,
           193., 200., 205., 198., 204.],
          [163., 161., 138., 135., 121., 131., 164., 185., 195., 194., 203.,
           205., 210., 212., 218., 216.]]]])]}
Given groups=1, weight of size [128, 128, 1, 1], expected input[1, 3, 16, 16] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 16, 16], dtype=Float32, value=
[[[[2.24000000e+002, 2.16000000e+002, 1.77000000e+002 ... 1.09000000e+002, 1.97000000e+002, 1.95000000e+002],
   [1.77000000e+002, 2.07000000e+002, 1.86000000e+002 ... 1.30000000e+002, 1.58000000e+002, 1.72000000e+002],
   [1.63000000e+002, 1.65000000e+002, 2.07000000e+002 ... 1.14000000e+002, 1.58000000e+002, 1.78000000e+002],
   ...
   [1.47000000e+002, 1.31000000e+002, 1.70000000e+001 ... 1.89000000e+002, 1.95000000e+002, 1.95000000e+002],
   [1.05000000e+002, 8.30000000e+001, 3.70000000e+001 ... 1.97000000e+002, 1.91000000e+002, 1.96000000e+002],
   [1.52000000e+002, 1.51000000e+002, 1.34000000e+002 ... 2.03000000e+002, 2.10000000e+002, 2.06000000e+002]],
  [[2.19000000e+002, 2.17000000e+002, 1.71000000e+002 ... 1.09000000e+002, 2.02000000e+002, 1.99000000e+002],
   [1.68000000e+002, 2.05000000e+002, 1.82000000e+002 ... 1.30000000e+002, 1.63000000e+002, 1.79000000e+002],
   [1.59000000e+002, 1.61000000e+002, 2.03000000e+002 ... 1.16000000e+002, 1.64000000e+002, 1.83000000e+002],
   ...
   [1.32000000e+002, 1.17000000e+002, 1.10000000e+001 ... 1.88000000e+002, 1.94000000e+002, 1.95000000e+002],
   [9.50000000e+001, 7.40000000e+001, 3.30000000e+001 ... 1.97000000e+002, 1.90000000e+002, 1.96000000e+002],
   [1.50000000e+002, 1.48000000e+002, 1.29000000e+002 ... 2.04000000e+002, 2.08000000e+002, 2.07000000e+002]],
  [[2.21000000e+002, 2.24000000e+002, 1.79000000e+002 ... 1.25000000e+002, 2.17000000e+002, 2.15000000e+002],
   [1.69000000e+002, 2.16000000e+002, 1.89000000e+002 ... 1.45000000e+002, 1.78000000e+002, 1.95000000e+002],
   [1.61000000e+002, 1.67000000e+002, 2.10000000e+002 ... 1.23000000e+002, 1.77000000e+002, 1.97000000e+002],
   ...
   [1.35000000e+002, 1.17000000e+002, 1.60000000e+001 ... 1.96000000e+002, 2.02000000e+002, 2.03000000e+002],
   [1.11000000e+002, 8.90000000e+001, 4.70000000e+001 ... 2.05000000e+002, 1.98000000e+002, 2.04000000e+002],
   [1.63000000e+002, 1.61000000e+002, 1.38000000e+002 ... 2.12000000e+002, 2.18000000e+002, 2.16000000e+002]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:155

analyse the exceptions in iter:224
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[ 22.,  63.,  81.,  ...,  83.,  75.,  55.],
          [ 40.,  80.,  92.,  ...,  90.,  94.,  87.],
          [ 35.,  71.,  82.,  ...,  91., 124., 119.],
          ...,
          [ 33.,  76.,  81.,  ..., 101., 101., 101.],
          [  4.,   7.,  10.,  ...,  14.,  11.,   8.],
          [  0.,   1.,   1.,  ...,   0.,   1.,   1.]],

         [[ 20.,  53.,  66.,  ...,  52.,  51.,  40.],
          [ 31.,  62.,  68.,  ...,  61.,  63.,  64.],
          [ 22.,  50.,  53.,  ...,  63.,  84.,  86.],
          ...,
          [ 23.,  57.,  58.,  ...,  64.,  61.,  70.],
          [  3.,   1.,   2.,  ...,   2.,   0.,   0.],
          [  1.,   0.,   0.,  ...,   0.,   0.,   0.]],

         [[ 20.,  56.,  71.,  ...,  60.,  65.,  52.],
          [ 34.,  68.,  75.,  ...,  70.,  76.,  74.],
          [ 26.,  57.,  61.,  ...,  73.,  96.,  95.],
          ...,
          [ 25.,  63.,  64.,  ...,  62.,  58.,  69.],
          [  3.,   2.,   3.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]])]}
Given groups=1, weight of size [64, 64, 1, 1], expected input[1, 3, 32, 32] to have 64 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[2.20000000e+001, 6.30000000e+001, 8.10000000e+001 ... 8.30000000e+001, 7.50000000e+001, 5.50000000e+001],
   [4.00000000e+001, 8.00000000e+001, 9.20000000e+001 ... 9.00000000e+001, 9.40000000e+001, 8.70000000e+001],
   [3.50000000e+001, 7.10000000e+001, 8.20000000e+001 ... 9.10000000e+001, 1.24000000e+002, 1.19000000e+002],
   ...
   [3.30000000e+001, 7.60000000e+001, 8.10000000e+001 ... 1.01000000e+002, 1.01000000e+002, 1.01000000e+002],
   [4.00000000e+000, 7.00000000e+000, 1.00000000e+001 ... 1.40000000e+001, 1.10000000e+001, 8.00000000e+000],
   [0.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 0.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  [[2.00000000e+001, 5.30000000e+001, 6.60000000e+001 ... 5.20000000e+001, 5.10000000e+001, 4.00000000e+001],
   [3.10000000e+001, 6.20000000e+001, 6.80000000e+001 ... 6.10000000e+001, 6.30000000e+001, 6.40000000e+001],
   [2.20000000e+001, 5.00000000e+001, 5.30000000e+001 ... 6.30000000e+001, 8.40000000e+001, 8.60000000e+001],
   ...
   [2.30000000e+001, 5.70000000e+001, 5.80000000e+001 ... 6.40000000e+001, 6.10000000e+001, 7.00000000e+001],
   [3.00000000e+000, 1.00000000e+000, 2.00000000e+000 ... 2.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [1.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[2.00000000e+001, 5.60000000e+001, 7.10000000e+001 ... 6.00000000e+001, 6.50000000e+001, 5.20000000e+001],
   [3.40000000e+001, 6.80000000e+001, 7.50000000e+001 ... 7.00000000e+001, 7.60000000e+001, 7.40000000e+001],
   [2.60000000e+001, 5.70000000e+001, 6.10000000e+001 ... 7.30000000e+001, 9.60000000e+001, 9.50000000e+001],
   ...
   [2.50000000e+001, 6.30000000e+001, 6.40000000e+001 ... 6.20000000e+001, 5.80000000e+001, 6.90000000e+001],
   [3.00000000e+000, 2.00000000e+000, 3.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 64, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:187

analyse the exceptions in iter:239
torch exception:
{'id': 2, 'name': 'linear', 'frame_work': 'torch', 'input_datas': [tensor([[[[ 74.,  74.,  81.,  ..., 122., 120., 121.],
          [ 69., 109., 111.,  ..., 123., 120., 121.],
          [ 63., 153., 141.,  ..., 122., 119., 122.],
          ...,
          [  5.,   5.,  18.,  ..., 106., 110., 116.],
          [  3.,   5.,  11.,  ...,  91.,  93.,  97.],
          [  4.,   9.,  20.,  ...,  80.,  82.,  87.]],

         [[ 21.,  46.,  67.,  ...,  52.,  52.,  49.],
          [ 23., 103., 138.,  ...,  53.,  51.,  49.],
          [ 29., 170., 203.,  ...,  51.,  49.,  49.],
          ...,
          [ 26.,  24.,  26.,  ...,  18.,  22.,  29.],
          [ 19.,  13.,  13.,  ...,  13.,  14.,  14.],
          [  9.,   5.,   6.,  ...,   8.,   9.,  10.]],

         [[ 29.,  56.,  77.,  ...,  57.,  57.,  57.],
          [ 26., 112., 150.,  ...,  58.,  56.,  58.],
          [ 27., 176., 215.,  ...,  57.,  55.,  59.],
          ...,
          [ 49.,  39.,  25.,  ...,  27.,  31.,  38.],
          [ 35.,  26.,  11.,  ...,  19.,  21.,  19.],
          [ 17.,  11.,   5.,  ...,  11.,  13.,  14.]]]])]}
mat1 and mat2 shapes cannot be multiplied (96x32 and 100x100)
mindspore exception:
{'id': 2, 'name': 'linear', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[7.40000000e+001, 7.40000000e+001, 8.10000000e+001 ... 1.22000000e+002, 1.20000000e+002, 1.21000000e+002],
   [6.90000000e+001, 1.09000000e+002, 1.11000000e+002 ... 1.23000000e+002, 1.20000000e+002, 1.21000000e+002],
   [6.30000000e+001, 1.53000000e+002, 1.41000000e+002 ... 1.22000000e+002, 1.19000000e+002, 1.22000000e+002],
   ...
   [5.00000000e+000, 5.00000000e+000, 1.80000000e+001 ... 1.06000000e+002, 1.10000000e+002, 1.16000000e+002],
   [3.00000000e+000, 5.00000000e+000, 1.10000000e+001 ... 9.10000000e+001, 9.30000000e+001, 9.70000000e+001],
   [4.00000000e+000, 9.00000000e+000, 2.00000000e+001 ... 8.00000000e+001, 8.20000000e+001, 8.70000000e+001]],
  [[2.10000000e+001, 4.60000000e+001, 6.70000000e+001 ... 5.20000000e+001, 5.20000000e+001, 4.90000000e+001],
   [2.30000000e+001, 1.03000000e+002, 1.38000000e+002 ... 5.30000000e+001, 5.10000000e+001, 4.90000000e+001],
   [2.90000000e+001, 1.70000000e+002, 2.03000000e+002 ... 5.10000000e+001, 4.90000000e+001, 4.90000000e+001],
   ...
   [2.60000000e+001, 2.40000000e+001, 2.60000000e+001 ... 1.80000000e+001, 2.20000000e+001, 2.90000000e+001],
   [1.90000000e+001, 1.30000000e+001, 1.30000000e+001 ... 1.30000000e+001, 1.40000000e+001, 1.40000000e+001],
   [9.00000000e+000, 5.00000000e+000, 6.00000000e+000 ... 8.00000000e+000, 9.00000000e+000, 1.00000000e+001]],
  [[2.90000000e+001, 5.60000000e+001, 7.70000000e+001 ... 5.70000000e+001, 5.70000000e+001, 5.70000000e+001],
   [2.60000000e+001, 1.12000000e+002, 1.50000000e+002 ... 5.80000000e+001, 5.60000000e+001, 5.80000000e+001],
   [2.70000000e+001, 1.76000000e+002, 2.15000000e+002 ... 5.70000000e+001, 5.50000000e+001, 5.90000000e+001],
   ...
   [4.90000000e+001, 3.90000000e+001, 2.50000000e+001 ... 2.70000000e+001, 3.10000000e+001, 3.80000000e+001],
   [3.50000000e+001, 2.60000000e+001, 1.10000000e+001 ... 1.90000000e+001, 2.10000000e+001, 1.90000000e+001],
   [1.70000000e+001, 1.10000000e+001, 5.00000000e+000 ... 1.10000000e+001, 1.30000000e+001, 1.40000000e+001]]]])]}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 100. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 100](transpose_b=True).

generate models:200

analyse the exceptions in iter:245
torch exception:
{'id': 3, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [143.7188, 143.7188, 143.7188,  ..., 143.7188, 143.7188, 143.7188],
          ...,
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [ 34.1622,  34.1622,  34.1622,  ...,  34.1622,  34.1622,  34.1622],
          [117.6645, 117.6645, 117.6645,  ..., 117.6645, 117.6645, 117.6645]],

         [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [143.7188, 143.7188, 143.7188,  ..., 143.7188, 143.7188, 143.7188],
          ...,
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [ 34.1622,  34.1622,  34.1622,  ...,  34.1622,  34.1622,  34.1622],
          [117.6645, 117.6645, 117.6645,  ..., 117.6645, 117.6645, 117.6645]],

         [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          ...,
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],

         ...,

         [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          ...,
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],

         [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          ...,
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],

         [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          ...,
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],
          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]]],
       grad_fn=<TransposeBackward0>)]}
Given groups=1, weight of size [512, 512, 3, 3], expected input[1, 64, 32, 32] to have 512 channels, but got 64 channels instead
mindspore exception:
{'id': 3, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 64, 32, 32], dtype=Float32, value=
[[[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [1.43411560e+002, 1.43411560e+002, 1.43411560e+002 ... 1.43411560e+002, 1.43409897e+002, 1.43409897e+002],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [3.42281761e+001, 3.42281761e+001, 3.42281761e+001 ... 3.42281761e+001, 3.42299423e+001, 3.42299423e+001],
   [1.17670975e+002, 1.17670975e+002, 1.17670975e+002 ... 1.17670975e+002, 1.17668625e+002, 1.17668625e+002]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [1.43411560e+002, 1.43411560e+002, 1.43411560e+002 ... 1.43411560e+002, 1.43409897e+002, 1.43409897e+002],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [3.42281761e+001, 3.42281761e+001, 3.42281761e+001 ... 3.42281761e+001, 3.42299423e+001, 3.42299423e+001],
   [1.17670975e+002, 1.17670975e+002, 1.17670975e+002 ... 1.17670975e+002, 1.17668625e+002, 1.17668625e+002]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  ...
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 64, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:205

analyse the exceptions in iter:248
torch exception:
{'id': 6, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[4307428., 3253285., 3281645., 3419668.],
          [4307740., 3253489., 3282068., 3419632.],
          [4307074., 3253234., 3282080., 3418786.],
          [4307014., 3253228., 3282080., 3418528.]],

         [[4307104., 3252934., 3282080., 3418510.],
          [4307365., 3253441., 3282080., 3418546.],
          [4306930., 3253123., 3282080., 3418636.],
          [4306444., 3252925., 3282080., 3418774.]],

         [[4306210., 3252622., 3282080., 3418618.],
          [4306159., 3252178., 3282080., 3418582.],
          [4306426., 3252337., 3282005., 3419299.],
          [4306723., 3252292., 3281873., 3419569.]],

         ...,

         [[      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.]],

         [[      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.]],

         [[      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.],
          [      0.,       0.,       0.,       0.]]]],
       grad_fn=<MaxPool2DWithIndicesBackward0>)]}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 64, 4, 4] to have 512 channels, but got 64 channels instead
mindspore exception:
{'id': 6, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 64, 4, 4], dtype=Float32, value=
[[[[4.30742800e+006, 3.25328500e+006, 3.28164500e+006, 3.41966800e+006],
   [4.30774000e+006, 3.25348900e+006, 3.28206800e+006, 3.41963200e+006],
   [4.30707400e+006, 3.25323400e+006, 3.28208000e+006, 3.41878600e+006],
   [4.30701400e+006, 3.25322800e+006, 3.28208000e+006, 3.41852800e+006]],
  [[4.30710400e+006, 3.25293400e+006, 3.28208000e+006, 3.41851000e+006],
   [4.30736500e+006, 3.25344100e+006, 3.28208000e+006, 3.41854600e+006],
   [4.30693000e+006, 3.25312300e+006, 3.28208000e+006, 3.41863600e+006],
   [4.30644400e+006, 3.25292500e+006, 3.28208000e+006, 3.41877400e+006]],
  [[4.30621000e+006, 3.25262200e+006, 3.28208000e+006, 3.41861800e+006],
   [4.30615900e+006, 3.25217800e+006, 3.28208000e+006, 3.41858200e+006],
   [4.30642600e+006, 3.25233700e+006, 3.28200500e+006, 3.41929900e+006],
   [4.30672300e+006, 3.25229200e+006, 3.28187300e+006, 3.41956900e+006]],
  ...
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 64, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:208

analyse the exceptions in iter:249
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 55.,  54.,  51.,  ...,  27.,  25.,  24.],
           [ 58.,  56.,  53.,  ...,  29.,  28.,  27.],
           [ 62.,  59.,  56.,  ...,  28.,  28.,  28.],
           ...,
           [ 49.,  48.,  45.,  ..., 146., 139., 122.],
           [ 52.,  48.,  45.,  ..., 134., 121., 116.],
           [ 57.,  52.,  49.,  ..., 121., 113., 112.]],

          [[ 62.,  61.,  58.,  ...,  33.,  32.,  30.],
           [ 65.,  63.,  60.,  ...,  37.,  35.,  33.],
           [ 69.,  66.,  63.,  ...,  38.,  37.,  35.],
           ...,
           [ 64.,  62.,  59.,  ..., 158., 150., 134.],
           [ 68.,  64.,  60.,  ..., 146., 133., 128.],
           [ 75.,  69.,  65.,  ..., 133., 125., 124.]],

          [[ 54.,  53.,  50.,  ...,  26.,  25.,  28.],
           [ 57.,  55.,  52.,  ...,  30.,  29.,  31.],
           [ 61.,  58.,  55.,  ...,  33.,  33.,  32.],
           ...,
           [ 33.,  36.,  36.,  ..., 171., 166., 148.],
           [ 29.,  28.,  29.,  ..., 160., 147., 142.],
           [ 26.,  24.,  24.,  ..., 146., 139., 138.]]]]])}
Given groups=1, weight of size [256, 128, 1, 1], expected input[1, 3, 32, 32] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[5.50000000e+001, 5.40000000e+001, 5.10000000e+001 ... 2.70000000e+001, 2.50000000e+001, 2.40000000e+001],
    [5.80000000e+001, 5.60000000e+001, 5.30000000e+001 ... 2.90000000e+001, 2.80000000e+001, 2.70000000e+001],
    [6.20000000e+001, 5.90000000e+001, 5.60000000e+001 ... 2.80000000e+001, 2.80000000e+001, 2.80000000e+001],
    ...
    [4.90000000e+001, 4.80000000e+001, 4.50000000e+001 ... 1.46000000e+002, 1.39000000e+002, 1.22000000e+002],
    [5.20000000e+001, 4.80000000e+001, 4.50000000e+001 ... 1.34000000e+002, 1.21000000e+002, 1.16000000e+002],
    [5.70000000e+001, 5.20000000e+001, 4.90000000e+001 ... 1.21000000e+002, 1.13000000e+002, 1.12000000e+002]],
   [[6.20000000e+001, 6.10000000e+001, 5.80000000e+001 ... 3.30000000e+001, 3.20000000e+001, 3.00000000e+001],
    [6.50000000e+001, 6.30000000e+001, 6.00000000e+001 ... 3.70000000e+001, 3.50000000e+001, 3.30000000e+001],
    [6.90000000e+001, 6.60000000e+001, 6.30000000e+001 ... 3.80000000e+001, 3.70000000e+001, 3.50000000e+001],
    ...
    [6.40000000e+001, 6.20000000e+001, 5.90000000e+001 ... 1.58000000e+002, 1.50000000e+002, 1.34000000e+002],
    [6.80000000e+001, 6.40000000e+001, 6.00000000e+001 ... 1.46000000e+002, 1.33000000e+002, 1.28000000e+002],
    [7.50000000e+001, 6.90000000e+001, 6.50000000e+001 ... 1.33000000e+002, 1.25000000e+002, 1.24000000e+002]],
   [[5.40000000e+001, 5.30000000e+001, 5.00000000e+001 ... 2.60000000e+001, 2.50000000e+001, 2.80000000e+001],
    [5.70000000e+001, 5.50000000e+001, 5.20000000e+001 ... 3.00000000e+001, 2.90000000e+001, 3.10000000e+001],
    [6.10000000e+001, 5.80000000e+001, 5.50000000e+001 ... 3.30000000e+001, 3.30000000e+001, 3.20000000e+001],
    ...
    [3.30000000e+001, 3.60000000e+001, 3.60000000e+001 ... 1.71000000e+002, 1.66000000e+002, 1.48000000e+002],
    [2.90000000e+001, 2.80000000e+001, 2.90000000e+001 ... 1.60000000e+002, 1.47000000e+002, 1.42000000e+002],
    [2.60000000e+001, 2.40000000e+001, 2.40000000e+001 ... 1.46000000e+002, 1.39000000e+002, 1.38000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:209

analyse the exceptions in iter:257
torch exception:
{'id': 4, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[232., 247., 242., 225., 218., 216., 216., 215., 188., 193., 200.,
           205., 179., 168., 173., 150.],
          [119., 143., 138., 141., 155., 160., 171., 170.,  86., 132., 144.,
           167., 120., 152., 134.,  96.],
          [143., 145.,  88., 133., 165., 143.,  96., 157.,  84.,  72., 143.,
            72., 101., 103., 114.,  83.],
          [103., 103., 130., 125., 120., 106.,  64.,  86., 161., 198., 194.,
           136.,  31.,  51.,  54.,  40.],
          [ 74., 132., 135., 133., 165., 149., 110., 158., 170., 179., 203.,
           116.,  88.,  98., 105.,  38.],
          [151., 145., 129., 117., 150., 154., 115., 120.,  87., 197., 189.,
           110., 165., 193., 138.,  93.],
          [126., 124., 182., 218., 218., 218., 214., 206., 189., 192., 199.,
           177., 163., 101.,  83.,  79.],
          [ 85.,  35.,  88., 138., 176., 202., 219., 216., 172., 148., 104.,
            35.,  85.,  80.,  69.,  72.],
          [ 62., 100., 101.,  96.,  92.,  84.,  81.,  65.,  63.,  63.,  82.,
            72., 109.,  95.,  56.,  65.],
          [ 63.,  95., 126., 109., 115., 107.,  82.,  92.,  93., 120., 108.,
           118.,  98.,  62.,  61.,  61.],
          [ 61.,  58.,  35.,  41.,  77., 112., 126., 142., 150., 137.,  59.,
           106.,  59.,  60.,  61.,  60.],
          [ 67.,  48.,  36.,  22.,  20.,  21.,  23.,  31.,  45.,  55.,  44.,
            47.,  50.,  55.,  59.,  57.],
          [ 56.,  44.,  40.,  44.,  35.,  33.,  20.,  11.,  13.,  33.,  44.,
            51.,  53.,  54.,  57.,  54.],
          [ 66.,  55.,  49.,  51.,  52.,  43.,  43.,  43.,  40.,  48.,  52.,
            54.,  61.,  59.,  66.,  55.],
          [101., 114.,  60.,  55.,  54.,  47.,  54.,  51.,  48.,  49.,  66.,
            63.,  64.,  57.,  59.,  54.],
          [ 51.,  93., 106., 108.,  71.,  57.,  54.,  58.,  53.,  51.,  57.,
            55.,  63.,  70.,  65., 111.]],

         [[231., 244., 242., 228., 221., 218., 220., 214., 196., 198., 204.,
           206., 183., 172., 177., 155.],
          [135., 157., 146., 152., 164., 152., 183., 176.,  95., 143., 155.,
           175., 128., 158., 145.,  96.],
          [147., 150.,  93., 140., 170., 135.,  92., 166.,  82.,  76., 146.,
            75., 110., 113., 122.,  85.],
          [110., 112., 140., 133., 118., 106.,  63.,  92., 161., 197., 197.,
           138.,  39.,  61.,  66.,  49.],
          [ 78., 139., 145., 142., 169., 153., 112., 160., 169., 177., 201.,
           124.,  98., 103., 110.,  45.],
          [156., 150., 136., 120., 153., 157., 119., 122.,  90., 199., 192.,
           114., 173., 195., 139.,  93.],
          [131., 130., 185., 220., 220., 220., 215., 210., 193., 195., 203.,
           180., 167., 108.,  85.,  95.],
          [ 90.,  40.,  93., 140., 177., 208., 217., 221., 175., 151., 111.,
            39.,  91.,  84.,  73.,  88.],
          [ 66.,  89.,  70., 101.,  97.,  93.,  86.,  67.,  59.,  71.,  86.,
            77., 115., 100.,  72.,  82.],
          [ 80., 102., 122., 114., 122., 113.,  77.,  23.,  27., 124., 115.,
           122., 104.,  75.,  77.,  80.],
          [ 76.,  73.,  46.,  43.,  83., 119., 125., 124., 138., 133.,  65.,
           109.,  71.,  73.,  77.,  78.],
          [ 78.,  65.,  51.,  34.,  20.,  21.,  19.,  31.,  53.,  65.,  51.,
            57.,  68.,  73.,  76.,  73.],
          [ 68.,  61.,  58.,  58.,  53.,  45.,  31.,  16.,  20.,  43.,  60.,
            65.,  69.,  71.,  76.,  75.],
          [ 70.,  75.,  65.,  66.,  66.,  64.,  60.,  61.,  57.,  67.,  68.,
            67.,  77.,  77.,  84.,  67.],
          [111., 118.,  77.,  70.,  69.,  65.,  69.,  68.,  60.,  67.,  76.,
            73.,  71.,  66.,  69.,  68.],
          [ 60.,  94., 111., 119.,  84.,  73.,  69.,  67.,  69.,  69.,  67.,
            70.,  74.,  82.,  75.,  86.]],

         [[232., 247., 246., 231., 222., 221., 222., 224., 189., 204., 212.,
           210., 187., 172., 179., 156.],
          [143., 170., 154., 149., 167., 158., 195., 196.,  82., 143., 160.,
           173., 123., 157., 141.,  94.],
          [151., 154.,  91., 134., 170., 134.,  91., 175.,  80.,  70., 143.,
            73., 112., 109., 116.,  80.],
          [119., 123., 147., 144., 105., 100.,  71.,  78., 160., 201., 203.,
           128.,  25.,  27.,  24.,  22.],
          [ 86., 150., 151., 147., 167., 155., 112., 162., 180., 185., 208.,
           124.,  90.,  95., 108.,  26.],
          [163., 157., 139., 122., 154., 161., 127., 134.,  96., 206., 198.,
           119., 178., 200., 142.,  60.],
          [135., 141., 189., 219., 219., 219., 217., 209., 196., 200., 207.,
           185., 168., 102.,  74.,  39.],
          [ 94.,  39.,  91., 140., 178., 206., 220., 219., 180., 157., 109.,
            36.,  85.,  78.,  55.,  25.],
          [ 59.,  68.,  73., 104., 100.,  92.,  80.,  64.,  58.,  63.,  82.,
            74., 111.,  93.,  31.,  25.],
          [ 34.,  77., 125., 117., 126., 120.,  74.,  31.,  31., 132., 118.,
           123., 100.,  37.,  28.,  27.],
          [ 32.,  26.,  23.,  42.,  81., 121., 123., 128., 139., 134.,  63.,
           113.,  30.,  23.,  25.,  25.],
          [ 35.,  17.,  17.,  12.,  22.,  19.,  21.,  30.,  44.,  52.,  41.,
            20.,  19.,  25.,  31.,  24.],
          [ 27.,  19.,  18.,  20.,  20.,  18.,  14.,  14.,  12.,  19.,  24.,
            25.,  24.,  25.,  29.,  28.],
          [ 38.,  29.,  22.,  21.,  22.,  20.,  19.,  22.,  16.,  22.,  26.,
            21.,  29.,  26.,  33.,  22.],
          [ 82.,  87.,  37.,  22.,  20.,  18.,  26.,  24.,  19.,  22.,  33.,
            27.,  25.,  24.,  24.,  21.],
          [ 27.,  71.,  85.,  92.,  52.,  28.,  24.,  22.,  25.,  24.,  25.,
            29.,  39.,  48.,  43.,  58.]]]])]}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 16, 16] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 4, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 16, 16], dtype=Float32, value=
[[[[2.32000000e+002, 2.47000000e+002, 2.42000000e+002 ... 1.68000000e+002, 1.73000000e+002, 1.50000000e+002],
   [1.19000000e+002, 1.43000000e+002, 1.38000000e+002 ... 1.52000000e+002, 1.34000000e+002, 9.60000000e+001],
   [1.43000000e+002, 1.45000000e+002, 8.80000000e+001 ... 1.03000000e+002, 1.14000000e+002, 8.30000000e+001],
   ...
   [6.60000000e+001, 5.50000000e+001, 4.90000000e+001 ... 5.90000000e+001, 6.60000000e+001, 5.50000000e+001],
   [1.01000000e+002, 1.14000000e+002, 6.00000000e+001 ... 5.70000000e+001, 5.90000000e+001, 5.40000000e+001],
   [5.10000000e+001, 9.30000000e+001, 1.06000000e+002 ... 7.00000000e+001, 6.50000000e+001, 1.11000000e+002]],
  [[2.31000000e+002, 2.44000000e+002, 2.42000000e+002 ... 1.72000000e+002, 1.77000000e+002, 1.55000000e+002],
   [1.35000000e+002, 1.57000000e+002, 1.46000000e+002 ... 1.58000000e+002, 1.45000000e+002, 9.60000000e+001],
   [1.47000000e+002, 1.50000000e+002, 9.30000000e+001 ... 1.13000000e+002, 1.22000000e+002, 8.50000000e+001],
   ...
   [7.00000000e+001, 7.50000000e+001, 6.50000000e+001 ... 7.70000000e+001, 8.40000000e+001, 6.70000000e+001],
   [1.11000000e+002, 1.18000000e+002, 7.70000000e+001 ... 6.60000000e+001, 6.90000000e+001, 6.80000000e+001],
   [6.00000000e+001, 9.40000000e+001, 1.11000000e+002 ... 8.20000000e+001, 7.50000000e+001, 8.60000000e+001]],
  [[2.32000000e+002, 2.47000000e+002, 2.46000000e+002 ... 1.72000000e+002, 1.79000000e+002, 1.56000000e+002],
   [1.43000000e+002, 1.70000000e+002, 1.54000000e+002 ... 1.57000000e+002, 1.41000000e+002, 9.40000000e+001],
   [1.51000000e+002, 1.54000000e+002, 9.10000000e+001 ... 1.09000000e+002, 1.16000000e+002, 8.00000000e+001],
   ...
   [3.80000000e+001, 2.90000000e+001, 2.20000000e+001 ... 2.60000000e+001, 3.30000000e+001, 2.20000000e+001],
   [8.20000000e+001, 8.70000000e+001, 3.70000000e+001 ... 2.40000000e+001, 2.40000000e+001, 2.10000000e+001],
   [2.70000000e+001, 7.10000000e+001, 8.50000000e+001 ... 4.80000000e+001, 4.30000000e+001, 5.80000000e+001]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:215

analyse the exceptions in iter:258
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 92.,  97.,  76.,  ...,  25., 102., 128.],
           [ 26.,  28.,  27.,  ...,  26., 102., 131.],
           [ 20.,  18.,  18.,  ...,  65., 114., 132.],
           ...,
           [ 60.,  61.,  61.,  ..., 138.,  71.,  54.],
           [ 69.,  66.,  70.,  ..., 107.,  59.,  46.],
           [ 71.,  70.,  81.,  ...,  80.,  50.,  39.]],

          [[ 71.,  73.,  59.,  ...,  24., 104., 136.],
           [ 24.,  25.,  25.,  ...,  22., 103., 139.],
           [ 19.,  18.,  16.,  ...,  63., 114., 138.],
           ...,
           [ 65.,  67.,  66.,  ..., 139.,  72.,  51.],
           [ 73.,  73.,  75.,  ..., 103.,  55.,  41.],
           [ 76.,  75.,  87.,  ...,  71.,  44.,  34.]],

          [[ 71.,  71.,  54.,  ...,  22.,  99., 137.],
           [ 26.,  25.,  25.,  ...,  19., 100., 141.],
           [ 21.,  20.,  19.,  ...,  62., 111., 140.],
           ...,
           [ 69.,  74.,  77.,  ..., 112.,  51.,  39.],
           [ 81.,  82.,  85.,  ...,  86.,  41.,  30.],
           [ 79.,  82.,  96.,  ...,  45.,  32.,  27.]]]]])}
Given groups=1, weight of size [512, 128, 1, 1], expected input[1, 3, 32, 32] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[9.20000000e+001, 9.70000000e+001, 7.60000000e+001 ... 2.50000000e+001, 1.02000000e+002, 1.28000000e+002],
    [2.60000000e+001, 2.80000000e+001, 2.70000000e+001 ... 2.60000000e+001, 1.02000000e+002, 1.31000000e+002],
    [2.00000000e+001, 1.80000000e+001, 1.80000000e+001 ... 6.50000000e+001, 1.14000000e+002, 1.32000000e+002],
    ...
    [6.00000000e+001, 6.10000000e+001, 6.10000000e+001 ... 1.38000000e+002, 7.10000000e+001, 5.40000000e+001],
    [6.90000000e+001, 6.60000000e+001, 7.00000000e+001 ... 1.07000000e+002, 5.90000000e+001, 4.60000000e+001],
    [7.10000000e+001, 7.00000000e+001, 8.10000000e+001 ... 8.00000000e+001, 5.00000000e+001, 3.90000000e+001]],
   [[7.10000000e+001, 7.30000000e+001, 5.90000000e+001 ... 2.40000000e+001, 1.04000000e+002, 1.36000000e+002],
    [2.40000000e+001, 2.50000000e+001, 2.50000000e+001 ... 2.20000000e+001, 1.03000000e+002, 1.39000000e+002],
    [1.90000000e+001, 1.80000000e+001, 1.60000000e+001 ... 6.30000000e+001, 1.14000000e+002, 1.38000000e+002],
    ...
    [6.50000000e+001, 6.70000000e+001, 6.60000000e+001 ... 1.39000000e+002, 7.20000000e+001, 5.10000000e+001],
    [7.30000000e+001, 7.30000000e+001, 7.50000000e+001 ... 1.03000000e+002, 5.50000000e+001, 4.10000000e+001],
    [7.60000000e+001, 7.50000000e+001, 8.70000000e+001 ... 7.10000000e+001, 4.40000000e+001, 3.40000000e+001]],
   [[7.10000000e+001, 7.10000000e+001, 5.40000000e+001 ... 2.20000000e+001, 9.90000000e+001, 1.37000000e+002],
    [2.60000000e+001, 2.50000000e+001, 2.50000000e+001 ... 1.90000000e+001, 1.00000000e+002, 1.41000000e+002],
    [2.10000000e+001, 2.00000000e+001, 1.90000000e+001 ... 6.20000000e+001, 1.11000000e+002, 1.40000000e+002],
    ...
    [6.90000000e+001, 7.40000000e+001, 7.70000000e+001 ... 1.12000000e+002, 5.10000000e+001, 3.90000000e+001],
    [8.10000000e+001, 8.20000000e+001, 8.50000000e+001 ... 8.60000000e+001, 4.10000000e+001, 3.00000000e+001],
    [7.90000000e+001, 8.20000000e+001, 9.60000000e+001 ... 4.50000000e+001, 3.20000000e+001, 2.70000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:216

analyse output arrays in iter:265

pre layer res:
4:conv2d
{'name': 'conv2d', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [12], 'to': [9]}
tf node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [4], 'to': [13]}
ms node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [4], 'to': [13]}
torch node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [4], 'to': [13]}

generate models:222

analyse the exceptions in iter:272
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[160., 167., 165.,  ..., 154., 148., 146.],
           [146., 147., 166.,  ..., 165., 158., 158.],
           [155., 155., 166.,  ..., 156., 157., 148.],
           ...,
           [174., 164., 168.,  ..., 181., 193., 195.],
           [165., 154., 156.,  ..., 183., 186., 168.],
           [166., 199., 198.,  ..., 200., 184., 182.]],

          [[161., 169., 166.,  ..., 155., 150., 149.],
           [146., 148., 167.,  ..., 167., 160., 160.],
           [155., 156., 167.,  ..., 160., 160., 150.],
           ...,
           [177., 168., 171.,  ..., 181., 193., 195.],
           [170., 160., 161.,  ..., 183., 186., 168.],
           [168., 201., 199.,  ..., 200., 184., 182.]],

          [[153., 157., 159.,  ..., 153., 145., 143.],
           [141., 140., 160.,  ..., 162., 154., 155.],
           [153., 152., 160.,  ..., 151., 152., 145.],
           ...,
           [170., 156., 161.,  ..., 179., 191., 193.],
           [166., 148., 151.,  ..., 181., 184., 166.],
           [164., 194., 195.,  ..., 198., 182., 180.]]]]])}
Given groups=1, weight of size [64, 64, 1, 1], expected input[1, 3, 32, 32] to have 64 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.60000000e+002, 1.67000000e+002, 1.65000000e+002 ... 1.54000000e+002, 1.48000000e+002, 1.46000000e+002],
    [1.46000000e+002, 1.47000000e+002, 1.66000000e+002 ... 1.65000000e+002, 1.58000000e+002, 1.58000000e+002],
    [1.55000000e+002, 1.55000000e+002, 1.66000000e+002 ... 1.56000000e+002, 1.57000000e+002, 1.48000000e+002],
    ...
    [1.74000000e+002, 1.64000000e+002, 1.68000000e+002 ... 1.81000000e+002, 1.93000000e+002, 1.95000000e+002],
    [1.65000000e+002, 1.54000000e+002, 1.56000000e+002 ... 1.83000000e+002, 1.86000000e+002, 1.68000000e+002],
    [1.66000000e+002, 1.99000000e+002, 1.98000000e+002 ... 2.00000000e+002, 1.84000000e+002, 1.82000000e+002]],
   [[1.61000000e+002, 1.69000000e+002, 1.66000000e+002 ... 1.55000000e+002, 1.50000000e+002, 1.49000000e+002],
    [1.46000000e+002, 1.48000000e+002, 1.67000000e+002 ... 1.67000000e+002, 1.60000000e+002, 1.60000000e+002],
    [1.55000000e+002, 1.56000000e+002, 1.67000000e+002 ... 1.60000000e+002, 1.60000000e+002, 1.50000000e+002],
    ...
    [1.77000000e+002, 1.68000000e+002, 1.71000000e+002 ... 1.81000000e+002, 1.93000000e+002, 1.95000000e+002],
    [1.70000000e+002, 1.60000000e+002, 1.61000000e+002 ... 1.83000000e+002, 1.86000000e+002, 1.68000000e+002],
    [1.68000000e+002, 2.01000000e+002, 1.99000000e+002 ... 2.00000000e+002, 1.84000000e+002, 1.82000000e+002]],
   [[1.53000000e+002, 1.57000000e+002, 1.59000000e+002 ... 1.53000000e+002, 1.45000000e+002, 1.43000000e+002],
    [1.41000000e+002, 1.40000000e+002, 1.60000000e+002 ... 1.62000000e+002, 1.54000000e+002, 1.55000000e+002],
    [1.53000000e+002, 1.52000000e+002, 1.60000000e+002 ... 1.51000000e+002, 1.52000000e+002, 1.45000000e+002],
    ...
    [1.70000000e+002, 1.56000000e+002, 1.61000000e+002 ... 1.79000000e+002, 1.91000000e+002, 1.93000000e+002],
    [1.66000000e+002, 1.48000000e+002, 1.51000000e+002 ... 1.81000000e+002, 1.84000000e+002, 1.66000000e+002],
    [1.64000000e+002, 1.94000000e+002, 1.95000000e+002 ... 1.98000000e+002, 1.82000000e+002, 1.80000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 64, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:227

analyse output arrays in iter:276

pre layer res:
4:conv2d
{'name': 'conv2d', 'output': array([[[[7.03530880e+07, 8.87360960e+07, 6.05883280e+07, ...,
          5.58697360e+07, 6.52086080e+07, 4.62030200e+07],
         [1.05677152e+08, 1.33595712e+08, 9.15542880e+07, ...,
          8.40504240e+07, 9.79112800e+07, 6.94029120e+07],
         [1.06496376e+08, 1.35168592e+08, 9.32582320e+07, ...,
          8.52300640e+07, 9.88615600e+07, 7.00582800e+07],
         ...,
         [1.42311872e+08, 2.14532768e+08, 2.10469536e+08, ...,
          1.66330880e+08, 1.76226896e+08, 1.22028400e+08],
         [1.46735584e+08, 2.20693168e+08, 2.17776816e+08, ...,
          1.94052784e+08, 1.97165728e+08, 1.33398992e+08],
         [9.99427200e+07, 1.49914080e+08, 1.48963792e+08, ...,
          1.45424864e+08, 1.46211264e+08, 9.77472320e+07]],

        [[7.03530880e+07, 8.87360960e+07, 6.05883280e+07, ...,
          5.58697360e+07, 6.52086080e+07, 4.62030200e+07],
         [1.05677152e+08, 1.33595712e+08, 9.15542880e+07, ...,
          8.40504240e+07, 9.79112800e+07, 6.94029120e+07],
         [1.06496376e+08, 1.35168592e+08, 9.32582320e+07, ...,
          8.52300640e+07, 9.88615600e+07, 7.00582800e+07],
         ...,
         [1.42311872e+08, 2.14532768e+08, 2.10469536e+08, ...,
          1.66330880e+08, 1.76226896e+08, 1.22028400e+08],
         [1.46735584e+08, 2.20693168e+08, 2.17776816e+08, ...,
          1.94052784e+08, 1.97165728e+08, 1.33398992e+08],
         [9.99427200e+07, 1.49914080e+08, 1.48963792e+08, ...,
          1.45424864e+08, 1.46211264e+08, 9.77472320e+07]],

        [[7.03530880e+07, 8.87360960e+07, 6.05883280e+07, ...,
          5.58697360e+07, 6.52086080e+07, 4.62030200e+07],
         [1.05677152e+08, 1.33595712e+08, 9.15542880e+07, ...,
          8.40504240e+07, 9.79112800e+07, 6.94029120e+07],
         [1.06496376e+08, 1.35168592e+08, 9.32582320e+07, ...,
          8.52300640e+07, 9.88615600e+07, 7.00582800e+07],
         ...,
         [1.42311872e+08, 2.14532768e+08, 2.10469536e+08, ...,
          1.66330880e+08, 1.76226896e+08, 1.22028400e+08],
         [1.46735584e+08, 2.20693168e+08, 2.17776816e+08, ...,
          1.94052784e+08, 1.97165728e+08, 1.33398992e+08],
         [9.99427200e+07, 1.49914080e+08, 1.48963792e+08, ...,
          1.45424864e+08, 1.46211264e+08, 9.77472320e+07]],

        ...,

        [[7.03530880e+07, 8.87360960e+07, 6.05883280e+07, ...,
          5.58697360e+07, 6.52086080e+07, 4.62030200e+07],
         [1.05677152e+08, 1.33595712e+08, 9.15542880e+07, ...,
          8.40504240e+07, 9.79112800e+07, 6.94029120e+07],
         [1.06496376e+08, 1.35168592e+08, 9.32582320e+07, ...,
          8.52300640e+07, 9.88615600e+07, 7.00582800e+07],
         ...,
         [1.42311872e+08, 2.14532768e+08, 2.10469536e+08, ...,
          1.66330880e+08, 1.76226896e+08, 1.22028400e+08],
         [1.46735584e+08, 2.20693168e+08, 2.17776816e+08, ...,
          1.94052784e+08, 1.97165728e+08, 1.33398992e+08],
         [9.99427200e+07, 1.49914080e+08, 1.48963792e+08, ...,
          1.45424864e+08, 1.46211264e+08, 9.77472320e+07]],

        [[7.03530880e+07, 8.87360960e+07, 6.05883280e+07, ...,
          5.58697360e+07, 6.52086080e+07, 4.62030200e+07],
         [1.05677152e+08, 1.33595712e+08, 9.15542880e+07, ...,
          8.40504240e+07, 9.79112800e+07, 6.94029120e+07],
         [1.06496376e+08, 1.35168592e+08, 9.32582320e+07, ...,
          8.52300640e+07, 9.88615600e+07, 7.00582800e+07],
         ...,
         [1.42311872e+08, 2.14532768e+08, 2.10469536e+08, ...,
          1.66330880e+08, 1.76226896e+08, 1.22028400e+08],
         [1.46735584e+08, 2.20693168e+08, 2.17776816e+08, ...,
          1.94052784e+08, 1.97165728e+08, 1.33398992e+08],
         [9.99427200e+07, 1.49914080e+08, 1.48963792e+08, ...,
          1.45424864e+08, 1.46211264e+08, 9.77472320e+07]],

        [[7.03530880e+07, 8.87360960e+07, 6.05883280e+07, ...,
          5.58697360e+07, 6.52086080e+07, 4.62030200e+07],
         [1.05677152e+08, 1.33595712e+08, 9.15542880e+07, ...,
          8.40504240e+07, 9.79112800e+07, 6.94029120e+07],
         [1.06496376e+08, 1.35168592e+08, 9.32582320e+07, ...,
          8.52300640e+07, 9.88615600e+07, 7.00582800e+07],
         ...,
         [1.42311872e+08, 2.14532768e+08, 2.10469536e+08, ...,
          1.66330880e+08, 1.76226896e+08, 1.22028400e+08],
         [1.46735584e+08, 2.20693168e+08, 2.17776816e+08, ...,
          1.94052784e+08, 1.97165728e+08, 1.33398992e+08],
         [9.99427200e+07, 1.49914080e+08, 1.48963792e+08, ...,
          1.45424864e+08, 1.46211264e+08, 9.77472320e+07]]]],
      dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [17], 'to': [15]}
tf node:
{'name': 'cos', 'output': array([[[[-0.20599109, -0.36272603,  0.78966606, ..., -0.56913435,
          -0.28105226,  0.99305093],
         [ 0.75969726,  0.9313437 , -0.9997525 , ..., -0.948241  ,
           0.33012453, -0.9981157 ],
         [-0.5263874 , -0.911218  , -0.78313076, ...,  0.99593157,
           0.96164256, -0.91392994],
         ...,
         [ 0.7683505 , -0.99388266,  0.98802257, ..., -0.0576171 ,
          -0.7934502 ,  0.9352328 ],
         [-0.9912447 , -0.8312598 ,  0.04531239, ...,  0.27502978,
           0.1903916 ,  0.99233073],
         [ 0.85768574,  0.68944997,  0.5279145 , ...,  0.958641  ,
          -0.81384254,  0.60618126]],

        [[-0.20599109, -0.36272603,  0.78966606, ..., -0.56913435,
          -0.28105226,  0.99305093],
         [ 0.75969726,  0.9313437 , -0.9997525 , ..., -0.948241  ,
           0.33012453, -0.9981157 ],
         [-0.5263874 , -0.911218  , -0.78313076, ...,  0.99593157,
           0.96164256, -0.91392994],
         ...,
         [ 0.7683505 , -0.99388266,  0.98802257, ..., -0.0576171 ,
          -0.7934502 ,  0.9352328 ],
         [-0.9912447 , -0.8312598 ,  0.04531239, ...,  0.27502978,
           0.1903916 ,  0.99233073],
         [ 0.85768574,  0.68944997,  0.5279145 , ...,  0.958641  ,
          -0.81384254,  0.60618126]],

        [[-0.20599109, -0.36272603,  0.78966606, ..., -0.56913435,
          -0.28105226,  0.99305093],
         [ 0.75969726,  0.9313437 , -0.9997525 , ..., -0.948241  ,
           0.33012453, -0.9981157 ],
         [-0.5263874 , -0.911218  , -0.78313076, ...,  0.99593157,
           0.96164256, -0.91392994],
         ...,
         [ 0.7683505 , -0.99388266,  0.98802257, ..., -0.0576171 ,
          -0.7934502 ,  0.9352328 ],
         [-0.9912447 , -0.8312598 ,  0.04531239, ...,  0.27502978,
           0.1903916 ,  0.99233073],
         [ 0.85768574,  0.68944997,  0.5279145 , ...,  0.958641  ,
          -0.81384254,  0.60618126]],

        ...,

        [[-0.20599109, -0.36272603,  0.78966606, ..., -0.56913435,
          -0.28105226,  0.99305093],
         [ 0.75969726,  0.9313437 , -0.9997525 , ..., -0.948241  ,
           0.33012453, -0.9981157 ],
         [-0.5263874 , -0.911218  , -0.78313076, ...,  0.99593157,
           0.96164256, -0.91392994],
         ...,
         [ 0.7683505 , -0.99388266,  0.98802257, ..., -0.0576171 ,
          -0.7934502 ,  0.9352328 ],
         [-0.9912447 , -0.8312598 ,  0.04531239, ...,  0.27502978,
           0.1903916 ,  0.99233073],
         [ 0.85768574,  0.68944997,  0.5279145 , ...,  0.958641  ,
          -0.81384254,  0.60618126]],

        [[-0.20599109, -0.36272603,  0.78966606, ..., -0.56913435,
          -0.28105226,  0.99305093],
         [ 0.75969726,  0.9313437 , -0.9997525 , ..., -0.948241  ,
           0.33012453, -0.9981157 ],
         [-0.5263874 , -0.911218  , -0.78313076, ...,  0.99593157,
           0.96164256, -0.91392994],
         ...,
         [ 0.7683505 , -0.99388266,  0.98802257, ..., -0.0576171 ,
          -0.7934502 ,  0.9352328 ],
         [-0.9912447 , -0.8312598 ,  0.04531239, ...,  0.27502978,
           0.1903916 ,  0.99233073],
         [ 0.85768574,  0.68944997,  0.5279145 , ...,  0.958641  ,
          -0.81384254,  0.60618126]],

        [[-0.20599109, -0.36272603,  0.78966606, ..., -0.56913435,
          -0.28105226,  0.99305093],
         [ 0.75969726,  0.9313437 , -0.9997525 , ..., -0.948241  ,
           0.33012453, -0.9981157 ],
         [-0.5263874 , -0.911218  , -0.78313076, ...,  0.99593157,
           0.96164256, -0.91392994],
         ...,
         [ 0.7683505 , -0.99388266,  0.98802257, ..., -0.0576171 ,
          -0.7934502 ,  0.9352328 ],
         [-0.9912447 , -0.8312598 ,  0.04531239, ...,  0.27502978,
           0.1903916 ,  0.99233073],
         [ 0.85768574,  0.68944997,  0.5279145 , ...,  0.958641  ,
          -0.81384254,  0.60618126]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [4], 'to': [7]}
ms node:
{'name': 'cos', 'output': array([[[[ 0.4789982 , -0.7735688 ,  0.3371555 , ...,  0.51841074,
           0.9903728 , -0.7615837 ],
         [ 0.8038019 ,  0.81480265, -0.5064953 , ...,  0.51411545,
          -0.958973  , -0.36781383],
         [ 0.4860671 ,  0.829174  , -0.99986833, ...,  0.98705995,
           0.9800688 ,  0.30711406],
         ...,
         [ 0.9683943 , -0.61597383,  0.80115163, ..., -0.19795562,
          -0.3252656 ,  0.6394005 ],
         [ 0.95497084, -0.70302445, -0.97238773, ..., -0.4950453 ,
           0.83496475,  0.11924827],
         [ 0.367079  , -0.3212696 ,  0.40275097, ..., -0.75030863,
           0.8917277 ,  0.6609333 ]],

        [[ 0.4789982 , -0.7735688 ,  0.3371555 , ...,  0.51841074,
           0.9903728 , -0.7615837 ],
         [ 0.8038019 ,  0.81480265, -0.5064953 , ...,  0.51411545,
          -0.958973  , -0.36781383],
         [ 0.4860671 ,  0.829174  , -0.99986833, ...,  0.98705995,
           0.9800688 ,  0.30711406],
         ...,
         [ 0.9683943 , -0.61597383,  0.80115163, ..., -0.19795562,
          -0.3252656 ,  0.6394005 ],
         [ 0.95497084, -0.70302445, -0.97238773, ..., -0.4950453 ,
           0.83496475,  0.11924827],
         [ 0.367079  , -0.3212696 ,  0.40275097, ..., -0.75030863,
           0.8917277 ,  0.6609333 ]],

        [[ 0.4789982 , -0.7735688 ,  0.3371555 , ...,  0.51841074,
           0.9903728 , -0.7615837 ],
         [ 0.8038019 ,  0.81480265, -0.5064953 , ...,  0.51411545,
          -0.958973  , -0.36781383],
         [ 0.4860671 ,  0.829174  , -0.99986833, ...,  0.98705995,
           0.9800688 ,  0.30711406],
         ...,
         [ 0.9683943 , -0.61597383,  0.80115163, ..., -0.19795562,
          -0.3252656 ,  0.6394005 ],
         [ 0.95497084, -0.70302445, -0.97238773, ..., -0.4950453 ,
           0.83496475,  0.11924827],
         [ 0.367079  , -0.3212696 ,  0.40275097, ..., -0.75030863,
           0.8917277 ,  0.6609333 ]],

        ...,

        [[ 0.4789982 , -0.7735688 ,  0.3371555 , ...,  0.51841074,
           0.9903728 , -0.7615837 ],
         [ 0.8038019 ,  0.81480265, -0.5064953 , ...,  0.51411545,
          -0.958973  , -0.36781383],
         [ 0.4860671 ,  0.829174  , -0.99986833, ...,  0.98705995,
           0.9800688 ,  0.30711406],
         ...,
         [ 0.9683943 , -0.61597383,  0.80115163, ..., -0.19795562,
          -0.3252656 ,  0.6394005 ],
         [ 0.95497084, -0.70302445, -0.97238773, ..., -0.4950453 ,
           0.83496475,  0.11924827],
         [ 0.367079  , -0.3212696 ,  0.40275097, ..., -0.75030863,
           0.8917277 ,  0.6609333 ]],

        [[ 0.4789982 , -0.7735688 ,  0.3371555 , ...,  0.51841074,
           0.9903728 , -0.7615837 ],
         [ 0.8038019 ,  0.81480265, -0.5064953 , ...,  0.51411545,
          -0.958973  , -0.36781383],
         [ 0.4860671 ,  0.829174  , -0.99986833, ...,  0.98705995,
           0.9800688 ,  0.30711406],
         ...,
         [ 0.9683943 , -0.61597383,  0.80115163, ..., -0.19795562,
          -0.3252656 ,  0.6394005 ],
         [ 0.95497084, -0.70302445, -0.97238773, ..., -0.4950453 ,
           0.83496475,  0.11924827],
         [ 0.367079  , -0.3212696 ,  0.40275097, ..., -0.75030863,
           0.8917277 ,  0.6609333 ]],

        [[ 0.4789982 , -0.7735688 ,  0.3371555 , ...,  0.51841074,
           0.9903728 , -0.7615837 ],
         [ 0.8038019 ,  0.81480265, -0.5064953 , ...,  0.51411545,
          -0.958973  , -0.36781383],
         [ 0.4860671 ,  0.829174  , -0.99986833, ...,  0.98705995,
           0.9800688 ,  0.30711406],
         ...,
         [ 0.9683943 , -0.61597383,  0.80115163, ..., -0.19795562,
          -0.3252656 ,  0.6394005 ],
         [ 0.95497084, -0.70302445, -0.97238773, ..., -0.4950453 ,
           0.83496475,  0.11924827],
         [ 0.367079  , -0.3212696 ,  0.40275097, ..., -0.75030863,
           0.8917277 ,  0.6609333 ]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [4], 'to': [7]}
torch node:
{'name': 'cos', 'output': array([[[[ 0.89966094, -0.9850589 , -0.8973762 , ..., -0.9674329 ,
           0.4692249 ,  0.78591216],
         [-0.1280078 ,  0.83363205, -0.2365153 , ..., -0.99648255,
          -0.21962225, -0.82899576],
         [-0.9669242 , -0.9775845 ,  0.7065961 , ...,  0.9502342 ,
           0.30398968,  0.37367737],
         ...,
         [-0.42005855, -0.71495664,  0.5063671 , ...,  0.78212184,
           0.9887907 ,  0.61178297],
         [ 0.18946993,  0.37880573, -0.59574467, ...,  0.9182039 ,
          -0.6391098 ,  0.9550533 ],
         [ 0.33392182,  0.98941237, -0.9729558 , ..., -0.57422304,
           0.3513712 , -0.818817  ]],

        [[ 0.89966094, -0.9850589 , -0.8973762 , ..., -0.9674329 ,
           0.4692249 ,  0.78591216],
         [-0.1280078 ,  0.83363205, -0.2365153 , ..., -0.99648255,
          -0.21962225, -0.82899576],
         [-0.9669242 , -0.9775845 ,  0.7065961 , ...,  0.9502342 ,
           0.30398968,  0.37367737],
         ...,
         [-0.42005855, -0.71495664,  0.5063671 , ...,  0.78212184,
           0.9887907 ,  0.61178297],
         [ 0.18946993,  0.37880573, -0.59574467, ...,  0.9182039 ,
          -0.6391098 ,  0.9550533 ],
         [ 0.33392182,  0.98941237, -0.9729558 , ..., -0.57422304,
           0.3513712 , -0.818817  ]],

        [[ 0.89966094, -0.9850589 , -0.8973762 , ..., -0.9674329 ,
           0.4692249 ,  0.78591216],
         [-0.1280078 ,  0.83363205, -0.2365153 , ..., -0.99648255,
          -0.21962225, -0.82899576],
         [-0.9669242 , -0.9775845 ,  0.7065961 , ...,  0.9502342 ,
           0.30398968,  0.37367737],
         ...,
         [-0.42005855, -0.71495664,  0.5063671 , ...,  0.78212184,
           0.9887907 ,  0.61178297],
         [ 0.18946993,  0.37880573, -0.59574467, ...,  0.9182039 ,
          -0.6391098 ,  0.9550533 ],
         [ 0.33392182,  0.98941237, -0.9729558 , ..., -0.57422304,
           0.3513712 , -0.818817  ]],

        ...,

        [[ 0.89966094, -0.9850589 , -0.8973762 , ..., -0.9674329 ,
           0.4692249 ,  0.78591216],
         [-0.1280078 ,  0.83363205, -0.2365153 , ..., -0.99648255,
          -0.21962225, -0.82899576],
         [-0.9669242 , -0.9775845 ,  0.7065961 , ...,  0.9502342 ,
           0.30398968,  0.37367737],
         ...,
         [-0.42005855, -0.71495664,  0.5063671 , ...,  0.78212184,
           0.9887907 ,  0.61178297],
         [ 0.18946993,  0.37880573, -0.59574467, ...,  0.9182039 ,
          -0.6391098 ,  0.9550533 ],
         [ 0.33392182,  0.98941237, -0.9729558 , ..., -0.57422304,
           0.3513712 , -0.818817  ]],

        [[ 0.89966094, -0.9850589 , -0.8973762 , ..., -0.9674329 ,
           0.4692249 ,  0.78591216],
         [-0.1280078 ,  0.83363205, -0.2365153 , ..., -0.99648255,
          -0.21962225, -0.82899576],
         [-0.9669242 , -0.9775845 ,  0.7065961 , ...,  0.9502342 ,
           0.30398968,  0.37367737],
         ...,
         [-0.42005855, -0.71495664,  0.5063671 , ...,  0.78212184,
           0.9887907 ,  0.61178297],
         [ 0.18946993,  0.37880573, -0.59574467, ...,  0.9182039 ,
          -0.6391098 ,  0.9550533 ],
         [ 0.33392182,  0.98941237, -0.9729558 , ..., -0.57422304,
           0.3513712 , -0.818817  ]],

        [[ 0.89966094, -0.9850589 , -0.8973762 , ..., -0.9674329 ,
           0.4692249 ,  0.78591216],
         [-0.1280078 ,  0.83363205, -0.2365153 , ..., -0.99648255,
          -0.21962225, -0.82899576],
         [-0.9669242 , -0.9775845 ,  0.7065961 , ...,  0.9502342 ,
           0.30398968,  0.37367737],
         ...,
         [-0.42005855, -0.71495664,  0.5063671 , ...,  0.78212184,
           0.9887907 ,  0.61178297],
         [ 0.18946993,  0.37880573, -0.59574467, ...,  0.9182039 ,
          -0.6391098 ,  0.9550533 ],
         [ 0.33392182,  0.98941237, -0.9729558 , ..., -0.57422304,
           0.3513712 , -0.818817  ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [4], 'to': [7]}

generate models:231

analyse the exceptions in iter:279
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[172., 166., 162.,  ..., 159., 157., 158.],
           [176., 169., 168.,  ..., 160., 160., 160.],
           [174., 164., 169.,  ..., 157., 155., 162.],
           ...,
           [164., 161., 162.,  ..., 144., 138., 141.],
           [164., 163., 163.,  ..., 146., 136., 134.],
           [167., 164., 163.,  ..., 142., 136., 133.]],

          [[156., 150., 146.,  ..., 153., 151., 152.],
           [161., 154., 153.,  ..., 154., 154., 154.],
           [161., 151., 157.,  ..., 151., 149., 156.],
           ...,
           [152., 149., 151.,  ..., 142., 137., 140.],
           [152., 151., 153.,  ..., 145., 137., 136.],
           [156., 152., 152.,  ..., 143., 137., 135.]],

          [[ 78.,  73.,  69.,  ...,  76.,  74.,  74.],
           [ 82.,  76.,  75.,  ...,  76.,  76.,  74.],
           [ 81.,  72.,  78.,  ...,  73.,  71.,  78.],
           ...,
           [ 77.,  73.,  69.,  ...,  66.,  62.,  60.],
           [ 75.,  76.,  70.,  ...,  70.,  63.,  57.],
           [ 75.,  79.,  72.,  ...,  68.,  64.,  57.]]]]])}
Given groups=1, weight of size [128, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.72000000e+002, 1.66000000e+002, 1.62000000e+002 ... 1.59000000e+002, 1.57000000e+002, 1.58000000e+002],
    [1.76000000e+002, 1.69000000e+002, 1.68000000e+002 ... 1.60000000e+002, 1.60000000e+002, 1.60000000e+002],
    [1.74000000e+002, 1.64000000e+002, 1.69000000e+002 ... 1.57000000e+002, 1.55000000e+002, 1.62000000e+002],
    ...
    [1.64000000e+002, 1.61000000e+002, 1.62000000e+002 ... 1.44000000e+002, 1.38000000e+002, 1.41000000e+002],
    [1.64000000e+002, 1.63000000e+002, 1.63000000e+002 ... 1.46000000e+002, 1.36000000e+002, 1.34000000e+002],
    [1.67000000e+002, 1.64000000e+002, 1.63000000e+002 ... 1.42000000e+002, 1.36000000e+002, 1.33000000e+002]],
   [[1.56000000e+002, 1.50000000e+002, 1.46000000e+002 ... 1.53000000e+002, 1.51000000e+002, 1.52000000e+002],
    [1.61000000e+002, 1.54000000e+002, 1.53000000e+002 ... 1.54000000e+002, 1.54000000e+002, 1.54000000e+002],
    [1.61000000e+002, 1.51000000e+002, 1.57000000e+002 ... 1.51000000e+002, 1.49000000e+002, 1.56000000e+002],
    ...
    [1.52000000e+002, 1.49000000e+002, 1.51000000e+002 ... 1.42000000e+002, 1.37000000e+002, 1.40000000e+002],
    [1.52000000e+002, 1.51000000e+002, 1.53000000e+002 ... 1.45000000e+002, 1.37000000e+002, 1.36000000e+002],
    [1.56000000e+002, 1.52000000e+002, 1.52000000e+002 ... 1.43000000e+002, 1.37000000e+002, 1.35000000e+002]],
   [[7.80000000e+001, 7.30000000e+001, 6.90000000e+001 ... 7.60000000e+001, 7.40000000e+001, 7.40000000e+001],
    [8.20000000e+001, 7.60000000e+001, 7.50000000e+001 ... 7.60000000e+001, 7.60000000e+001, 7.40000000e+001],
    [8.10000000e+001, 7.20000000e+001, 7.80000000e+001 ... 7.30000000e+001, 7.10000000e+001, 7.80000000e+001],
    ...
    [7.70000000e+001, 7.30000000e+001, 6.90000000e+001 ... 6.60000000e+001, 6.20000000e+001, 6.00000000e+001],
    [7.50000000e+001, 7.60000000e+001, 7.00000000e+001 ... 7.00000000e+001, 6.30000000e+001, 5.70000000e+001],
    [7.50000000e+001, 7.90000000e+001, 7.20000000e+001 ... 6.80000000e+001, 6.40000000e+001, 5.70000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:234

analyse the exceptions in iter:285
torch exception:
{'id': 4, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          ...,
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf]],

         [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          ...,
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf]],

         [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          ...,
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf]],

         ...,

         [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          ...,
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf]],

         [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          ...,
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf]],

         [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          ...,
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf],
          [-inf, -inf, -inf,  ..., -inf, -inf, -inf]]]])]}
Given groups=1, weight of size [64, 64, 1, 1], expected input[1, 512, 16, 100] to have 64 channels, but got 512 channels instead
mindspore exception:
{'id': 4, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 512, 16, 100], dtype=Float32, value=
[[[[           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   ...
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf]],
  [[           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   ...
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf]],
  [[           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   ...
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf]],
  ...
  [[           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   ...
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf]],
  [[           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   ...
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf]],
  [[           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   ...
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf],
   [           -inf,            -inf,            -inf ...            -inf,            -inf,            -inf]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 64, but got 'C_in' of input 'x' shape: 512, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:237

analyse the exceptions in iter:286
torch exception:
{'id': 3, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[496., 288., 266.,  ..., 312., 289., 338.],
          [285., 269., 230.,  ..., 305., 258., 248.],
          [348., 337., 407.,  ..., 234., 314., 373.],
          ...,
          [146.,  91., 140.,  ..., 165., 158., 142.],
          [142., 121., 104.,  ..., 332., 404., 421.],
          [514., 254., 242.,  ..., 260., 369., 363.]],

         [[502., 321., 297.,  ..., 397., 230., 247.],
          [250., 243., 309.,  ..., 292., 288., 291.],
          [252., 244., 329.,  ..., 346., 317., 378.],
          ...,
          [140., 133., 172.,  ..., 411., 342., 255.],
          [244., 325., 403.,  ..., 262., 206., 325.],
          [274., 309., 437.,  ..., 277., 261., 257.]],

         [[387., 445., 294.,  ..., 347., 379., 284.],
          [363., 415., 345.,  ..., 467., 451., 519.],
          [587., 410., 316.,  ..., 408., 332., 320.],
          ...,
          [490., 450., 404.,  ..., 513., 459., 407.],
          [291., 293., 228.,  ..., 387., 254., 203.],
          [298., 305., 240.,  ..., 293., 294., 274.]],

         ...,

         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          ...,
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          ...,
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          ...,
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],
       grad_fn=<ReshapeAliasBackward0>)]}
Given groups=1, weight of size [128, 128, 1, 1], expected input[1, 256, 32, 100] to have 128 channels, but got 256 channels instead
mindspore exception:
{'id': 3, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 256, 32, 100], dtype=Float32, value=
[[[[4.96000000e+002, 2.88000000e+002, 2.66000000e+002 ... 3.12000000e+002, 2.89000000e+002, 3.38000000e+002],
   [2.85000000e+002, 2.69000000e+002, 2.30000000e+002 ... 3.05000000e+002, 2.58000000e+002, 2.48000000e+002],
   [3.48000000e+002, 3.37000000e+002, 4.07000000e+002 ... 2.34000000e+002, 3.14000000e+002, 3.73000000e+002],
   ...
   [1.46000000e+002, 9.10000000e+001, 1.40000000e+002 ... 1.65000000e+002, 1.58000000e+002, 1.42000000e+002],
   [1.42000000e+002, 1.21000000e+002, 1.04000000e+002 ... 3.32000000e+002, 4.04000000e+002, 4.21000000e+002],
   [5.14000000e+002, 2.54000000e+002, 2.42000000e+002 ... 2.60000000e+002, 3.69000000e+002, 3.63000000e+002]],
  [[5.02000000e+002, 3.21000000e+002, 2.97000000e+002 ... 3.97000000e+002, 2.30000000e+002, 2.47000000e+002],
   [2.50000000e+002, 2.43000000e+002, 3.09000000e+002 ... 2.92000000e+002, 2.88000000e+002, 2.91000000e+002],
   [2.52000000e+002, 2.44000000e+002, 3.29000000e+002 ... 3.46000000e+002, 3.17000000e+002, 3.78000000e+002],
   ...
   [1.40000000e+002, 1.33000000e+002, 1.72000000e+002 ... 4.11000000e+002, 3.42000000e+002, 2.55000000e+002],
   [2.44000000e+002, 3.25000000e+002, 4.03000000e+002 ... 2.62000000e+002, 2.06000000e+002, 3.25000000e+002],
   [2.74000000e+002, 3.09000000e+002, 4.37000000e+002 ... 2.77000000e+002, 2.61000000e+002, 2.57000000e+002]],
  [[3.87000000e+002, 4.45000000e+002, 2.94000000e+002 ... 3.47000000e+002, 3.79000000e+002, 2.84000000e+002],
   [3.63000000e+002, 4.15000000e+002, 3.45000000e+002 ... 4.67000000e+002, 4.51000000e+002, 5.19000000e+002],
   [5.87000000e+002, 4.10000000e+002, 3.16000000e+002 ... 4.08000000e+002, 3.32000000e+002, 3.20000000e+002],
   ...
   [4.90000000e+002, 4.50000000e+002, 4.04000000e+002 ... 5.13000000e+002, 4.59000000e+002, 4.07000000e+002],
   [2.91000000e+002, 2.93000000e+002, 2.28000000e+002 ... 3.87000000e+002, 2.54000000e+002, 2.03000000e+002],
   [2.98000000e+002, 3.05000000e+002, 2.40000000e+002 ... 2.93000000e+002, 2.94000000e+002, 2.74000000e+002]],
  ...
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 256, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:238

analyse the exceptions in iter:295
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[363264., 364288., 360192.,  ..., 390400., 388864., 391936.],
          [373504., 374016., 370432.,  ..., 391936., 390400., 391936.],
          [373504., 374528., 379648.,  ..., 391936., 391936., 391936.],
          ...,
          [168192., 157952., 161536.,  ..., 124672., 119552., 109312.],
          [167168., 176384., 171264.,  ..., 124672., 122112., 119040.],
          [192768., 190720., 194304.,  ..., 127744., 127232., 127232.]],

         [[363264., 364288., 360192.,  ..., 390400., 388864., 391936.],
          [373504., 374016., 370432.,  ..., 391936., 390400., 391936.],
          [373504., 374528., 379648.,  ..., 391936., 391936., 391936.],
          ...,
          [168192., 157952., 161536.,  ..., 124672., 119552., 109312.],
          [167168., 176384., 171264.,  ..., 124672., 122112., 119040.],
          [192768., 190720., 194304.,  ..., 127744., 127232., 127232.]],

         [[363264., 364288., 360192.,  ..., 390400., 388864., 391936.],
          [373504., 374016., 370432.,  ..., 391936., 390400., 391936.],
          [373504., 374528., 379648.,  ..., 391936., 391936., 391936.],
          ...,
          [168192., 157952., 161536.,  ..., 124672., 119552., 109312.],
          [167168., 176384., 171264.,  ..., 124672., 122112., 119040.],
          [192768., 190720., 194304.,  ..., 127744., 127232., 127232.]],

         ...,

         [[363264., 364288., 360192.,  ..., 390400., 388864., 391936.],
          [373504., 374016., 370432.,  ..., 391936., 390400., 391936.],
          [373504., 374528., 379648.,  ..., 391936., 391936., 391936.],
          ...,
          [168192., 157952., 161536.,  ..., 124672., 119552., 109312.],
          [167168., 176384., 171264.,  ..., 124672., 122112., 119040.],
          [192768., 190720., 194304.,  ..., 127744., 127232., 127232.]],

         [[363264., 364288., 360192.,  ..., 390400., 388864., 391936.],
          [373504., 374016., 370432.,  ..., 391936., 390400., 391936.],
          [373504., 374528., 379648.,  ..., 391936., 391936., 391936.],
          ...,
          [168192., 157952., 161536.,  ..., 124672., 119552., 109312.],
          [167168., 176384., 171264.,  ..., 124672., 122112., 119040.],
          [192768., 190720., 194304.,  ..., 127744., 127232., 127232.]],

         [[363264., 364288., 360192.,  ..., 390400., 388864., 391936.],
          [373504., 374016., 370432.,  ..., 391936., 390400., 391936.],
          [373504., 374528., 379648.,  ..., 391936., 391936., 391936.],
          ...,
          [168192., 157952., 161536.,  ..., 124672., 119552., 109312.],
          [167168., 176384., 171264.,  ..., 124672., 122112., 119040.],
          [192768., 190720., 194304.,  ..., 127744., 127232., 127232.]]]],
       grad_fn=<ConvolutionBackward0>)]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 512, 32, 32] to have 256 channels, but got 512 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 512, 32, 32], dtype=Float32, value=
[[[[3.63264000e+005, 3.64288000e+005, 3.60192000e+005 ... 3.90400000e+005, 3.88864000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74016000e+005, 3.70432000e+005 ... 3.91936000e+005, 3.90400000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74528000e+005, 3.79648000e+005 ... 3.91936000e+005, 3.91936000e+005, 3.91936000e+005],
   ...
   [1.68192000e+005, 1.57952000e+005, 1.61536000e+005 ... 1.24672000e+005, 1.19552000e+005, 1.09312000e+005],
   [1.67168000e+005, 1.76384000e+005, 1.71264000e+005 ... 1.24672000e+005, 1.22112000e+005, 1.19040000e+005],
   [1.92768000e+005, 1.90720000e+005, 1.94304000e+005 ... 1.27744000e+005, 1.27232000e+005, 1.27232000e+005]],
  [[3.63264000e+005, 3.64288000e+005, 3.60192000e+005 ... 3.90400000e+005, 3.88864000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74016000e+005, 3.70432000e+005 ... 3.91936000e+005, 3.90400000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74528000e+005, 3.79648000e+005 ... 3.91936000e+005, 3.91936000e+005, 3.91936000e+005],
   ...
   [1.68192000e+005, 1.57952000e+005, 1.61536000e+005 ... 1.24672000e+005, 1.19552000e+005, 1.09312000e+005],
   [1.67168000e+005, 1.76384000e+005, 1.71264000e+005 ... 1.24672000e+005, 1.22112000e+005, 1.19040000e+005],
   [1.92768000e+005, 1.90720000e+005, 1.94304000e+005 ... 1.27744000e+005, 1.27232000e+005, 1.27232000e+005]],
  [[3.63264000e+005, 3.64288000e+005, 3.60192000e+005 ... 3.90400000e+005, 3.88864000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74016000e+005, 3.70432000e+005 ... 3.91936000e+005, 3.90400000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74528000e+005, 3.79648000e+005 ... 3.91936000e+005, 3.91936000e+005, 3.91936000e+005],
   ...
   [1.68192000e+005, 1.57952000e+005, 1.61536000e+005 ... 1.24672000e+005, 1.19552000e+005, 1.09312000e+005],
   [1.67168000e+005, 1.76384000e+005, 1.71264000e+005 ... 1.24672000e+005, 1.22112000e+005, 1.19040000e+005],
   [1.92768000e+005, 1.90720000e+005, 1.94304000e+005 ... 1.27744000e+005, 1.27232000e+005, 1.27232000e+005]],
  ...
  [[3.63264000e+005, 3.64288000e+005, 3.60192000e+005 ... 3.90400000e+005, 3.88864000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74016000e+005, 3.70432000e+005 ... 3.91936000e+005, 3.90400000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74528000e+005, 3.79648000e+005 ... 3.91936000e+005, 3.91936000e+005, 3.91936000e+005],
   ...
   [1.68192000e+005, 1.57952000e+005, 1.61536000e+005 ... 1.24672000e+005, 1.19552000e+005, 1.09312000e+005],
   [1.67168000e+005, 1.76384000e+005, 1.71264000e+005 ... 1.24672000e+005, 1.22112000e+005, 1.19040000e+005],
   [1.92768000e+005, 1.90720000e+005, 1.94304000e+005 ... 1.27744000e+005, 1.27232000e+005, 1.27232000e+005]],
  [[3.63264000e+005, 3.64288000e+005, 3.60192000e+005 ... 3.90400000e+005, 3.88864000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74016000e+005, 3.70432000e+005 ... 3.91936000e+005, 3.90400000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74528000e+005, 3.79648000e+005 ... 3.91936000e+005, 3.91936000e+005, 3.91936000e+005],
   ...
   [1.68192000e+005, 1.57952000e+005, 1.61536000e+005 ... 1.24672000e+005, 1.19552000e+005, 1.09312000e+005],
   [1.67168000e+005, 1.76384000e+005, 1.71264000e+005 ... 1.24672000e+005, 1.22112000e+005, 1.19040000e+005],
   [1.92768000e+005, 1.90720000e+005, 1.94304000e+005 ... 1.27744000e+005, 1.27232000e+005, 1.27232000e+005]],
  [[3.63264000e+005, 3.64288000e+005, 3.60192000e+005 ... 3.90400000e+005, 3.88864000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74016000e+005, 3.70432000e+005 ... 3.91936000e+005, 3.90400000e+005, 3.91936000e+005],
   [3.73504000e+005, 3.74528000e+005, 3.79648000e+005 ... 3.91936000e+005, 3.91936000e+005, 3.91936000e+005],
   ...
   [1.68192000e+005, 1.57952000e+005, 1.61536000e+005 ... 1.24672000e+005, 1.19552000e+005, 1.09312000e+005],
   [1.67168000e+005, 1.76384000e+005, 1.71264000e+005 ... 1.24672000e+005, 1.22112000e+005, 1.19040000e+005],
   [1.92768000e+005, 1.90720000e+005, 1.94304000e+005 ... 1.27744000e+005, 1.27232000e+005, 1.27232000e+005]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 512, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:246

analyse output arrays in iter:303

pre layer res:
9:log
{'name': 'log', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 16]), 'from': [2], 'to': [3]}
tf node:
{'name': 'maxpool2d', 'output': array([[[[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        ...,

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]]]],
      dtype=float32), 'output_shape': TensorShape([1, 512, 8, 8]), 'from': [9], 'to': []}
ms node:
{'name': 'maxpool2d', 'output': array([[[[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        ...,

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]]]],
      dtype=float32), 'output_shape': (1, 512, 8, 8), 'from': [9], 'to': []}
torch node:
{'name': 'maxpool2d', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 8, 8]), 'from': [9], 'to': []}

generate models:253

analyse output arrays in iter:304

pre layer res:
15:add
{'name': 'add', 'output': array([[[           inf, 4.09399685e+35,            inf,            inf,
                    inf, 2.03828115e+34, 9.25378162e+29, 5.68572002e+24,
         7.69478547e+23, 1.14200740e+26, 7.49841698e+33, 3.02507734e+36,
         2.51543870e+30, 1.69488921e+28, 1.01480034e+33, 3.73324224e+32,
         9.25378162e+29, 6.23514884e+27, 2.83075322e+23, 7.01673559e+20,
         3.49342706e+19, 9.49611953e+19, 1.28515999e+19, 4.31123180e+15,
         2.14643591e+14, 3.93133425e+12, 3.93133425e+12, 1.58601345e+15,
         1.40934904e+22, 1.69488921e+28, 2.75851355e+33,            inf],
        [8.22301239e+36, 1.14200740e+26,            inf,            inf,
                    inf, 8.22301239e+36, 8.22301239e+36, 4.09399685e+35,
         3.40427617e+29, 1.54553889e+25, 3.73324224e+32, 5.05239356e+31,
         1.54553889e+25, 1.37338306e+32,            inf,            inf,
                    inf, 6.07603035e+37, 6.83767114e+30, 2.29378327e+27,
         2.09165959e+24, 1.73927498e+18, 3.93133425e+12, 5.32048216e+11,
         5.32048216e+11, 3.93133425e+12, 2.35385253e+17, 6.23514884e+27,
         4.09399685e+35, 1.01480034e+33, 5.68572002e+24, 6.83767114e+30],
        [2.03828115e+34, 1.65163627e+38,            inf,            inf,
         2.75851355e+33,            inf,            inf,            inf,
         7.49841698e+33, 3.10429778e+26, 9.25378162e+29, 2.75851355e+33,
         1.65163627e+38,            inf,            inf,            inf,
         2.23524653e+37, 1.50609736e+35, 2.03828115e+34, 2.75851355e+33,
         2.29378327e+27, 7.01673559e+20, 1.17191425e+16, 1.28515999e+19,
         1.54553889e+25, 3.40427617e+29, 1.01480034e+33, 2.03828115e+34,
         1.37338306e+32, 4.20121045e+25, 7.69478547e+23, 2.51543870e+30]]],
      dtype=float32), 'output_shape': TensorShape([1, 3, 32]), 'from': [6, 18], 'to': [12]}
tf node:
{'name': 'sin', 'output': array([[[        nan, -0.9400254 ,         nan,         nan,
                 nan, -0.61439854, -0.7398784 ,  0.06715184,
          0.992944  ,  0.40051377,  0.7574497 , -0.32816833,
          0.89168143, -0.7533393 , -0.9325689 , -0.48129064,
         -0.7398784 , -0.9992202 , -0.7437689 ,  0.936549  ,
         -0.19850658, -0.92996293, -0.5310695 ,  0.531357  ,
          0.6630395 ,  0.07053794,  0.07053794, -0.9429934 ,
          0.9353243 , -0.7533393 , -0.78602695,         nan],
        [ 0.02346549,  0.40051377,         nan,         nan,
                 nan,  0.02346549,  0.02346549, -0.9400254 ,
         -0.542743  ,  0.9818572 , -0.48129064, -0.9465945 ,
          0.9818572 ,  0.11015363,         nan,         nan,
                 nan,  0.4087277 , -0.56593406, -0.6347794 ,
         -0.45884642,  0.03048715,  0.07053794, -0.92895585,
         -0.92895585,  0.07053794, -0.7495278 , -0.9992202 ,
         -0.9400254 , -0.9325689 ,  0.06715184, -0.56593406],
        [-0.61439854, -0.17997307,         nan,         nan,
         -0.78602695,         nan,         nan,         nan,
          0.7574497 , -0.4769409 , -0.7398784 , -0.78602695,
         -0.17997307,         nan,         nan,         nan,
         -0.7855283 ,  0.39501524, -0.61439854, -0.78602695,
         -0.6347794 ,  0.936549  , -0.6532907 , -0.5310695 ,
          0.9818572 , -0.542743  , -0.9325689 , -0.61439854,
          0.11015363,  0.98839915,  0.992944  ,  0.89168143]]],
      dtype=float32), 'output_shape': TensorShape([1, 3, 32]), 'from': [15], 'to': [7]}
ms node:
{'name': 'sin', 'output': array([[[        nan,  0.39603096,         nan,         nan,
                 nan,  0.81708694,  0.10704125,  0.8500537 ,
          0.7138806 , -0.99982095, -0.63037264,  0.9769175 ,
         -0.7804324 , -0.4540636 ,  0.23482543, -0.3892945 ,
          0.10704125, -0.8658157 , -0.9993184 ,  0.4370445 ,
          0.37345344,  0.92970467, -0.9993704 , -0.4895594 ,
          0.99884605, -0.09766053, -0.09766053, -0.17208557,
          0.5002549 , -0.4540636 , -0.79655224,         nan],
        [ 0.08509474, -0.99982095,         nan,         nan,
                 nan,  0.08509474,  0.08509474,  0.39603096,
         -0.19222502, -0.38642263, -0.3892945 , -0.93582237,
         -0.38642263,  0.9513449 ,         nan,         nan,
                 nan,  0.9974514 ,  0.5911699 , -0.25192514,
          0.9146128 , -0.3646076 , -0.09766053, -0.9289558 ,
         -0.9289558 , -0.09766053,  0.14684047, -0.8658157 ,
          0.39603096,  0.23482543,  0.8500537 ,  0.5911699 ],
        [ 0.81708694, -0.46192455,         nan,         nan,
         -0.79655224,         nan,         nan,         nan,
         -0.63037264,  0.569605  ,  0.10704125, -0.79655224,
         -0.46192455,         nan,         nan,         nan,
          0.98528636, -0.5363818 ,  0.81708694, -0.79655224,
         -0.25192514,  0.4370445 , -0.9813336 , -0.9993704 ,
         -0.38642263, -0.19222502,  0.23482543,  0.81708694,
          0.9513449 , -0.9453893 ,  0.7138806 , -0.7804324 ]]],
      dtype=float32), 'output_shape': (1, 3, 32), 'from': [15], 'to': [7]}
torch node:
{'name': 'sin', 'output': array([[[        nan, -0.9400254 ,         nan,         nan,
                 nan,  0.45147815, -0.7398784 ,  0.06715184,
          0.992944  ,  0.40051377,  0.7574497 , -0.32816833,
          0.89168143, -0.75333923, -0.9325689 ,  0.8930073 ,
         -0.7398784 , -0.9992202 , -0.7437689 ,  0.936549  ,
         -0.19850658, -0.92996293, -0.53106946,  0.7474796 ,
          0.9988461 ,  0.07053794,  0.07053794, -0.9429934 ,
          0.9875721 , -0.75333923, -0.7860269 ,         nan],
        [ 0.02346548,  0.40051377,         nan,         nan,
                 nan,  0.02346548,  0.02346548, -0.9400254 ,
         -0.542743  ,  0.9818572 ,  0.8930073 , -0.9465945 ,
          0.9818572 ,  0.8718129 ,         nan,         nan,
                 nan,  0.40872774, -0.56593406, -0.7685224 ,
         -0.03852721,  0.03048715,  0.07053794, -0.00295908,
         -0.00295908,  0.07053794, -0.3646984 , -0.9992202 ,
         -0.9400254 , -0.9325689 ,  0.06715184, -0.56593406],
        [ 0.45147815, -0.17997307,         nan,         nan,
         -0.7860269 ,         nan,         nan,         nan,
          0.7574497 , -0.4769409 , -0.7398784 , -0.7860269 ,
         -0.17997307,         nan,         nan,         nan,
         -0.7855283 ,  0.39501524,  0.45147815, -0.7860269 ,
         -0.7685224 ,  0.936549  , -0.6532907 , -0.53106946,
          0.9818572 , -0.542743  , -0.9325689 ,  0.45147815,
          0.8718129 ,  0.98839915,  0.992944  ,  0.89168143]]],
      dtype=float32), 'output_shape': torch.Size([1, 3, 32]), 'from': [15], 'to': [7]}

generate models:254

analyse the exceptions in iter:308
torch exception:
{'id': 6, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[514.6813,   2.7183,   3.6979,  ...,   1.0000,   2.0000,   1.0000],
          [  1.0024, 513.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0024, 512.8281, 513.0000,  ...,   1.0009, 513.0000, 513.0000],
          ...,
          [  1.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ..., 513.0000, 513.0000,   1.0000]],

         [[514.0000,   1.0000,   1.0000,  ...,   1.0000,   2.0000,   1.0000],
          [  1.0000, 513.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000, 512.8281, 513.0000,  ...,   1.0003, 514.7183, 513.0000],
          ...,
          [  1.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ..., 513.0000, 513.0000,   1.0000]],

         [[513.0000,   1.0000,   1.0000,  ...,   1.0177,   1.0000,   1.0000],
          [  1.0000, 513.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000, 512.8281, 513.0000,  ...,   1.0000, 513.0000, 513.0000],
          ...,
          [  2.5924,   1.0003,   1.0181,  ...,   1.0000,   1.0000,   1.0000],
          [  2.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ..., 514.7183, 513.0000,   2.7179]],

         ...,

         [[513.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000, 514.0000,   1.0000,  ...,   2.0000,   1.0000,   1.0000],
          [  1.0000, 512.8281, 513.0000,  ...,   1.0003, 514.7183, 513.0000],
          ...,
          [  1.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ..., 513.0000, 513.0000,   1.0000]],

         [[513.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000, 513.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000, 513.8281, 513.0000,  ...,   1.0000, 513.0000, 513.0000],
          ...,
          [  2.5924,   1.0003,   1.0181,  ...,   2.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0000,   1.0000,  ..., 514.7183, 513.0000,   2.7179]],

         [[513.0000,   1.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000, 513.0000,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000, 512.8281, 513.0000,  ...,   1.0000, 513.0000, 513.0000],
          ...,
          [  1.0000,   1.9997,   1.0000,  ...,   1.0000,   1.0000,   1.0000],
          [  1.0000,   1.0003,   1.0000,  ...,   3.7183,   2.7174,   1.0000],
          [  2.7183,   1.0000,   1.0000,  ..., 513.0000, 513.0000,   2.7183]]]],
       grad_fn=<AddBackward0>)]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 128, 8, 8] to have 256 channels, but got 128 channels instead
mindspore exception:
{'id': 6, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 128, 8, 8], dtype=Float32, value=
[[[[5.14681274e+002, 2.71828198e+000, 3.69786167e+000 ... 1.00000000e+000, 2.00000000e+000, 1.00000000e+000],
   [1.00243700e+000, 5.13000000e+002, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00242817e+000, 5.12828125e+002, 5.13000000e+002 ... 1.00087929e+000, 5.13000000e+002, 5.13000000e+002],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 5.13000000e+002, 5.13000000e+002, 1.00000000e+000]],
  [[5.14000000e+002, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.99999964e+000, 1.00000000e+000],
   [1.00000000e+000, 5.13000000e+002, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.12828125e+002, 5.13000000e+002 ... 1.00033545e+000, 5.14718262e+002, 5.13000000e+002],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000012e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 5.13000000e+002, 5.13000000e+002, 1.00000000e+000]],
  [[5.13000000e+002, 1.00000000e+000, 1.00000000e+000 ... 1.01765287e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.13000000e+002, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.12828125e+002, 5.13000000e+002 ... 1.00000000e+000, 5.13000000e+002, 5.13000000e+002],
   ...
   [2.59237432e+000, 1.00033534e+000, 1.01814890e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [2.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000036e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 5.14718262e+002, 5.13000000e+002, 2.71794677e+000]],
  ...
  [[5.13000000e+002, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.14000000e+002, 1.00000000e+000 ... 2.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.12828125e+002, 5.13000000e+002 ... 1.00033545e+000, 5.14718262e+002, 5.13000000e+002],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000012e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 5.13000000e+002, 5.13000000e+002, 1.00000000e+000]],
  [[5.13000000e+002, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.13000000e+002, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.13828125e+002, 5.13000000e+002 ... 1.00000000e+000, 5.13000000e+002, 5.13000000e+002],
   ...
   [2.59237432e+000, 1.00033534e+000, 1.01814890e+000 ... 2.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000036e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 5.14718262e+002, 5.13000000e+002, 2.71794677e+000]],
  [[5.13000000e+002, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.13000000e+002, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 5.12828125e+002, 5.13000000e+002 ... 1.00000000e+000, 5.13000000e+002, 5.13000000e+002],
   ...
   [1.00000000e+000, 1.99966466e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00033534e+000, 1.00000000e+000 ... 3.71828198e+000, 2.71737075e+000, 1.00000000e+000],
   [2.71828198e+000, 1.00000000e+000, 1.00000000e+000 ... 5.13000000e+002, 5.13000000e+002, 2.71828198e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 128, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:257

analyse output arrays in iter:315

pre layer res:
12:add
{'name': 'add', 'output': array([[[[-0.7271632 , -0.50639164, -0.50639164, ..., -0.50639164,
          -0.50639164, -0.7271632 ],
         [ 0.81676   , -0.50639164, -0.50639164, ..., -0.50639164,
           0.4519989 ,  0.81676   ],
         [ 0.92680717, -0.50639164, -0.50639164, ..., -0.50639164,
           0.4519989 ,  0.81676   ],
         ...,
         [ 0.8064184 ,  0.23669069, -0.9983471 , ..., -0.9956842 ,
           0.98024565, -0.97845656],
         [ 0.7958059 ,  0.6960585 , -0.9300949 , ...,  0.32996237,
           0.4677185 ,  0.5949086 ],
         [ 0.609068  ,  0.99646664,  0.36319944, ...,  0.98024565,
           0.98024565, -0.87329733]],

        [[-0.7271632 , -0.50639164, -0.50639164, ..., -0.50639164,
          -0.50639164, -0.7271632 ],
         [ 0.81676   , -0.50639164, -0.50639164, ..., -0.50639164,
           0.4519989 ,  0.81676   ],
         [ 0.92680717, -0.50639164, -0.50639164, ..., -0.50639164,
           0.4519989 ,  0.81676   ],
         ...,
         [ 0.9726301 ,  0.9395301 , -0.21078107, ...,  0.87757534,
          -0.9983454 , -0.88999563],
         [-0.88999563,  0.9333205 ,  0.3466212 , ..., -0.21078107,
           0.36317137, -0.8645515 ],
         [-0.04424268,  0.94543535, -0.1934734 , ..., -0.9425145 ,
           0.72103775, -0.04424268]],

        [[-0.7271632 , -0.50639164, -0.50639164, ..., -0.50639164,
          -0.50639164, -0.7271632 ],
         [ 0.81676   , -0.50639164, -0.50639164, ..., -0.50639164,
           0.4519989 ,  0.81676   ],
         [ 0.92680717, -0.50639164, -0.50639164, ..., -0.50639164,
           0.4519989 ,  0.81676   ],
         ...,
         [-0.1934734 ,  0.7958059 , -0.21078107, ..., -0.936462  ,
          -0.587795  , -0.88999563],
         [-0.8645515 ,  0.9333205 ,  0.9765844 , ..., -0.9364514 ,
           0.69608015, -0.04424268],
         [ 0.18478175,  0.94543535,  0.05308359, ...,  0.08836868,
          -0.995687  , -0.7271425 ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [7, 15], 'to': [4]}
tf node:
{'name': 'conv2d', 'output': array([[[[-2.7695606 , -5.80791   , -6.2398787 , ..., -6.2398777 ,
          -2.932738  ,  0.10561174],
         [-1.5083125 , -6.065837  , -7.9222317 , ..., -7.9222307 ,
          -0.64563614,  3.9118884 ],
         [ 3.4535985 , -1.1039267 , -5.04706   , ..., -5.047059  ,
           6.861305  , 11.418829  ],
         ...,
         [ 6.894364  ,  6.013096  ,  2.7051682 , ...,  0.23422027,
          -3.4338777 , -1.5482979 ],
         [ 8.798504  ,  7.994515  ,  8.19264   , ...,  0.4716425 ,
          -4.836085  , -3.090344  ],
         [ 5.240902  ,  5.856822  ,  6.232695  , ...,  0.32444715,
          -0.4171716 ,  0.2739985 ]],

        [[-2.7695606 , -5.80791   , -6.2398787 , ..., -6.2398777 ,
          -2.932738  ,  0.10561174],
         [-1.5083125 , -6.065837  , -7.9222317 , ..., -7.9222307 ,
          -0.64563614,  3.9118884 ],
         [ 3.4535985 , -1.1039267 , -5.04706   , ..., -5.047059  ,
           6.861305  , 11.418829  ],
         ...,
         [ 6.894364  ,  6.013096  ,  2.7051682 , ...,  0.23422027,
          -3.4338777 , -1.5482979 ],
         [ 8.798504  ,  7.994515  ,  8.19264   , ...,  0.4716425 ,
          -4.836085  , -3.090344  ],
         [ 5.240902  ,  5.856822  ,  6.232695  , ...,  0.32444715,
          -0.4171716 ,  0.2739985 ]],

        [[-2.7695606 , -5.80791   , -6.2398787 , ..., -6.2398777 ,
          -2.932738  ,  0.10561174],
         [-1.5083125 , -6.065837  , -7.9222317 , ..., -7.9222307 ,
          -0.64563614,  3.9118884 ],
         [ 3.4535985 , -1.1039267 , -5.04706   , ..., -5.047059  ,
           6.861305  , 11.418829  ],
         ...,
         [ 6.894364  ,  6.013096  ,  2.7051682 , ...,  0.23422027,
          -3.4338777 , -1.5482979 ],
         [ 8.798504  ,  7.994515  ,  8.19264   , ...,  0.4716425 ,
          -4.836085  , -3.090344  ],
         [ 5.240902  ,  5.856822  ,  6.232695  , ...,  0.32444715,
          -0.4171716 ,  0.2739985 ]],

        ...,

        [[-2.7695606 , -5.80791   , -6.2398787 , ..., -6.2398777 ,
          -2.932738  ,  0.10561174],
         [-1.5083125 , -6.065837  , -7.9222317 , ..., -7.9222307 ,
          -0.64563614,  3.9118884 ],
         [ 3.4535985 , -1.1039267 , -5.04706   , ..., -5.047059  ,
           6.861305  , 11.418829  ],
         ...,
         [ 6.894364  ,  6.013096  ,  2.7051682 , ...,  0.23422027,
          -3.4338777 , -1.5482979 ],
         [ 8.798504  ,  7.994515  ,  8.19264   , ...,  0.4716425 ,
          -4.836085  , -3.090344  ],
         [ 5.240902  ,  5.856822  ,  6.232695  , ...,  0.32444715,
          -0.4171716 ,  0.2739985 ]],

        [[-2.7695606 , -5.80791   , -6.2398787 , ..., -6.2398777 ,
          -2.932738  ,  0.10561174],
         [-1.5083125 , -6.065837  , -7.9222317 , ..., -7.9222307 ,
          -0.64563614,  3.9118884 ],
         [ 3.4535985 , -1.1039267 , -5.04706   , ..., -5.047059  ,
           6.861305  , 11.418829  ],
         ...,
         [ 6.894364  ,  6.013096  ,  2.7051682 , ...,  0.23422027,
          -3.4338777 , -1.5482979 ],
         [ 8.798504  ,  7.994515  ,  8.19264   , ...,  0.4716425 ,
          -4.836085  , -3.090344  ],
         [ 5.240902  ,  5.856822  ,  6.232695  , ...,  0.32444715,
          -0.4171716 ,  0.2739985 ]],

        [[-2.7695606 , -5.80791   , -6.2398787 , ..., -6.2398777 ,
          -2.932738  ,  0.10561174],
         [-1.5083125 , -6.065837  , -7.9222317 , ..., -7.9222307 ,
          -0.64563614,  3.9118884 ],
         [ 3.4535985 , -1.1039267 , -5.04706   , ..., -5.047059  ,
           6.861305  , 11.418829  ],
         ...,
         [ 6.894364  ,  6.013096  ,  2.7051682 , ...,  0.23422027,
          -3.4338777 , -1.5482979 ],
         [ 8.798504  ,  7.994515  ,  8.19264   , ...,  0.4716425 ,
          -4.836085  , -3.090344  ],
         [ 5.240902  ,  5.856822  ,  6.232695  , ...,  0.32444715,
          -0.4171716 ,  0.2739985 ]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 32, 32]), 'from': [12], 'to': [5]}
ms node:
{'name': 'conv2d', 'output': array([[[[-2.769559  , -5.8079085 , -6.239877  , ..., -6.239877  ,
          -2.9327376 ,  0.10561216],
         [-1.5083127 , -6.065837  , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.911889  ],
         [ 3.453598  , -1.1039267 , -5.0470595 , ..., -5.0470595 ,
           6.861305  , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013097  ,  2.705168  , ...,  0.23422104,
          -3.4338782 , -1.5482976 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164166,
          -4.836085  , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.3244468 ,
          -0.417172  ,  0.27399856]],

        [[-2.769559  , -5.8079085 , -6.239877  , ..., -6.239877  ,
          -2.9327376 ,  0.10561216],
         [-1.5083127 , -6.065837  , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.911889  ],
         [ 3.453598  , -1.1039267 , -5.0470595 , ..., -5.0470595 ,
           6.861305  , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013097  ,  2.705168  , ...,  0.23422104,
          -3.4338782 , -1.5482976 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164166,
          -4.836085  , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.3244468 ,
          -0.417172  ,  0.27399856]],

        [[-2.769559  , -5.8079085 , -6.239877  , ..., -6.239877  ,
          -2.9327376 ,  0.10561216],
         [-1.5083127 , -6.065837  , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.911889  ],
         [ 3.453598  , -1.1039267 , -5.0470595 , ..., -5.0470595 ,
           6.861305  , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013097  ,  2.705168  , ...,  0.23422104,
          -3.4338782 , -1.5482976 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164166,
          -4.836085  , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.3244468 ,
          -0.417172  ,  0.27399856]],

        ...,

        [[-2.769559  , -5.8079085 , -6.239877  , ..., -6.239877  ,
          -2.9327376 ,  0.10561216],
         [-1.5083127 , -6.065837  , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.911889  ],
         [ 3.453598  , -1.1039267 , -5.0470595 , ..., -5.0470595 ,
           6.861305  , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013097  ,  2.705168  , ...,  0.23422104,
          -3.4338782 , -1.5482976 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164166,
          -4.836085  , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.3244468 ,
          -0.417172  ,  0.27399856]],

        [[-2.769559  , -5.8079085 , -6.239877  , ..., -6.239877  ,
          -2.9327376 ,  0.10561216],
         [-1.5083127 , -6.065837  , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.911889  ],
         [ 3.453598  , -1.1039267 , -5.0470595 , ..., -5.0470595 ,
           6.861305  , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013097  ,  2.705168  , ...,  0.23422104,
          -3.4338782 , -1.5482976 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164166,
          -4.836085  , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.3244468 ,
          -0.417172  ,  0.27399856]],

        [[-2.769559  , -5.8079085 , -6.239877  , ..., -6.239877  ,
          -2.9327376 ,  0.10561216],
         [-1.5083127 , -6.065837  , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.911889  ],
         [ 3.453598  , -1.1039267 , -5.0470595 , ..., -5.0470595 ,
           6.861305  , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013097  ,  2.705168  , ...,  0.23422104,
          -3.4338782 , -1.5482976 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164166,
          -4.836085  , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.3244468 ,
          -0.417172  ,  0.27399856]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [12], 'to': [5]}
torch node:
{'name': 'conv2d', 'output': array([[[[-2.769559  , -5.8079076 , -6.239877  , ..., -6.239877  ,
          -2.9327378 ,  0.1056124 ],
         [-1.5083123 , -6.0658355 , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.9118893 ],
         [ 3.453599  , -1.1039267 , -5.0470586 , ..., -5.0470586 ,
           6.8613057 , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013096  ,  2.7051675 , ...,  0.23422107,
          -3.4338782 , -1.5482974 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164202,
          -4.8360853 , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.32444715,
          -0.41717178,  0.27399856]],

        [[-2.769559  , -5.8079076 , -6.239877  , ..., -6.239877  ,
          -2.9327378 ,  0.1056124 ],
         [-1.5083123 , -6.0658355 , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.9118893 ],
         [ 3.453599  , -1.1039267 , -5.0470586 , ..., -5.0470586 ,
           6.8613057 , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013096  ,  2.7051675 , ...,  0.23422107,
          -3.4338782 , -1.5482974 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164202,
          -4.8360853 , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.32444715,
          -0.41717178,  0.27399856]],

        [[-2.769559  , -5.8079076 , -6.239877  , ..., -6.239877  ,
          -2.9327378 ,  0.1056124 ],
         [-1.5083123 , -6.0658355 , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.9118893 ],
         [ 3.453599  , -1.1039267 , -5.0470586 , ..., -5.0470586 ,
           6.8613057 , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013096  ,  2.7051675 , ...,  0.23422107,
          -3.4338782 , -1.5482974 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164202,
          -4.8360853 , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.32444715,
          -0.41717178,  0.27399856]],

        ...,

        [[-2.769559  , -5.8079076 , -6.239877  , ..., -6.239877  ,
          -2.9327378 ,  0.1056124 ],
         [-1.5083123 , -6.0658355 , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.9118893 ],
         [ 3.453599  , -1.1039267 , -5.0470586 , ..., -5.0470586 ,
           6.8613057 , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013096  ,  2.7051675 , ...,  0.23422107,
          -3.4338782 , -1.5482974 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164202,
          -4.8360853 , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.32444715,
          -0.41717178,  0.27399856]],

        [[-2.769559  , -5.8079076 , -6.239877  , ..., -6.239877  ,
          -2.9327378 ,  0.1056124 ],
         [-1.5083123 , -6.0658355 , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.9118893 ],
         [ 3.453599  , -1.1039267 , -5.0470586 , ..., -5.0470586 ,
           6.8613057 , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013096  ,  2.7051675 , ...,  0.23422107,
          -3.4338782 , -1.5482974 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164202,
          -4.8360853 , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.32444715,
          -0.41717178,  0.27399856]],

        [[-2.769559  , -5.8079076 , -6.239877  , ..., -6.239877  ,
          -2.9327378 ,  0.1056124 ],
         [-1.5083123 , -6.0658355 , -7.9222307 , ..., -7.9222307 ,
          -0.6456354 ,  3.9118893 ],
         [ 3.453599  , -1.1039267 , -5.0470586 , ..., -5.0470586 ,
           6.8613057 , 11.41883   ],
         ...,
         [ 6.8943644 ,  6.013096  ,  2.7051675 , ...,  0.23422107,
          -3.4338782 , -1.5482974 ],
         [ 8.798504  ,  7.994515  ,  8.192641  , ...,  0.47164202,
          -4.8360853 , -3.090344  ],
         [ 5.240903  ,  5.856823  ,  6.2326956 , ...,  0.32444715,
          -0.41717178,  0.27399856]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [12], 'to': [5]}

generate models:263

analyse output arrays in iter:325

pre layer res:
13:exp
{'name': 'exp', 'output': array([[[inf, inf, inf, ..., inf, inf, inf],
        [inf, inf, inf, ..., inf, inf, inf],
        [inf, inf, inf, ..., inf, inf, inf],
        ...,
        [inf, inf, inf, ..., inf, inf, inf],
        [inf, inf, inf, ..., inf, inf, inf],
        [inf, inf, inf, ..., inf, inf, inf]]], dtype=float32), 'output_shape': TensorShape([1, 128, 32]), 'from': [7], 'to': [11]}
tf node:
{'name': 'cos', 'output': array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32), 'output_shape': TensorShape([1, 128, 32]), 'from': [13], 'to': [8, 15]}
ms node:
{'name': 'cos', 'output': array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32), 'output_shape': (1, 128, 32), 'from': [13], 'to': [8, 15]}
torch node:
{'name': 'cos', 'output': array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32]), 'from': [13], 'to': [8, 15]}

generate models:270

analyse output arrays in iter:327

pre layer res:
15:transpose
{'name': 'transpose', 'output': array([[[[1.33597063e+30, 4.33034206e+29, 2.42542962e+21, ...,
          7.04544903e+34, 1.04563326e+37,            inf],
         [1.58571447e+28, 4.33963152e+29, 4.44277288e+19, ...,
                     inf,            inf,            inf],
         [1.52447167e+26, 3.31150814e+27, 6.60922723e+21, ...,
                     inf,            inf,            inf],
         ...,
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [9.59927798e+33,            inf, 1.41511402e+36, ...,
                     inf,            inf,            inf]],

        [[1.33597063e+30, 4.33034206e+29, 2.42542962e+21, ...,
          7.04544903e+34, 1.04563326e+37,            inf],
         [1.58571447e+28, 4.33963152e+29, 4.44277288e+19, ...,
                     inf,            inf,            inf],
         [1.52447167e+26, 3.31150814e+27, 6.60922723e+21, ...,
                     inf,            inf,            inf],
         ...,
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [9.59927798e+33,            inf, 1.41511402e+36, ...,
                     inf,            inf,            inf]],

        [[1.33597063e+30, 4.33034206e+29, 2.42542962e+21, ...,
          7.04544903e+34, 1.04563326e+37,            inf],
         [1.58571447e+28, 4.33963152e+29, 4.44277288e+19, ...,
                     inf,            inf,            inf],
         [1.52447167e+26, 3.31150814e+27, 6.60922723e+21, ...,
                     inf,            inf,            inf],
         ...,
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [9.59927798e+33,            inf, 1.41511402e+36, ...,
                     inf,            inf,            inf]],

        ...,

        [[1.33597063e+30, 4.33034206e+29, 2.42542962e+21, ...,
          7.04544903e+34, 1.04563326e+37,            inf],
         [1.58571447e+28, 4.33963152e+29, 4.44277288e+19, ...,
                     inf,            inf,            inf],
         [1.52447167e+26, 3.31150814e+27, 6.60922723e+21, ...,
                     inf,            inf,            inf],
         ...,
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [9.59927798e+33,            inf, 1.41511402e+36, ...,
                     inf,            inf,            inf]],

        [[1.33597063e+30, 4.33034206e+29, 2.42542962e+21, ...,
          7.04544903e+34, 1.04563326e+37,            inf],
         [1.58571447e+28, 4.33963152e+29, 4.44277288e+19, ...,
                     inf,            inf,            inf],
         [1.52447167e+26, 3.31150814e+27, 6.60922723e+21, ...,
                     inf,            inf,            inf],
         ...,
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [9.59927798e+33,            inf, 1.41511402e+36, ...,
                     inf,            inf,            inf]],

        [[1.33597063e+30, 4.33034206e+29, 2.42542962e+21, ...,
          7.04544903e+34, 1.04563326e+37,            inf],
         [1.58571447e+28, 4.33963152e+29, 4.44277288e+19, ...,
                     inf,            inf,            inf],
         [1.52447167e+26, 3.31150814e+27, 6.60922723e+21, ...,
                     inf,            inf,            inf],
         ...,
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [9.59927798e+33,            inf, 1.41511402e+36, ...,
                     inf,            inf,            inf]]]],
      dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [16], 'to': [13]}
tf node:
{'name': 'cos', 'output': array([[[[ 0.05325297, -0.36785734,  0.973472  , ...,  0.45232207,
           0.978985  ,         nan],
         [ 0.969315  ,  0.47710332,  0.23584704, ...,         nan,
                  nan,         nan],
         [ 0.7728959 ,  0.61440736, -0.28409243, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.36810073,         nan,  0.5489429 , ...,         nan,
                  nan,         nan]],

        [[ 0.05325297, -0.36785734,  0.973472  , ...,  0.45232207,
           0.978985  ,         nan],
         [ 0.969315  ,  0.47710332,  0.23584704, ...,         nan,
                  nan,         nan],
         [ 0.7728959 ,  0.61440736, -0.28409243, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.36810073,         nan,  0.5489429 , ...,         nan,
                  nan,         nan]],

        [[ 0.05325297, -0.36785734,  0.973472  , ...,  0.45232207,
           0.978985  ,         nan],
         [ 0.969315  ,  0.47710332,  0.23584704, ...,         nan,
                  nan,         nan],
         [ 0.7728959 ,  0.61440736, -0.28409243, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.36810073,         nan,  0.5489429 , ...,         nan,
                  nan,         nan]],

        ...,

        [[ 0.05325297, -0.36785734,  0.973472  , ...,  0.45232207,
           0.978985  ,         nan],
         [ 0.969315  ,  0.47710332,  0.23584704, ...,         nan,
                  nan,         nan],
         [ 0.7728959 ,  0.61440736, -0.28409243, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.36810073,         nan,  0.5489429 , ...,         nan,
                  nan,         nan]],

        [[ 0.05325297, -0.36785734,  0.973472  , ...,  0.45232207,
           0.978985  ,         nan],
         [ 0.969315  ,  0.47710332,  0.23584704, ...,         nan,
                  nan,         nan],
         [ 0.7728959 ,  0.61440736, -0.28409243, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.36810073,         nan,  0.5489429 , ...,         nan,
                  nan,         nan]],

        [[ 0.05325297, -0.36785734,  0.973472  , ...,  0.45232207,
           0.978985  ,         nan],
         [ 0.969315  ,  0.47710332,  0.23584704, ...,         nan,
                  nan,         nan],
         [ 0.7728959 ,  0.61440736, -0.28409243, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.36810073,         nan,  0.5489429 , ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [15], 'to': [4]}
ms node:
{'name': 'cos', 'output': array([[[[-0.99949265,  0.50712883, -0.92517364, ..., -0.7635365 ,
           0.94109666,         nan],
         [ 0.12897083,  0.9997256 ,  0.99317   , ...,         nan,
                  nan,         nan],
         [ 0.9176208 ,  0.13227546,  0.8537596 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.79728943,         nan, -0.78755563, ...,         nan,
                  nan,         nan]],

        [[-0.99949265,  0.50712883, -0.92517364, ..., -0.7635365 ,
           0.94109666,         nan],
         [ 0.12897083,  0.9997256 ,  0.99317   , ...,         nan,
                  nan,         nan],
         [ 0.9176208 ,  0.13227546,  0.8537596 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.79728943,         nan, -0.78755563, ...,         nan,
                  nan,         nan]],

        [[-0.99949265,  0.50712883, -0.92517364, ..., -0.7635365 ,
           0.94109666,         nan],
         [ 0.12897083,  0.9997256 ,  0.99317   , ...,         nan,
                  nan,         nan],
         [ 0.9176208 ,  0.13227546,  0.8537596 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.79728943,         nan, -0.78755563, ...,         nan,
                  nan,         nan]],

        ...,

        [[-0.99949265,  0.50712883, -0.92517364, ..., -0.7635365 ,
           0.94109666,         nan],
         [ 0.12897083,  0.9997256 ,  0.99317   , ...,         nan,
                  nan,         nan],
         [ 0.9176208 ,  0.13227546,  0.8537596 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.79728943,         nan, -0.78755563, ...,         nan,
                  nan,         nan]],

        [[-0.99949265,  0.50712883, -0.92517364, ..., -0.7635365 ,
           0.94109666,         nan],
         [ 0.12897083,  0.9997256 ,  0.99317   , ...,         nan,
                  nan,         nan],
         [ 0.9176208 ,  0.13227546,  0.8537596 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.79728943,         nan, -0.78755563, ...,         nan,
                  nan,         nan]],

        [[-0.99949265,  0.50712883, -0.92517364, ..., -0.7635365 ,
           0.94109666,         nan],
         [ 0.12897083,  0.9997256 ,  0.99317   , ...,         nan,
                  nan,         nan],
         [ 0.9176208 ,  0.13227546,  0.8537596 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [ 0.79728943,         nan, -0.78755563, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [15], 'to': [4]}
torch node:
{'name': 'cos', 'output': array([[[[-0.36267594,  0.52194613, -0.21665147, ..., -0.20513894,
          -0.9975605 ,         nan],
         [-0.45366764, -0.12439447, -0.73717415, ...,         nan,
                  nan,         nan],
         [ 0.40410116, -0.794718  , -0.4043765 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.1657824 ,         nan,  0.17537278, ...,         nan,
                  nan,         nan]],

        [[-0.36267594,  0.52194613, -0.21665147, ..., -0.20513894,
          -0.9975605 ,         nan],
         [-0.45366764, -0.12439447, -0.73717415, ...,         nan,
                  nan,         nan],
         [ 0.40410116, -0.794718  , -0.4043765 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.1657824 ,         nan,  0.17537278, ...,         nan,
                  nan,         nan]],

        [[-0.36267594,  0.52194613, -0.21665147, ..., -0.20513894,
          -0.9975605 ,         nan],
         [-0.45366764, -0.12439447, -0.73717415, ...,         nan,
                  nan,         nan],
         [ 0.40410116, -0.794718  , -0.4043765 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.1657824 ,         nan,  0.17537278, ...,         nan,
                  nan,         nan]],

        ...,

        [[-0.36267594,  0.52194613, -0.21665147, ..., -0.20513894,
          -0.9975605 ,         nan],
         [-0.45366764, -0.12439447, -0.73717415, ...,         nan,
                  nan,         nan],
         [ 0.40410116, -0.794718  , -0.4043765 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.1657824 ,         nan,  0.17537278, ...,         nan,
                  nan,         nan]],

        [[-0.36267594,  0.52194613, -0.21665147, ..., -0.20513894,
          -0.9975605 ,         nan],
         [-0.45366764, -0.12439447, -0.73717415, ...,         nan,
                  nan,         nan],
         [ 0.40410116, -0.794718  , -0.4043765 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.1657824 ,         nan,  0.17537278, ...,         nan,
                  nan,         nan]],

        [[-0.36267594,  0.52194613, -0.21665147, ..., -0.20513894,
          -0.9975605 ,         nan],
         [-0.45366764, -0.12439447, -0.73717415, ...,         nan,
                  nan,         nan],
         [ 0.40410116, -0.794718  , -0.4043765 , ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.1657824 ,         nan,  0.17537278, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [15], 'to': [4]}

generate models:272

analyse the exceptions in iter:329
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[135., 134., 135.,  ..., 127., 126., 128.],
           [138., 136., 137.,  ..., 130., 129., 130.],
           [140., 138., 139.,  ..., 134., 133., 135.],
           ...,
           [164., 159., 160.,  ..., 159., 159., 159.],
           [159., 154., 156.,  ..., 153., 148., 150.],
           [159., 155., 151.,  ..., 148., 144., 150.]],

          [[175., 173., 174.,  ..., 174., 173., 177.],
           [175., 172., 173.,  ..., 175., 173., 177.],
           [176., 174., 175.,  ..., 176., 175., 178.],
           ...,
           [146., 142., 142.,  ..., 141., 141., 141.],
           [138., 134., 135.,  ..., 134., 129., 130.],
           [138., 131., 126.,  ..., 129., 125., 130.]],

          [[212., 209., 210.,  ..., 208., 206., 211.],
           [209., 206., 207.,  ..., 205., 204., 209.],
           [208., 205., 206.,  ..., 205., 204., 208.],
           ...,
           [109., 105., 105.,  ..., 103., 104., 103.],
           [104., 101., 102.,  ...,  94.,  89.,  92.],
           [ 95.,  93.,  91.,  ...,  95.,  90.,  96.]]]]])}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.35000000e+002, 1.34000000e+002, 1.35000000e+002 ... 1.27000000e+002, 1.26000000e+002, 1.28000000e+002],
    [1.38000000e+002, 1.36000000e+002, 1.37000000e+002 ... 1.30000000e+002, 1.29000000e+002, 1.30000000e+002],
    [1.40000000e+002, 1.38000000e+002, 1.39000000e+002 ... 1.34000000e+002, 1.33000000e+002, 1.35000000e+002],
    ...
    [1.64000000e+002, 1.59000000e+002, 1.60000000e+002 ... 1.59000000e+002, 1.59000000e+002, 1.59000000e+002],
    [1.59000000e+002, 1.54000000e+002, 1.56000000e+002 ... 1.53000000e+002, 1.48000000e+002, 1.50000000e+002],
    [1.59000000e+002, 1.55000000e+002, 1.51000000e+002 ... 1.48000000e+002, 1.44000000e+002, 1.50000000e+002]],
   [[1.75000000e+002, 1.73000000e+002, 1.74000000e+002 ... 1.74000000e+002, 1.73000000e+002, 1.77000000e+002],
    [1.75000000e+002, 1.72000000e+002, 1.73000000e+002 ... 1.75000000e+002, 1.73000000e+002, 1.77000000e+002],
    [1.76000000e+002, 1.74000000e+002, 1.75000000e+002 ... 1.76000000e+002, 1.75000000e+002, 1.78000000e+002],
    ...
    [1.46000000e+002, 1.42000000e+002, 1.42000000e+002 ... 1.41000000e+002, 1.41000000e+002, 1.41000000e+002],
    [1.38000000e+002, 1.34000000e+002, 1.35000000e+002 ... 1.34000000e+002, 1.29000000e+002, 1.30000000e+002],
    [1.38000000e+002, 1.31000000e+002, 1.26000000e+002 ... 1.29000000e+002, 1.25000000e+002, 1.30000000e+002]],
   [[2.12000000e+002, 2.09000000e+002, 2.10000000e+002 ... 2.08000000e+002, 2.06000000e+002, 2.11000000e+002],
    [2.09000000e+002, 2.06000000e+002, 2.07000000e+002 ... 2.05000000e+002, 2.04000000e+002, 2.09000000e+002],
    [2.08000000e+002, 2.05000000e+002, 2.06000000e+002 ... 2.05000000e+002, 2.04000000e+002, 2.08000000e+002],
    ...
    [1.09000000e+002, 1.05000000e+002, 1.05000000e+002 ... 1.03000000e+002, 1.04000000e+002, 1.03000000e+002],
    [1.04000000e+002, 1.01000000e+002, 1.02000000e+002 ... 9.40000000e+001, 8.90000000e+001, 9.20000000e+001],
    [9.50000000e+001, 9.30000000e+001, 9.10000000e+001 ... 9.50000000e+001, 9.00000000e+001, 9.60000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:274

analyse the exceptions in iter:337
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[151., 157., 149.,  ..., 159., 155., 152.],
          [165., 169., 165.,  ..., 162., 162., 172.],
          [152., 155., 154.,  ..., 155., 152., 162.],
          ...,
          [158., 153., 147.,  ..., 154., 147., 151.],
          [154., 165., 163.,  ..., 162., 149., 148.],
          [156., 152., 159.,  ..., 142., 138., 144.]],

         [[141., 141., 138.,  ..., 151., 144., 134.],
          [134., 132., 133.,  ..., 133., 131., 133.],
          [132., 128., 132.,  ..., 136., 130., 134.],
          ...,
          [141., 130., 130.,  ..., 140., 137., 134.],
          [125., 131., 134.,  ..., 135., 126., 119.],
          [136., 127., 139.,  ..., 125., 125., 124.]],

         [[105., 114., 105.,  ..., 116., 114., 103.],
          [113., 120., 115.,  ..., 113., 117., 117.],
          [109., 116., 113.,  ..., 115., 115., 117.],
          ...,
          [113., 111., 105.,  ..., 116., 118., 113.],
          [ 99., 114., 111.,  ..., 116., 111., 102.],
          [105., 105., 111.,  ...,  95.,  99.,  96.]]]])]}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[1.51000000e+002, 1.57000000e+002, 1.49000000e+002 ... 1.59000000e+002, 1.55000000e+002, 1.52000000e+002],
   [1.65000000e+002, 1.69000000e+002, 1.65000000e+002 ... 1.62000000e+002, 1.62000000e+002, 1.72000000e+002],
   [1.52000000e+002, 1.55000000e+002, 1.54000000e+002 ... 1.55000000e+002, 1.52000000e+002, 1.62000000e+002],
   ...
   [1.58000000e+002, 1.53000000e+002, 1.47000000e+002 ... 1.54000000e+002, 1.47000000e+002, 1.51000000e+002],
   [1.54000000e+002, 1.65000000e+002, 1.63000000e+002 ... 1.62000000e+002, 1.49000000e+002, 1.48000000e+002],
   [1.56000000e+002, 1.52000000e+002, 1.59000000e+002 ... 1.42000000e+002, 1.38000000e+002, 1.44000000e+002]],
  [[1.41000000e+002, 1.41000000e+002, 1.38000000e+002 ... 1.51000000e+002, 1.44000000e+002, 1.34000000e+002],
   [1.34000000e+002, 1.32000000e+002, 1.33000000e+002 ... 1.33000000e+002, 1.31000000e+002, 1.33000000e+002],
   [1.32000000e+002, 1.28000000e+002, 1.32000000e+002 ... 1.36000000e+002, 1.30000000e+002, 1.34000000e+002],
   ...
   [1.41000000e+002, 1.30000000e+002, 1.30000000e+002 ... 1.40000000e+002, 1.37000000e+002, 1.34000000e+002],
   [1.25000000e+002, 1.31000000e+002, 1.34000000e+002 ... 1.35000000e+002, 1.26000000e+002, 1.19000000e+002],
   [1.36000000e+002, 1.27000000e+002, 1.39000000e+002 ... 1.25000000e+002, 1.25000000e+002, 1.24000000e+002]],
  [[1.05000000e+002, 1.14000000e+002, 1.05000000e+002 ... 1.16000000e+002, 1.14000000e+002, 1.03000000e+002],
   [1.13000000e+002, 1.20000000e+002, 1.15000000e+002 ... 1.13000000e+002, 1.17000000e+002, 1.17000000e+002],
   [1.09000000e+002, 1.16000000e+002, 1.13000000e+002 ... 1.15000000e+002, 1.15000000e+002, 1.17000000e+002],
   ...
   [1.13000000e+002, 1.11000000e+002, 1.05000000e+002 ... 1.16000000e+002, 1.18000000e+002, 1.13000000e+002],
   [9.90000000e+001, 1.14000000e+002, 1.11000000e+002 ... 1.16000000e+002, 1.11000000e+002, 1.02000000e+002],
   [1.05000000e+002, 1.05000000e+002, 1.11000000e+002 ... 9.50000000e+001, 9.90000000e+001, 9.60000000e+001]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:279

analyse output arrays in iter:338

pre layer res:
15:log
{'name': 'log', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 100]), 'from': [7], 'to': [8]}
tf node:
{'name': 'maxpool2d', 'output': array([[[[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        ...,

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]]]],
      dtype=float32), 'output_shape': TensorShape([1, 512, 8, 50]), 'from': [15], 'to': []}
ms node:
{'name': 'maxpool2d', 'output': array([[[[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        ...,

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]],

        [[-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         ...,
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],
         [-3.4028235e+38, -3.4028235e+38, -3.4028235e+38, ...,
          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]]]],
      dtype=float32), 'output_shape': (1, 512, 8, 50), 'from': [15], 'to': []}
torch node:
{'name': 'maxpool2d', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 8, 50]), 'from': [15], 'to': []}

generate models:280

analyse output arrays in iter:345

pre layer res:
3:maxpool2d
{'name': 'maxpool2d', 'output': array([[[[43.81299 , 43.81299 , 43.81299 , ..., 43.81299 , 43.81299 ,
          43.81299 ],
         [44.45215 , 44.45215 , 44.45215 , ..., 44.45215 , 44.45215 ,
          44.45215 ],
         [42.157715, 42.157715, 42.157715, ..., 42.157715, 42.157715,
          42.157715],
         ...,
         [43.90747 , 43.90747 , 43.90747 , ..., 43.90747 , 43.90747 ,
          43.90747 ],
         [40.789062, 40.789062, 40.789062, ..., 40.789062, 40.789062,
          40.789062],
         [37.53662 , 37.53662 , 37.53662 , ..., 37.53662 , 37.53662 ,
          37.53662 ]],

        [[43.81299 , 43.81299 , 43.81299 , ..., 43.81299 , 43.81299 ,
          43.81299 ],
         [44.45215 , 44.45215 , 44.45215 , ..., 44.45215 , 44.45215 ,
          44.45215 ],
         [42.157715, 42.157715, 42.157715, ..., 42.157715, 42.157715,
          42.157715],
         ...,
         [43.90747 , 43.90747 , 43.90747 , ..., 43.90747 , 43.90747 ,
          43.90747 ],
         [40.789062, 40.789062, 40.789062, ..., 40.789062, 40.789062,
          40.789062],
         [37.53662 , 37.53662 , 37.53662 , ..., 37.53662 , 37.53662 ,
          37.53662 ]],

        [[43.81299 , 43.81299 , 43.81299 , ..., 43.81299 , 43.81299 ,
          43.81299 ],
         [44.45215 , 44.45215 , 44.45215 , ..., 44.45215 , 44.45215 ,
          44.45215 ],
         [42.157715, 42.157715, 42.157715, ..., 42.157715, 42.157715,
          42.157715],
         ...,
         [43.90747 , 43.90747 , 43.90747 , ..., 43.90747 , 43.90747 ,
          43.90747 ],
         [40.789062, 40.789062, 40.789062, ..., 40.789062, 40.789062,
          40.789062],
         [37.53662 , 37.53662 , 37.53662 , ..., 37.53662 , 37.53662 ,
          37.53662 ]],

        ...,

        [[43.81299 , 43.81299 , 43.81299 , ..., 43.81299 , 43.81299 ,
          43.81299 ],
         [44.45215 , 44.45215 , 44.45215 , ..., 44.45215 , 44.45215 ,
          44.45215 ],
         [42.157715, 42.157715, 42.157715, ..., 42.157715, 42.157715,
          42.157715],
         ...,
         [43.90747 , 43.90747 , 43.90747 , ..., 43.90747 , 43.90747 ,
          43.90747 ],
         [40.789062, 40.789062, 40.789062, ..., 40.789062, 40.789062,
          40.789062],
         [37.53662 , 37.53662 , 37.53662 , ..., 37.53662 , 37.53662 ,
          37.53662 ]],

        [[43.81299 , 43.81299 , 43.81299 , ..., 43.81299 , 43.81299 ,
          43.81299 ],
         [44.45215 , 44.45215 , 44.45215 , ..., 44.45215 , 44.45215 ,
          44.45215 ],
         [42.157715, 42.157715, 42.157715, ..., 42.157715, 42.157715,
          42.157715],
         ...,
         [43.90747 , 43.90747 , 43.90747 , ..., 43.90747 , 43.90747 ,
          43.90747 ],
         [40.789062, 40.789062, 40.789062, ..., 40.789062, 40.789062,
          40.789062],
         [37.53662 , 37.53662 , 37.53662 , ..., 37.53662 , 37.53662 ,
          37.53662 ]],

        [[43.81299 , 43.81299 , 43.81299 , ..., 43.81299 , 43.81299 ,
          43.81299 ],
         [44.45215 , 44.45215 , 44.45215 , ..., 44.45215 , 44.45215 ,
          44.45215 ],
         [42.157715, 42.157715, 42.157715, ..., 42.157715, 42.157715,
          42.157715],
         ...,
         [43.90747 , 43.90747 , 43.90747 , ..., 43.90747 , 43.90747 ,
          43.90747 ],
         [40.789062, 40.789062, 40.789062, ..., 40.789062, 40.789062,
          40.789062],
         [37.53662 , 37.53662 , 37.53662 , ..., 37.53662 , 37.53662 ,
          37.53662 ]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 50]), 'from': [2], 'to': [6]}
tf node:
{'name': 'cos', 'output': array([[[[ 0.98570144,  0.98570144,  0.98570144, ...,  0.98570144,
           0.98570144,  0.98570144],
         [ 0.89163566,  0.89163566,  0.89163566, ...,  0.89163566,
           0.89163566,  0.89163566],
         [-0.25107044, -0.25107044, -0.25107044, ..., -0.25107044,
          -0.25107044, -0.25107044],
         ...,
         [ 0.9972018 ,  0.9972018 ,  0.9972018 , ...,  0.9972018 ,
           0.9972018 ,  0.9972018 ],
         [-0.9986668 , -0.9986668 , -0.9986668 , ..., -0.9986668 ,
          -0.9986668 , -0.9986668 ],
         [ 0.9868274 ,  0.9868274 ,  0.9868274 , ...,  0.9868274 ,
           0.9868274 ,  0.9868274 ]],

        [[ 0.98570144,  0.98570144,  0.98570144, ...,  0.98570144,
           0.98570144,  0.98570144],
         [ 0.89163566,  0.89163566,  0.89163566, ...,  0.89163566,
           0.89163566,  0.89163566],
         [-0.25107044, -0.25107044, -0.25107044, ..., -0.25107044,
          -0.25107044, -0.25107044],
         ...,
         [ 0.9972018 ,  0.9972018 ,  0.9972018 , ...,  0.9972018 ,
           0.9972018 ,  0.9972018 ],
         [-0.9986668 , -0.9986668 , -0.9986668 , ..., -0.9986668 ,
          -0.9986668 , -0.9986668 ],
         [ 0.9868274 ,  0.9868274 ,  0.9868274 , ...,  0.9868274 ,
           0.9868274 ,  0.9868274 ]],

        [[ 0.98570144,  0.98570144,  0.98570144, ...,  0.98570144,
           0.98570144,  0.98570144],
         [ 0.89163566,  0.89163566,  0.89163566, ...,  0.89163566,
           0.89163566,  0.89163566],
         [-0.25107044, -0.25107044, -0.25107044, ..., -0.25107044,
          -0.25107044, -0.25107044],
         ...,
         [ 0.9972018 ,  0.9972018 ,  0.9972018 , ...,  0.9972018 ,
           0.9972018 ,  0.9972018 ],
         [-0.9986668 , -0.9986668 , -0.9986668 , ..., -0.9986668 ,
          -0.9986668 , -0.9986668 ],
         [ 0.9868274 ,  0.9868274 ,  0.9868274 , ...,  0.9868274 ,
           0.9868274 ,  0.9868274 ]],

        ...,

        [[ 0.98570144,  0.98570144,  0.98570144, ...,  0.98570144,
           0.98570144,  0.98570144],
         [ 0.89163566,  0.89163566,  0.89163566, ...,  0.89163566,
           0.89163566,  0.89163566],
         [-0.25107044, -0.25107044, -0.25107044, ..., -0.25107044,
          -0.25107044, -0.25107044],
         ...,
         [ 0.9972018 ,  0.9972018 ,  0.9972018 , ...,  0.9972018 ,
           0.9972018 ,  0.9972018 ],
         [-0.9986668 , -0.9986668 , -0.9986668 , ..., -0.9986668 ,
          -0.9986668 , -0.9986668 ],
         [ 0.9868274 ,  0.9868274 ,  0.9868274 , ...,  0.9868274 ,
           0.9868274 ,  0.9868274 ]],

        [[ 0.98570144,  0.98570144,  0.98570144, ...,  0.98570144,
           0.98570144,  0.98570144],
         [ 0.89163566,  0.89163566,  0.89163566, ...,  0.89163566,
           0.89163566,  0.89163566],
         [-0.25107044, -0.25107044, -0.25107044, ..., -0.25107044,
          -0.25107044, -0.25107044],
         ...,
         [ 0.9972018 ,  0.9972018 ,  0.9972018 , ...,  0.9972018 ,
           0.9972018 ,  0.9972018 ],
         [-0.9986668 , -0.9986668 , -0.9986668 , ..., -0.9986668 ,
          -0.9986668 , -0.9986668 ],
         [ 0.9868274 ,  0.9868274 ,  0.9868274 , ...,  0.9868274 ,
           0.9868274 ,  0.9868274 ]],

        [[ 0.98570144,  0.98570144,  0.98570144, ...,  0.98570144,
           0.98570144,  0.98570144],
         [ 0.89163566,  0.89163566,  0.89163566, ...,  0.89163566,
           0.89163566,  0.89163566],
         [-0.25107044, -0.25107044, -0.25107044, ..., -0.25107044,
          -0.25107044, -0.25107044],
         ...,
         [ 0.9972018 ,  0.9972018 ,  0.9972018 , ...,  0.9972018 ,
           0.9972018 ,  0.9972018 ],
         [-0.9986668 , -0.9986668 , -0.9986668 , ..., -0.9986668 ,
          -0.9986668 , -0.9986668 ],
         [ 0.9868274 ,  0.9868274 ,  0.9868274 , ...,  0.9868274 ,
           0.9868274 ,  0.9868274 ]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 50]), 'from': [3], 'to': [7, 8]}
ms node:
{'name': 'cos', 'output': array([[[[ 0.9855248 ,  0.9855248 ,  0.9855248 , ...,  0.9855248 ,
           0.9855248 ,  0.9855248 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513363 , -0.2513363 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.9972413 ,  0.9972413 ],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.99863756, -0.99863756],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855248 ,  0.9855248 ,  0.9855248 , ...,  0.9855248 ,
           0.9855248 ,  0.9855248 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513363 , -0.2513363 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.9972413 ,  0.9972413 ],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.99863756, -0.99863756],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855248 ,  0.9855248 ,  0.9855248 , ...,  0.9855248 ,
           0.9855248 ,  0.9855248 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513363 , -0.2513363 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.9972413 ,  0.9972413 ],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.99863756, -0.99863756],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        ...,

        [[ 0.9855248 ,  0.9855248 ,  0.9855248 , ...,  0.9855248 ,
           0.9855248 ,  0.9855248 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513363 , -0.2513363 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.9972413 ,  0.9972413 ],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.99863756, -0.99863756],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855248 ,  0.9855248 ,  0.9855248 , ...,  0.9855248 ,
           0.9855248 ,  0.9855248 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513363 , -0.2513363 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.9972413 ,  0.9972413 ],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.99863756, -0.99863756],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855248 ,  0.9855248 ,  0.9855248 , ...,  0.9855248 ,
           0.9855248 ,  0.9855248 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513363 , -0.2513363 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.9972413 ,  0.9972413 ],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.99863756, -0.99863756],
         [ 0.9866733 ,  0.9866733 ,  0.9866733 , ...,  0.9866733 ,
           0.9866733 ,  0.9866733 ]]]], dtype=float32), 'output_shape': (1, 512, 16, 50), 'from': [3], 'to': [7, 8]}
torch node:
{'name': 'cos', 'output': array([[[[ 0.9855242 ,  0.9855242 ,  0.9855242 , ...,  0.9855242 ,
           0.9855242 ,  0.9855242 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513326 , -0.2513326 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.99724156,  0.99724156],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.9986373 , -0.9986373 ],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855242 ,  0.9855242 ,  0.9855242 , ...,  0.9855242 ,
           0.9855242 ,  0.9855242 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513326 , -0.2513326 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.99724156,  0.99724156],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.9986373 , -0.9986373 ],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855242 ,  0.9855242 ,  0.9855242 , ...,  0.9855242 ,
           0.9855242 ,  0.9855242 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513326 , -0.2513326 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.99724156,  0.99724156],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.9986373 , -0.9986373 ],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        ...,

        [[ 0.9855242 ,  0.9855242 ,  0.9855242 , ...,  0.9855242 ,
           0.9855242 ,  0.9855242 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513326 , -0.2513326 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.99724156,  0.99724156],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.9986373 , -0.9986373 ],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855242 ,  0.9855242 ,  0.9855242 , ...,  0.9855242 ,
           0.9855242 ,  0.9855242 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513326 , -0.2513326 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.99724156,  0.99724156],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.9986373 , -0.9986373 ],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]],

        [[ 0.9855242 ,  0.9855242 ,  0.9855242 , ...,  0.9855242 ,
           0.9855242 ,  0.9855242 ],
         [ 0.8930664 ,  0.8930664 ,  0.8930664 , ...,  0.8930664 ,
           0.8930681 ,  0.8930681 ],
         [-0.2513363 , -0.2513363 , -0.2513363 , ..., -0.2513363 ,
          -0.2513326 , -0.2513326 ],
         ...,
         [ 0.997241  ,  0.997241  ,  0.997241  , ...,  0.997241  ,
           0.99724156,  0.99724156],
         [-0.99863756, -0.99863756, -0.99863756, ..., -0.99863756,
          -0.9986373 , -0.9986373 ],
         [ 0.98667264,  0.98667264,  0.98667264, ...,  0.98667264,
           0.9866733 ,  0.9866733 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 50]), 'from': [3], 'to': [7, 8]}

generate models:284

analyse the exceptions in iter:357
torch exception:
{'id': 0, 'name': 'linear', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 18.,  22.,  21.,  ...,  10.,  13.,  19.],
           [ 14.,  16.,  15.,  ...,  35.,  19.,  27.],
           [ 12.,  10.,  11.,  ..., 145.,  88.,  47.],
           ...,
           [144., 153., 155.,  ...,  54.,  64.,  75.],
           [181., 178., 178.,  ...,  65.,  71.,  80.],
           [207., 206., 209.,  ..., 104.,  90.,  92.]],

          [[ 14.,  18.,  17.,  ...,  12.,   7.,  10.],
           [ 10.,  12.,  11.,  ...,  23.,  16.,  22.],
           [  8.,   6.,   7.,  ...,  61.,  64.,  43.],
           ...,
           [129., 133., 136.,  ...,  53.,  63.,  73.],
           [163., 158., 159.,  ...,  60.,  65.,  74.],
           [189., 188., 191.,  ...,  96.,  81.,  83.]],

          [[ 15.,  19.,  18.,  ...,  15.,  10.,  13.],
           [ 11.,  13.,  12.,  ...,  12.,  14.,  24.],
           [  9.,   7.,   8.,  ...,  48.,  55.,  37.],
           ...,
           [109., 118., 123.,  ...,  42.,  49.,  61.],
           [149., 146., 147.,  ...,  49.,  49.,  57.],
           [180., 178., 181.,  ...,  87.,  67.,  69.]]]]])}
mat1 and mat2 shapes cannot be multiplied (96x32 and 100x100)
mindspore exception:
{'id': 0, 'name': 'linear', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.80000000e+001, 2.20000000e+001, 2.10000000e+001 ... 1.00000000e+001, 1.30000000e+001, 1.90000000e+001],
    [1.40000000e+001, 1.60000000e+001, 1.50000000e+001 ... 3.50000000e+001, 1.90000000e+001, 2.70000000e+001],
    [1.20000000e+001, 1.00000000e+001, 1.10000000e+001 ... 1.45000000e+002, 8.80000000e+001, 4.70000000e+001],
    ...
    [1.44000000e+002, 1.53000000e+002, 1.55000000e+002 ... 5.40000000e+001, 6.40000000e+001, 7.50000000e+001],
    [1.81000000e+002, 1.78000000e+002, 1.78000000e+002 ... 6.50000000e+001, 7.10000000e+001, 8.00000000e+001],
    [2.07000000e+002, 2.06000000e+002, 2.09000000e+002 ... 1.04000000e+002, 9.00000000e+001, 9.20000000e+001]],
   [[1.40000000e+001, 1.80000000e+001, 1.70000000e+001 ... 1.20000000e+001, 7.00000000e+000, 1.00000000e+001],
    [1.00000000e+001, 1.20000000e+001, 1.10000000e+001 ... 2.30000000e+001, 1.60000000e+001, 2.20000000e+001],
    [8.00000000e+000, 6.00000000e+000, 7.00000000e+000 ... 6.10000000e+001, 6.40000000e+001, 4.30000000e+001],
    ...
    [1.29000000e+002, 1.33000000e+002, 1.36000000e+002 ... 5.30000000e+001, 6.30000000e+001, 7.30000000e+001],
    [1.63000000e+002, 1.58000000e+002, 1.59000000e+002 ... 6.00000000e+001, 6.50000000e+001, 7.40000000e+001],
    [1.89000000e+002, 1.88000000e+002, 1.91000000e+002 ... 9.60000000e+001, 8.10000000e+001, 8.30000000e+001]],
   [[1.50000000e+001, 1.90000000e+001, 1.80000000e+001 ... 1.50000000e+001, 1.00000000e+001, 1.30000000e+001],
    [1.10000000e+001, 1.30000000e+001, 1.20000000e+001 ... 1.20000000e+001, 1.40000000e+001, 2.40000000e+001],
    [9.00000000e+000, 7.00000000e+000, 8.00000000e+000 ... 4.80000000e+001, 5.50000000e+001, 3.70000000e+001],
    ...
    [1.09000000e+002, 1.18000000e+002, 1.23000000e+002 ... 4.20000000e+001, 4.90000000e+001, 6.10000000e+001],
    [1.49000000e+002, 1.46000000e+002, 1.47000000e+002 ... 4.90000000e+001, 4.90000000e+001, 5.70000000e+001],
    [1.80000000e+002, 1.78000000e+002, 1.81000000e+002 ... 8.70000000e+001, 6.70000000e+001, 6.90000000e+001]]]]])}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 100. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 100](transpose_b=True).

generate models:295

analyse the exceptions in iter:358
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0.5403, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

         ...,

         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]],
       grad_fn=<ReshapeAliasBackward0>)]}
Given groups=1, weight of size [512, 256, 1, 1], expected input[1, 512, 32, 100] to have 256 channels, but got 512 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 512, 32, 100], dtype=Float32, value=
[[[[5.40302277e-001, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  ...
  [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 512, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:296

analyse the exceptions in iter:359
torch exception:
{'id': 0, 'name': 'linear', 'frame_work': 'torch', 'input_datas': tensor([[[[[17., 20., 24.,  ..., 39., 45., 45.],
           [18., 21., 25.,  ..., 18., 20., 21.],
           [18., 22., 25.,  ..., 50., 51., 44.],
           ...,
           [13., 17., 21.,  ...,  6.,  2.,  2.],
           [12., 15., 19.,  ...,  7.,  6.,  3.],
           [11., 14., 17.,  ..., 10., 10.,  4.]],

          [[26., 29., 33.,  ..., 41., 45., 45.],
           [27., 30., 34.,  ..., 33., 34., 32.],
           [28., 31., 34.,  ..., 49., 49., 43.],
           ...,
           [15., 19., 23.,  ...,  2.,  1.,  1.],
           [14., 17., 21.,  ...,  2.,  2.,  2.],
           [13., 16., 19.,  ...,  4.,  4.,  3.]],

          [[21., 24., 28.,  ..., 37., 42., 41.],
           [22., 25., 29.,  ..., 35., 37., 35.],
           [22., 26., 29.,  ..., 48., 49., 44.],
           ...,
           [12., 16., 20.,  ...,  1.,  0.,  0.],
           [11., 14., 18.,  ...,  2.,  1.,  0.],
           [10., 13., 16.,  ...,  4.,  4.,  1.]]]]])}
mat1 and mat2 shapes cannot be multiplied (96x32 and 100x100)
mindspore exception:
{'id': 0, 'name': 'linear', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.70000000e+001, 2.00000000e+001, 2.40000000e+001 ... 3.90000000e+001, 4.50000000e+001, 4.50000000e+001],
    [1.80000000e+001, 2.10000000e+001, 2.50000000e+001 ... 1.80000000e+001, 2.00000000e+001, 2.10000000e+001],
    [1.80000000e+001, 2.20000000e+001, 2.50000000e+001 ... 5.00000000e+001, 5.10000000e+001, 4.40000000e+001],
    ...
    [1.30000000e+001, 1.70000000e+001, 2.10000000e+001 ... 6.00000000e+000, 2.00000000e+000, 2.00000000e+000],
    [1.20000000e+001, 1.50000000e+001, 1.90000000e+001 ... 7.00000000e+000, 6.00000000e+000, 3.00000000e+000],
    [1.10000000e+001, 1.40000000e+001, 1.70000000e+001 ... 1.00000000e+001, 1.00000000e+001, 4.00000000e+000]],
   [[2.60000000e+001, 2.90000000e+001, 3.30000000e+001 ... 4.10000000e+001, 4.50000000e+001, 4.50000000e+001],
    [2.70000000e+001, 3.00000000e+001, 3.40000000e+001 ... 3.30000000e+001, 3.40000000e+001, 3.20000000e+001],
    [2.80000000e+001, 3.10000000e+001, 3.40000000e+001 ... 4.90000000e+001, 4.90000000e+001, 4.30000000e+001],
    ...
    [1.50000000e+001, 1.90000000e+001, 2.30000000e+001 ... 2.00000000e+000, 1.00000000e+000, 1.00000000e+000],
    [1.40000000e+001, 1.70000000e+001, 2.10000000e+001 ... 2.00000000e+000, 2.00000000e+000, 2.00000000e+000],
    [1.30000000e+001, 1.60000000e+001, 1.90000000e+001 ... 4.00000000e+000, 4.00000000e+000, 3.00000000e+000]],
   [[2.10000000e+001, 2.40000000e+001, 2.80000000e+001 ... 3.70000000e+001, 4.20000000e+001, 4.10000000e+001],
    [2.20000000e+001, 2.50000000e+001, 2.90000000e+001 ... 3.50000000e+001, 3.70000000e+001, 3.50000000e+001],
    [2.20000000e+001, 2.60000000e+001, 2.90000000e+001 ... 4.80000000e+001, 4.90000000e+001, 4.40000000e+001],
    ...
    [1.20000000e+001, 1.60000000e+001, 2.00000000e+001 ... 1.00000000e+000, 0.00000000e+000, 0.00000000e+000],
    [1.10000000e+001, 1.40000000e+001, 1.80000000e+001 ... 2.00000000e+000, 1.00000000e+000, 0.00000000e+000],
    [1.00000000e+001, 1.30000000e+001, 1.60000000e+001 ... 4.00000000e+000, 4.00000000e+000, 1.00000000e+000]]]]])}
For 'MatMul', the input dimensions must be equal, but got 'x1_col': 32 and 'x2_row': 100. And 'x' shape [96, 32](transpose_a=False), 'y' shape [100, 100](transpose_b=True).

generate models:297

analyse the exceptions in iter:364
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[255., 253., 254.,  ..., 254., 253., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 254., 254.,  ..., 252., 253., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.]],

          [[255., 253., 254.,  ..., 254., 253., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 254., 254.,  ..., 255., 253., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.]],

          [[255., 253., 254.,  ..., 254., 253., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.],
           [255., 255., 255.,  ..., 255., 255., 255.],
           ...,
           [255., 254., 254.,  ..., 254., 254., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.],
           [255., 254., 255.,  ..., 255., 254., 255.]]]]])}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[2.55000000e+002, 2.53000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.53000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.55000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.55000000e+002, 2.55000000e+002],
    ...
    [2.55000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.52000000e+002, 2.53000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002]],
   [[2.55000000e+002, 2.53000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.53000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.55000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.55000000e+002, 2.55000000e+002],
    ...
    [2.55000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.55000000e+002, 2.53000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002]],
   [[2.55000000e+002, 2.53000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.53000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.55000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.55000000e+002, 2.55000000e+002],
    ...
    [2.55000000e+002, 2.54000000e+002, 2.54000000e+002 ... 2.54000000e+002, 2.54000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002],
    [2.55000000e+002, 2.54000000e+002, 2.55000000e+002 ... 2.55000000e+002, 2.54000000e+002, 2.55000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:301

analyse the exceptions in iter:369
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[121., 160., 121.,  ...,  56.,  55.,  51.],
           [ 93., 133., 125.,  ...,  51.,  52.,  51.],
           [ 91.,  95., 125.,  ...,  60.,  58.,  52.],
           ...,
           [192., 187., 194.,  ..., 142., 142., 141.],
           [189., 183., 187.,  ..., 143., 130., 124.],
           [188., 184., 183.,  ..., 155., 143., 136.]],

          [[136., 179., 142.,  ...,  73.,  68.,  64.],
           [109., 151., 145.,  ...,  68.,  65.,  64.],
           [109., 113., 145.,  ...,  76.,  71.,  65.],
           ...,
           [189., 184., 191.,  ..., 158., 153., 152.],
           [186., 180., 184.,  ..., 149., 136., 130.],
           [185., 181., 180.,  ..., 153., 144., 137.]],

          [[128., 149., 101.,  ...,  47.,  48.,  44.],
           [ 95., 123., 107.,  ...,  46.,  45.,  44.],
           [ 88.,  87., 112.,  ...,  57.,  51.,  45.],
           ...,
           [174., 169., 176.,  ..., 165., 161., 160.],
           [171., 165., 169.,  ..., 148., 139., 133.],
           [170., 166., 165.,  ..., 144., 139., 132.]]]]])}
Given groups=1, weight of size [256, 64, 1, 1], expected input[1, 3, 32, 32] to have 64 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.21000000e+002, 1.60000000e+002, 1.21000000e+002 ... 5.60000000e+001, 5.50000000e+001, 5.10000000e+001],
    [9.30000000e+001, 1.33000000e+002, 1.25000000e+002 ... 5.10000000e+001, 5.20000000e+001, 5.10000000e+001],
    [9.10000000e+001, 9.50000000e+001, 1.25000000e+002 ... 6.00000000e+001, 5.80000000e+001, 5.20000000e+001],
    ...
    [1.92000000e+002, 1.87000000e+002, 1.94000000e+002 ... 1.42000000e+002, 1.42000000e+002, 1.41000000e+002],
    [1.89000000e+002, 1.83000000e+002, 1.87000000e+002 ... 1.43000000e+002, 1.30000000e+002, 1.24000000e+002],
    [1.88000000e+002, 1.84000000e+002, 1.83000000e+002 ... 1.55000000e+002, 1.43000000e+002, 1.36000000e+002]],
   [[1.36000000e+002, 1.79000000e+002, 1.42000000e+002 ... 7.30000000e+001, 6.80000000e+001, 6.40000000e+001],
    [1.09000000e+002, 1.51000000e+002, 1.45000000e+002 ... 6.80000000e+001, 6.50000000e+001, 6.40000000e+001],
    [1.09000000e+002, 1.13000000e+002, 1.45000000e+002 ... 7.60000000e+001, 7.10000000e+001, 6.50000000e+001],
    ...
    [1.89000000e+002, 1.84000000e+002, 1.91000000e+002 ... 1.58000000e+002, 1.53000000e+002, 1.52000000e+002],
    [1.86000000e+002, 1.80000000e+002, 1.84000000e+002 ... 1.49000000e+002, 1.36000000e+002, 1.30000000e+002],
    [1.85000000e+002, 1.81000000e+002, 1.80000000e+002 ... 1.53000000e+002, 1.44000000e+002, 1.37000000e+002]],
   [[1.28000000e+002, 1.49000000e+002, 1.01000000e+002 ... 4.70000000e+001, 4.80000000e+001, 4.40000000e+001],
    [9.50000000e+001, 1.23000000e+002, 1.07000000e+002 ... 4.60000000e+001, 4.50000000e+001, 4.40000000e+001],
    [8.80000000e+001, 8.70000000e+001, 1.12000000e+002 ... 5.70000000e+001, 5.10000000e+001, 4.50000000e+001],
    ...
    [1.74000000e+002, 1.69000000e+002, 1.76000000e+002 ... 1.65000000e+002, 1.61000000e+002, 1.60000000e+002],
    [1.71000000e+002, 1.65000000e+002, 1.69000000e+002 ... 1.48000000e+002, 1.39000000e+002, 1.33000000e+002],
    [1.70000000e+002, 1.66000000e+002, 1.65000000e+002 ... 1.44000000e+002, 1.39000000e+002, 1.32000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 64, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:306

analyse the exceptions in iter:375
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[174., 175., 176.,  ..., 180., 169., 170.],
           [171., 170., 170.,  ..., 179., 173., 173.],
           [168., 167., 165.,  ..., 166., 175., 177.],
           ...,
           [172., 175., 117.,  ..., 102., 136., 142.],
           [170., 175.,  98.,  ...,  94., 175., 184.],
           [187., 190., 128.,  ...,  66., 160., 176.]],

          [[187., 189., 190.,  ..., 188., 182., 186.],
           [184., 184., 184.,  ..., 185., 186., 190.],
           [181., 180., 179.,  ..., 181., 186., 187.],
           ...,
           [194., 194., 123.,  ..., 117., 167., 173.],
           [191., 193., 102.,  ...,  89., 192., 204.],
           [200., 202., 132.,  ...,  62., 181., 201.]],

          [[220., 224., 227.,  ..., 221., 217., 221.],
           [218., 219., 221.,  ..., 223., 220., 220.],
           [215., 216., 216.,  ..., 221., 220., 218.],
           ...,
           [227., 227., 143.,  ..., 149., 203., 217.],
           [223., 225., 119.,  ..., 108., 212., 230.],
           [227., 230., 148.,  ...,  91., 211., 233.]]]]])}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.74000000e+002, 1.75000000e+002, 1.76000000e+002 ... 1.80000000e+002, 1.69000000e+002, 1.70000000e+002],
    [1.71000000e+002, 1.70000000e+002, 1.70000000e+002 ... 1.79000000e+002, 1.73000000e+002, 1.73000000e+002],
    [1.68000000e+002, 1.67000000e+002, 1.65000000e+002 ... 1.66000000e+002, 1.75000000e+002, 1.77000000e+002],
    ...
    [1.72000000e+002, 1.75000000e+002, 1.17000000e+002 ... 1.02000000e+002, 1.36000000e+002, 1.42000000e+002],
    [1.70000000e+002, 1.75000000e+002, 9.80000000e+001 ... 9.40000000e+001, 1.75000000e+002, 1.84000000e+002],
    [1.87000000e+002, 1.90000000e+002, 1.28000000e+002 ... 6.60000000e+001, 1.60000000e+002, 1.76000000e+002]],
   [[1.87000000e+002, 1.89000000e+002, 1.90000000e+002 ... 1.88000000e+002, 1.82000000e+002, 1.86000000e+002],
    [1.84000000e+002, 1.84000000e+002, 1.84000000e+002 ... 1.85000000e+002, 1.86000000e+002, 1.90000000e+002],
    [1.81000000e+002, 1.80000000e+002, 1.79000000e+002 ... 1.81000000e+002, 1.86000000e+002, 1.87000000e+002],
    ...
    [1.94000000e+002, 1.94000000e+002, 1.23000000e+002 ... 1.17000000e+002, 1.67000000e+002, 1.73000000e+002],
    [1.91000000e+002, 1.93000000e+002, 1.02000000e+002 ... 8.90000000e+001, 1.92000000e+002, 2.04000000e+002],
    [2.00000000e+002, 2.02000000e+002, 1.32000000e+002 ... 6.20000000e+001, 1.81000000e+002, 2.01000000e+002]],
   [[2.20000000e+002, 2.24000000e+002, 2.27000000e+002 ... 2.21000000e+002, 2.17000000e+002, 2.21000000e+002],
    [2.18000000e+002, 2.19000000e+002, 2.21000000e+002 ... 2.23000000e+002, 2.20000000e+002, 2.20000000e+002],
    [2.15000000e+002, 2.16000000e+002, 2.16000000e+002 ... 2.21000000e+002, 2.20000000e+002, 2.18000000e+002],
    ...
    [2.27000000e+002, 2.27000000e+002, 1.43000000e+002 ... 1.49000000e+002, 2.03000000e+002, 2.17000000e+002],
    [2.23000000e+002, 2.25000000e+002, 1.19000000e+002 ... 1.08000000e+002, 2.12000000e+002, 2.30000000e+002],
    [2.27000000e+002, 2.30000000e+002, 1.48000000e+002 ... 9.10000000e+001, 2.11000000e+002, 2.33000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:311

analyse the exceptions in iter:378
torch exception:
{'id': 4, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          ...,
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],

         [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          ...,
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],

         [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          ...,
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],

         ...,

         [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          ...,
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],

         [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          ...,
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],

         [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          ...,
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],
          [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]]]],
       grad_fn=<SoftmaxBackward0>)]}
Given groups=1, weight of size [512, 128, 1, 1], expected input[1, 64, 32, 100] to have 128 channels, but got 64 channels instead
mindspore exception:
{'id': 4, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 64, 32, 100], dtype=Float32, value=
[[[[9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   ...
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003]],
  [[9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   ...
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003]],
  [[9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   ...
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003]],
  ...
  [[9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   ...
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003]],
  [[9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   ...
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003]],
  [[9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   ...
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003],
   [9.99999978e-003, 9.99999978e-003, 9.99999978e-003 ... 9.99999978e-003, 9.99999978e-003, 9.99999978e-003]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 64, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:314

analyse the exceptions in iter:379
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[16.0310, 16.0312, 16.0307, 16.0313, 16.0307, 16.0297, 16.0271,
           16.0324, 16.0356, 15.9515, 15.8670, 15.9966, 16.0183, 16.0221,
           16.0218, 16.0226],
          [16.0351, 16.0353, 16.0349, 16.0354, 16.0349, 16.0343, 16.0321,
           16.0342, 16.0365, 15.9790, 16.0029, 16.0202, 16.0281, 16.0300,
           16.0298, 16.0300],
          [16.0374, 16.0376, 16.0374, 16.0378, 16.0374, 16.0369, 16.0350,
           16.0361, 16.0377, 15.9967, 16.0178, 16.0281, 16.0331, 16.0342,
           16.0340, 16.0340],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
            0.0000,  0.0000]]]])]}
Given groups=1, weight of size [128, 128, 1, 1], expected input[1, 3, 16, 16] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 16, 16], dtype=Float32, value=
[[[[1.60310345e+001, 1.60311966e+001, 1.60307159e+001 ... 1.60221062e+001, 1.60218391e+001, 1.60226040e+001],
   [1.60351219e+001, 1.60352898e+001, 1.60348988e+001 ... 1.60299702e+001, 1.60298214e+001, 1.60299854e+001],
   [1.60374107e+001, 1.60375900e+001, 1.60374184e+001 ... 1.60341778e+001, 1.60340118e+001, 1.60340500e+001],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:315

analyse the exceptions in iter:381
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[155., 156., 168.,  ..., 105., 118., 130.],
           [164., 161., 170.,  ..., 147., 148., 124.],
           [185., 187., 183.,  ..., 172., 159., 141.],
           ...,
           [176., 161., 146.,  ...,  70.,  93., 105.],
           [176., 136., 139.,  ...,  69., 111., 118.],
           [172., 159., 164.,  ...,  83., 121., 116.]],

          [[145., 143., 157.,  ..., 104., 117., 130.],
           [153., 146., 158.,  ..., 139., 142., 120.],
           [173., 172., 169.,  ..., 161., 151., 135.],
           ...,
           [157., 148., 137.,  ...,  82., 102., 116.],
           [159., 124., 131.,  ...,  82., 117., 125.],
           [157., 146., 154.,  ...,  97., 127., 123.]],

          [[ 70.,  66.,  80.,  ...,  30.,  50.,  61.],
           [ 73.,  64.,  77.,  ...,  60.,  64.,  44.],
           [ 88.,  85.,  83.,  ...,  72.,  60.,  46.],
           ...,
           [ 73.,  76.,  76.,  ...,  36.,  52.,  61.],
           [ 86.,  61.,  74.,  ...,  38.,  61.,  64.],
           [ 92.,  89., 101.,  ...,  57.,  68.,  59.]]]]])}
Given groups=1, weight of size [128, 128, 1, 1], expected input[1, 3, 32, 32] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.55000000e+002, 1.56000000e+002, 1.68000000e+002 ... 1.05000000e+002, 1.18000000e+002, 1.30000000e+002],
    [1.64000000e+002, 1.61000000e+002, 1.70000000e+002 ... 1.47000000e+002, 1.48000000e+002, 1.24000000e+002],
    [1.85000000e+002, 1.87000000e+002, 1.83000000e+002 ... 1.72000000e+002, 1.59000000e+002, 1.41000000e+002],
    ...
    [1.76000000e+002, 1.61000000e+002, 1.46000000e+002 ... 7.00000000e+001, 9.30000000e+001, 1.05000000e+002],
    [1.76000000e+002, 1.36000000e+002, 1.39000000e+002 ... 6.90000000e+001, 1.11000000e+002, 1.18000000e+002],
    [1.72000000e+002, 1.59000000e+002, 1.64000000e+002 ... 8.30000000e+001, 1.21000000e+002, 1.16000000e+002]],
   [[1.45000000e+002, 1.43000000e+002, 1.57000000e+002 ... 1.04000000e+002, 1.17000000e+002, 1.30000000e+002],
    [1.53000000e+002, 1.46000000e+002, 1.58000000e+002 ... 1.39000000e+002, 1.42000000e+002, 1.20000000e+002],
    [1.73000000e+002, 1.72000000e+002, 1.69000000e+002 ... 1.61000000e+002, 1.51000000e+002, 1.35000000e+002],
    ...
    [1.57000000e+002, 1.48000000e+002, 1.37000000e+002 ... 8.20000000e+001, 1.02000000e+002, 1.16000000e+002],
    [1.59000000e+002, 1.24000000e+002, 1.31000000e+002 ... 8.20000000e+001, 1.17000000e+002, 1.25000000e+002],
    [1.57000000e+002, 1.46000000e+002, 1.54000000e+002 ... 9.70000000e+001, 1.27000000e+002, 1.23000000e+002]],
   [[7.00000000e+001, 6.60000000e+001, 8.00000000e+001 ... 3.00000000e+001, 5.00000000e+001, 6.10000000e+001],
    [7.30000000e+001, 6.40000000e+001, 7.70000000e+001 ... 6.00000000e+001, 6.40000000e+001, 4.40000000e+001],
    [8.80000000e+001, 8.50000000e+001, 8.30000000e+001 ... 7.20000000e+001, 6.00000000e+001, 4.60000000e+001],
    ...
    [7.30000000e+001, 7.60000000e+001, 7.60000000e+001 ... 3.60000000e+001, 5.20000000e+001, 6.10000000e+001],
    [8.60000000e+001, 6.10000000e+001, 7.40000000e+001 ... 3.80000000e+001, 6.10000000e+001, 6.40000000e+001],
    [9.20000000e+001, 8.90000000e+001, 1.01000000e+002 ... 5.70000000e+001, 6.80000000e+001, 5.90000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:316

analyse the exceptions in iter:408
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[112., 117.,  89.,  ..., 141., 133., 137.],
          [116., 122., 104.,  ..., 140., 137., 135.],
          [125., 129., 115.,  ..., 150., 144., 157.],
          ...,
          [184., 186., 190.,  ..., 190., 188., 184.],
          [185., 187., 190.,  ..., 191., 188., 184.],
          [177., 178., 179.,  ..., 186., 183., 181.]],

         [[107., 106.,  82.,  ..., 130., 123., 127.],
          [113., 114.,  99.,  ..., 127., 126., 125.],
          [124., 123., 110.,  ..., 139., 135., 151.],
          ...,
          [185., 187., 191.,  ..., 191., 189., 186.],
          [186., 188., 191.,  ..., 192., 189., 186.],
          [178., 178., 180.,  ..., 187., 184., 182.]],

         [[101.,  90.,  70.,  ..., 112., 107., 111.],
          [107., 103.,  89.,  ..., 113., 112., 114.],
          [120., 117., 102.,  ..., 124., 120., 141.],
          ...,
          [189., 191., 194.,  ..., 195., 193., 189.],
          [190., 192., 195.,  ..., 196., 193., 190.],
          [182., 183., 184.,  ..., 190., 188., 186.]]]])]}
Given groups=1, weight of size [256, 128, 1, 1], expected input[1, 3, 32, 32] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[1.12000000e+002, 1.17000000e+002, 8.90000000e+001 ... 1.41000000e+002, 1.33000000e+002, 1.37000000e+002],
   [1.16000000e+002, 1.22000000e+002, 1.04000000e+002 ... 1.40000000e+002, 1.37000000e+002, 1.35000000e+002],
   [1.25000000e+002, 1.29000000e+002, 1.15000000e+002 ... 1.50000000e+002, 1.44000000e+002, 1.57000000e+002],
   ...
   [1.84000000e+002, 1.86000000e+002, 1.90000000e+002 ... 1.90000000e+002, 1.88000000e+002, 1.84000000e+002],
   [1.85000000e+002, 1.87000000e+002, 1.90000000e+002 ... 1.91000000e+002, 1.88000000e+002, 1.84000000e+002],
   [1.77000000e+002, 1.78000000e+002, 1.79000000e+002 ... 1.86000000e+002, 1.83000000e+002, 1.81000000e+002]],
  [[1.07000000e+002, 1.06000000e+002, 8.20000000e+001 ... 1.30000000e+002, 1.23000000e+002, 1.27000000e+002],
   [1.13000000e+002, 1.14000000e+002, 9.90000000e+001 ... 1.27000000e+002, 1.26000000e+002, 1.25000000e+002],
   [1.24000000e+002, 1.23000000e+002, 1.10000000e+002 ... 1.39000000e+002, 1.35000000e+002, 1.51000000e+002],
   ...
   [1.85000000e+002, 1.87000000e+002, 1.91000000e+002 ... 1.91000000e+002, 1.89000000e+002, 1.86000000e+002],
   [1.86000000e+002, 1.88000000e+002, 1.91000000e+002 ... 1.92000000e+002, 1.89000000e+002, 1.86000000e+002],
   [1.78000000e+002, 1.78000000e+002, 1.80000000e+002 ... 1.87000000e+002, 1.84000000e+002, 1.82000000e+002]],
  [[1.01000000e+002, 9.00000000e+001, 7.00000000e+001 ... 1.12000000e+002, 1.07000000e+002, 1.11000000e+002],
   [1.07000000e+002, 1.03000000e+002, 8.90000000e+001 ... 1.13000000e+002, 1.12000000e+002, 1.14000000e+002],
   [1.20000000e+002, 1.17000000e+002, 1.02000000e+002 ... 1.24000000e+002, 1.20000000e+002, 1.41000000e+002],
   ...
   [1.89000000e+002, 1.91000000e+002, 1.94000000e+002 ... 1.95000000e+002, 1.93000000e+002, 1.89000000e+002],
   [1.90000000e+002, 1.92000000e+002, 1.95000000e+002 ... 1.96000000e+002, 1.93000000e+002, 1.90000000e+002],
   [1.82000000e+002, 1.83000000e+002, 1.84000000e+002 ... 1.90000000e+002, 1.88000000e+002, 1.86000000e+002]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:340

analyse output arrays in iter:409

pre layer res:
12:exp
{'name': 'exp', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 8, 8]), 'from': [6], 'to': [10]}
tf node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 8, 8]), 'from': [12], 'to': [7]}
ms node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 64, 8, 8), 'from': [12], 'to': [7]}
torch node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 8, 8]), 'from': [12], 'to': [7]}

generate models:341

analyse the exceptions in iter:418
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[19388., 19388., 19388.,  ..., 19388., 19388., 19388.],
          [20021., 20021., 20021.,  ..., 20021., 20021., 20021.],
          [19834., 19834., 19834.,  ..., 19834., 19834., 19834.],
          ...,
          [10627., 10627., 10627.,  ..., 10627., 10627., 10627.],
          [13812., 13812., 13812.,  ..., 13812., 13812., 13812.],
          [19886., 19886., 19886.,  ..., 19886., 19886., 19886.]],

         [[19388., 19388., 19388.,  ..., 19388., 19388., 19388.],
          [20021., 20021., 20021.,  ..., 20021., 20021., 20021.],
          [19834., 19834., 19834.,  ..., 19834., 19834., 19834.],
          ...,
          [10627., 10627., 10627.,  ..., 10627., 10627., 10627.],
          [13812., 13812., 13812.,  ..., 13812., 13812., 13812.],
          [19886., 19886., 19886.,  ..., 19886., 19886., 19886.]],

         [[19388., 19388., 19388.,  ..., 19388., 19388., 19388.],
          [20021., 20021., 20021.,  ..., 20021., 20021., 20021.],
          [19834., 19834., 19834.,  ..., 19834., 19834., 19834.],
          ...,
          [10627., 10627., 10627.,  ..., 10627., 10627., 10627.],
          [13812., 13812., 13812.,  ..., 13812., 13812., 13812.],
          [19886., 19886., 19886.,  ..., 19886., 19886., 19886.]],

         ...,

         [[19388., 19388., 19388.,  ..., 19388., 19388., 19388.],
          [20021., 20021., 20021.,  ..., 20021., 20021., 20021.],
          [19834., 19834., 19834.,  ..., 19834., 19834., 19834.],
          ...,
          [10627., 10627., 10627.,  ..., 10627., 10627., 10627.],
          [13812., 13812., 13812.,  ..., 13812., 13812., 13812.],
          [19886., 19886., 19886.,  ..., 19886., 19886., 19886.]],

         [[19388., 19388., 19388.,  ..., 19388., 19388., 19388.],
          [20021., 20021., 20021.,  ..., 20021., 20021., 20021.],
          [19834., 19834., 19834.,  ..., 19834., 19834., 19834.],
          ...,
          [10627., 10627., 10627.,  ..., 10627., 10627., 10627.],
          [13812., 13812., 13812.,  ..., 13812., 13812., 13812.],
          [19886., 19886., 19886.,  ..., 19886., 19886., 19886.]],

         [[19388., 19388., 19388.,  ..., 19388., 19388., 19388.],
          [20021., 20021., 20021.,  ..., 20021., 20021., 20021.],
          [19834., 19834., 19834.,  ..., 19834., 19834., 19834.],
          ...,
          [10627., 10627., 10627.,  ..., 10627., 10627., 10627.],
          [13812., 13812., 13812.,  ..., 13812., 13812., 13812.],
          [19886., 19886., 19886.,  ..., 19886., 19886., 19886.]]]],
       grad_fn=<UnsafeViewBackward0>)]}
Given groups=1, weight of size [512, 256, 1, 1], expected input[1, 512, 32, 100] to have 256 channels, but got 512 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 512, 32, 100], dtype=Float32, value=
[[[[1.93880000e+004, 1.93880000e+004, 1.93880000e+004 ... 1.93880000e+004, 1.93880000e+004, 1.93880000e+004],
   [2.00210000e+004, 2.00210000e+004, 2.00210000e+004 ... 2.00210000e+004, 2.00210000e+004, 2.00210000e+004],
   [1.98340000e+004, 1.98340000e+004, 1.98340000e+004 ... 1.98340000e+004, 1.98340000e+004, 1.98340000e+004],
   ...
   [1.06270000e+004, 1.06270000e+004, 1.06270000e+004 ... 1.06270000e+004, 1.06270000e+004, 1.06270000e+004],
   [1.38120000e+004, 1.38120000e+004, 1.38120000e+004 ... 1.38120000e+004, 1.38120000e+004, 1.38120000e+004],
   [1.98860000e+004, 1.98860000e+004, 1.98860000e+004 ... 1.98860000e+004, 1.98860000e+004, 1.98860000e+004]],
  [[1.93880000e+004, 1.93880000e+004, 1.93880000e+004 ... 1.93880000e+004, 1.93880000e+004, 1.93880000e+004],
   [2.00210000e+004, 2.00210000e+004, 2.00210000e+004 ... 2.00210000e+004, 2.00210000e+004, 2.00210000e+004],
   [1.98340000e+004, 1.98340000e+004, 1.98340000e+004 ... 1.98340000e+004, 1.98340000e+004, 1.98340000e+004],
   ...
   [1.06270000e+004, 1.06270000e+004, 1.06270000e+004 ... 1.06270000e+004, 1.06270000e+004, 1.06270000e+004],
   [1.38120000e+004, 1.38120000e+004, 1.38120000e+004 ... 1.38120000e+004, 1.38120000e+004, 1.38120000e+004],
   [1.98860000e+004, 1.98860000e+004, 1.98860000e+004 ... 1.98860000e+004, 1.98860000e+004, 1.98860000e+004]],
  [[1.93880000e+004, 1.93880000e+004, 1.93880000e+004 ... 1.93880000e+004, 1.93880000e+004, 1.93880000e+004],
   [2.00210000e+004, 2.00210000e+004, 2.00210000e+004 ... 2.00210000e+004, 2.00210000e+004, 2.00210000e+004],
   [1.98340000e+004, 1.98340000e+004, 1.98340000e+004 ... 1.98340000e+004, 1.98340000e+004, 1.98340000e+004],
   ...
   [1.06270000e+004, 1.06270000e+004, 1.06270000e+004 ... 1.06270000e+004, 1.06270000e+004, 1.06270000e+004],
   [1.38120000e+004, 1.38120000e+004, 1.38120000e+004 ... 1.38120000e+004, 1.38120000e+004, 1.38120000e+004],
   [1.98860000e+004, 1.98860000e+004, 1.98860000e+004 ... 1.98860000e+004, 1.98860000e+004, 1.98860000e+004]],
  ...
  [[1.93880000e+004, 1.93880000e+004, 1.93880000e+004 ... 1.93880000e+004, 1.93880000e+004, 1.93880000e+004],
   [2.00210000e+004, 2.00210000e+004, 2.00210000e+004 ... 2.00210000e+004, 2.00210000e+004, 2.00210000e+004],
   [1.98340000e+004, 1.98340000e+004, 1.98340000e+004 ... 1.98340000e+004, 1.98340000e+004, 1.98340000e+004],
   ...
   [1.06270000e+004, 1.06270000e+004, 1.06270000e+004 ... 1.06270000e+004, 1.06270000e+004, 1.06270000e+004],
   [1.38120000e+004, 1.38120000e+004, 1.38120000e+004 ... 1.38120000e+004, 1.38120000e+004, 1.38120000e+004],
   [1.98860000e+004, 1.98860000e+004, 1.98860000e+004 ... 1.98860000e+004, 1.98860000e+004, 1.98860000e+004]],
  [[1.93880000e+004, 1.93880000e+004, 1.93880000e+004 ... 1.93880000e+004, 1.93880000e+004, 1.93880000e+004],
   [2.00210000e+004, 2.00210000e+004, 2.00210000e+004 ... 2.00210000e+004, 2.00210000e+004, 2.00210000e+004],
   [1.98340000e+004, 1.98340000e+004, 1.98340000e+004 ... 1.98340000e+004, 1.98340000e+004, 1.98340000e+004],
   ...
   [1.06270000e+004, 1.06270000e+004, 1.06270000e+004 ... 1.06270000e+004, 1.06270000e+004, 1.06270000e+004],
   [1.38120000e+004, 1.38120000e+004, 1.38120000e+004 ... 1.38120000e+004, 1.38120000e+004, 1.38120000e+004],
   [1.98860000e+004, 1.98860000e+004, 1.98860000e+004 ... 1.98860000e+004, 1.98860000e+004, 1.98860000e+004]],
  [[1.93880000e+004, 1.93880000e+004, 1.93880000e+004 ... 1.93880000e+004, 1.93880000e+004, 1.93880000e+004],
   [2.00210000e+004, 2.00210000e+004, 2.00210000e+004 ... 2.00210000e+004, 2.00210000e+004, 2.00210000e+004],
   [1.98340000e+004, 1.98340000e+004, 1.98340000e+004 ... 1.98340000e+004, 1.98340000e+004, 1.98340000e+004],
   ...
   [1.06270000e+004, 1.06270000e+004, 1.06270000e+004 ... 1.06270000e+004, 1.06270000e+004, 1.06270000e+004],
   [1.38120000e+004, 1.38120000e+004, 1.38120000e+004 ... 1.38120000e+004, 1.38120000e+004, 1.38120000e+004],
   [1.98860000e+004, 1.98860000e+004, 1.98860000e+004 ... 1.98860000e+004, 1.98860000e+004, 1.98860000e+004]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 512, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:348

analyse the exceptions in iter:419
torch exception:
{'id': 5, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          ...,
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625]],

         [[0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          ...,
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625]],

         [[0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          ...,
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625]],

         ...,

         [[0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          ...,
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625]],

         [[0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          ...,
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625]],

         [[0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          ...,
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625],
          [0.0625, 0.0625, 0.0625,  ..., 0.0625, 0.0625, 0.0625]]]])]}
Given groups=1, weight of size [64, 64, 1, 1], expected input[1, 256, 8, 8] to have 64 channels, but got 256 channels instead
mindspore exception:
{'id': 5, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 256, 8, 8], dtype=Float32, value=
[[[[6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   ...
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002]],
  [[6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   ...
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002]],
  [[6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   ...
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002]],
  ...
  [[6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   ...
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002]],
  [[6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   ...
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002]],
  [[6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   ...
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002],
   [6.25000000e-002, 6.25000000e-002, 6.25000000e-002 ... 6.25000000e-002, 6.25000000e-002, 6.25000000e-002]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 64, but got 'C_in' of input 'x' shape: 256, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:349

analyse the exceptions in iter:422
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[194., 191., 192.,  ..., 184., 163., 200.],
           [196., 193., 194.,  ..., 106., 125., 205.],
           [201., 198., 198.,  ...,  42., 155., 209.],
           ...,
           [168., 213., 194.,  ..., 193., 192., 195.],
           [168., 192., 210.,  ..., 190., 191., 187.],
           [186., 189., 216.,  ..., 153., 156., 152.]],

          [[215., 211., 213.,  ..., 196., 178., 217.],
           [213., 210., 211.,  ..., 101., 125., 216.],
           [214., 210., 211.,  ...,  24., 143., 211.],
           ...,
           [156., 202., 184.,  ..., 167., 164., 167.],
           [157., 180., 197.,  ..., 168., 168., 164.],
           [175., 177., 203.,  ..., 133., 135., 125.]],

          [[229., 225., 226.,  ..., 208., 190., 232.],
           [226., 223., 223.,  ..., 111., 137., 232.],
           [227., 223., 223.,  ...,  31., 150., 220.],
           ...,
           [121., 183., 173.,  ..., 144., 141., 146.],
           [121., 157., 185.,  ..., 149., 146., 143.],
           [144., 152., 184.,  ..., 172., 173., 170.]]]]])}
Given groups=1, weight of size [128, 128, 1, 1], expected input[1, 3, 32, 32] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.94000000e+002, 1.91000000e+002, 1.92000000e+002 ... 1.84000000e+002, 1.63000000e+002, 2.00000000e+002],
    [1.96000000e+002, 1.93000000e+002, 1.94000000e+002 ... 1.06000000e+002, 1.25000000e+002, 2.05000000e+002],
    [2.01000000e+002, 1.98000000e+002, 1.98000000e+002 ... 4.20000000e+001, 1.55000000e+002, 2.09000000e+002],
    ...
    [1.68000000e+002, 2.13000000e+002, 1.94000000e+002 ... 1.93000000e+002, 1.92000000e+002, 1.95000000e+002],
    [1.68000000e+002, 1.92000000e+002, 2.10000000e+002 ... 1.90000000e+002, 1.91000000e+002, 1.87000000e+002],
    [1.86000000e+002, 1.89000000e+002, 2.16000000e+002 ... 1.53000000e+002, 1.56000000e+002, 1.52000000e+002]],
   [[2.15000000e+002, 2.11000000e+002, 2.13000000e+002 ... 1.96000000e+002, 1.78000000e+002, 2.17000000e+002],
    [2.13000000e+002, 2.10000000e+002, 2.11000000e+002 ... 1.01000000e+002, 1.25000000e+002, 2.16000000e+002],
    [2.14000000e+002, 2.10000000e+002, 2.11000000e+002 ... 2.40000000e+001, 1.43000000e+002, 2.11000000e+002],
    ...
    [1.56000000e+002, 2.02000000e+002, 1.84000000e+002 ... 1.67000000e+002, 1.64000000e+002, 1.67000000e+002],
    [1.57000000e+002, 1.80000000e+002, 1.97000000e+002 ... 1.68000000e+002, 1.68000000e+002, 1.64000000e+002],
    [1.75000000e+002, 1.77000000e+002, 2.03000000e+002 ... 1.33000000e+002, 1.35000000e+002, 1.25000000e+002]],
   [[2.29000000e+002, 2.25000000e+002, 2.26000000e+002 ... 2.08000000e+002, 1.90000000e+002, 2.32000000e+002],
    [2.26000000e+002, 2.23000000e+002, 2.23000000e+002 ... 1.11000000e+002, 1.37000000e+002, 2.32000000e+002],
    [2.27000000e+002, 2.23000000e+002, 2.23000000e+002 ... 3.10000000e+001, 1.50000000e+002, 2.20000000e+002],
    ...
    [1.21000000e+002, 1.83000000e+002, 1.73000000e+002 ... 1.44000000e+002, 1.41000000e+002, 1.46000000e+002],
    [1.21000000e+002, 1.57000000e+002, 1.85000000e+002 ... 1.49000000e+002, 1.46000000e+002, 1.43000000e+002],
    [1.44000000e+002, 1.52000000e+002, 1.84000000e+002 ... 1.72000000e+002, 1.73000000e+002, 1.70000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:351

analyse output arrays in iter:423

pre layer res:
7:add
{'name': 'add', 'output': array([[[[4.0267374e+13, 3.5782035e+20,           inf, ...,
                    inf, 8.6431331e+27, 4.5314960e+06],
         [9.9812835e+10,           inf,           inf, ...,
                    inf, 1.3174779e+26, 2.4741130e+08],
         [2.6439544e+21,           inf, 2.8896031e+34, ...,
                    inf, 7.1870132e+21, 2.4741130e+08],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[4.0267374e+13, 3.5782035e+20,           inf, ...,
                    inf, 8.6431331e+27, 4.5314960e+06],
         [9.9812835e+10,           inf,           inf, ...,
                    inf, 1.3174779e+26, 2.4741130e+08],
         [2.6439544e+21,           inf, 2.8896031e+34, ...,
                    inf, 7.1870132e+21, 2.4741130e+08],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[4.0267374e+13, 3.5782035e+20,           inf, ...,
                    inf, 8.6431331e+27, 4.5314960e+06],
         [9.9812835e+10,           inf,           inf, ...,
                    inf, 1.3174779e+26, 2.4741130e+08],
         [2.6439544e+21,           inf, 2.8896031e+34, ...,
                    inf, 7.1870132e+21, 2.4741130e+08],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        ...,

        [[4.0267374e+13, 3.5782035e+20,           inf, ...,
                    inf, 8.6431331e+27, 4.5314960e+06],
         [9.9812835e+10,           inf,           inf, ...,
                    inf, 1.3174779e+26, 2.4741130e+08],
         [2.6439544e+21,           inf, 2.8896031e+34, ...,
                    inf, 7.1870132e+21, 2.4741130e+08],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[4.0267374e+13, 3.5782035e+20,           inf, ...,
                    inf, 8.6431331e+27, 4.5314960e+06],
         [9.9812835e+10,           inf,           inf, ...,
                    inf, 1.3174779e+26, 2.4741130e+08],
         [2.6439544e+21,           inf, 2.8896031e+34, ...,
                    inf, 7.1870132e+21, 2.4741130e+08],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[4.0267374e+13, 3.5782035e+20,           inf, ...,
                    inf, 8.6431331e+27, 4.5314960e+06],
         [9.9812835e+10,           inf,           inf, ...,
                    inf, 1.3174779e+26, 2.4741130e+08],
         [2.6439544e+21,           inf, 2.8896031e+34, ...,
                    inf, 7.1870132e+21, 2.4741130e+08],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [1, 15], 'to': [16]}
tf node:
{'name': 'log', 'output': array([[[[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        ...,

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [7], 'to': [4]}
ms node:
{'name': 'log', 'output': array([[[[31.32656 , 47.32656 , 88.72284 , ..., 88.72284 , 64.32656 ,
          15.32656 ],
         [25.326563, 88.72284 , 88.72284 , ..., 88.72284 , 60.14293 ,
          19.326561],
         [49.32656 , 88.72284 , 79.349014, ..., 88.72284 , 50.32656 ,
          19.326561],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ]],

        [[31.32656 , 47.32656 , 88.72284 , ..., 88.72284 , 64.32656 ,
          15.32656 ],
         [25.326563, 88.72284 , 88.72284 , ..., 88.72284 , 60.14293 ,
          19.326561],
         [49.32656 , 88.72284 , 79.349014, ..., 88.72284 , 50.32656 ,
          19.326561],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ]],

        [[31.32656 , 47.32656 , 88.72284 , ..., 88.72284 , 64.32656 ,
          15.32656 ],
         [25.326563, 88.72284 , 88.72284 , ..., 88.72284 , 60.14293 ,
          19.326561],
         [49.32656 , 88.72284 , 79.349014, ..., 88.72284 , 50.32656 ,
          19.326561],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ]],

        ...,

        [[31.32656 , 47.32656 , 88.72284 , ..., 88.72284 , 64.32656 ,
          15.32656 ],
         [25.326563, 88.72284 , 88.72284 , ..., 88.72284 , 60.14293 ,
          19.326561],
         [49.32656 , 88.72284 , 79.349014, ..., 88.72284 , 50.32656 ,
          19.326561],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ]],

        [[31.32656 , 47.32656 , 88.72284 , ..., 88.72284 , 64.32656 ,
          15.32656 ],
         [25.326563, 88.72284 , 88.72284 , ..., 88.72284 , 60.14293 ,
          19.326561],
         [49.32656 , 88.72284 , 79.349014, ..., 88.72284 , 50.32656 ,
          19.326561],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ]],

        [[31.32656 , 47.32656 , 88.72284 , ..., 88.72284 , 64.32656 ,
          15.32656 ],
         [25.326563, 88.72284 , 88.72284 , ..., 88.72284 , 60.14293 ,
          19.326561],
         [49.32656 , 88.72284 , 79.349014, ..., 88.72284 , 50.32656 ,
          19.326561],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ]]]], dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [7], 'to': [4]}
torch node:
{'name': 'log', 'output': array([[[[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        ...,

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]],

        [[31.326563, 47.32656 ,       inf, ...,       inf, 64.32656 ,
          15.326563],
         [25.326563,       inf,       inf, ...,       inf, 60.142933,
          19.326563],
         [49.32656 ,       inf, 79.349014, ...,       inf, 50.32656 ,
          19.326563],
         ...,
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [7], 'to': [4]}

generate models:352

analyse the exceptions in iter:429
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[  1.,  13.,  26.,  ...,  49.,  52.,  53.],
           [  3.,  13.,  19.,  ...,  40.,  43.,  49.],
           [  3.,  12.,  13.,  ...,  41.,  25.,  38.],
           ...,
           [ 37.,  40.,  45.,  ...,  71.,  55.,  47.],
           [ 36.,  42.,  52.,  ...,  51.,  53.,  56.],
           [ 34.,  36.,  54.,  ...,  30.,  47.,  53.]],

          [[  6.,  21.,  36.,  ..., 114., 108., 107.],
           [  8.,  22.,  30.,  ..., 102., 101., 108.],
           [  8.,  19.,  24.,  ..., 102.,  89., 104.],
           ...,
           [114., 113., 108.,  ..., 129., 104.,  91.],
           [114., 117., 118.,  ..., 119., 113., 107.],
           [105., 107., 118.,  ...,  94., 111., 106.]],

          [[  4.,  18.,  33.,  ..., 135., 140., 152.],
           [  6.,  19.,  26.,  ..., 110., 118., 136.],
           [  6.,  16.,  20.,  ...,  97.,  94., 117.],
           ...,
           [118., 121., 122.,  ..., 118.,  92.,  83.],
           [118., 123., 126.,  ...,  96.,  93.,  93.],
           [111., 113., 121.,  ...,  68.,  92.,  96.]]]]])}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.00000000e+000, 1.30000000e+001, 2.60000000e+001 ... 4.90000000e+001, 5.20000000e+001, 5.30000000e+001],
    [3.00000000e+000, 1.30000000e+001, 1.90000000e+001 ... 4.00000000e+001, 4.30000000e+001, 4.90000000e+001],
    [3.00000000e+000, 1.20000000e+001, 1.30000000e+001 ... 4.10000000e+001, 2.50000000e+001, 3.80000000e+001],
    ...
    [3.70000000e+001, 4.00000000e+001, 4.50000000e+001 ... 7.10000000e+001, 5.50000000e+001, 4.70000000e+001],
    [3.60000000e+001, 4.20000000e+001, 5.20000000e+001 ... 5.10000000e+001, 5.30000000e+001, 5.60000000e+001],
    [3.40000000e+001, 3.60000000e+001, 5.40000000e+001 ... 3.00000000e+001, 4.70000000e+001, 5.30000000e+001]],
   [[6.00000000e+000, 2.10000000e+001, 3.60000000e+001 ... 1.14000000e+002, 1.08000000e+002, 1.07000000e+002],
    [8.00000000e+000, 2.20000000e+001, 3.00000000e+001 ... 1.02000000e+002, 1.01000000e+002, 1.08000000e+002],
    [8.00000000e+000, 1.90000000e+001, 2.40000000e+001 ... 1.02000000e+002, 8.90000000e+001, 1.04000000e+002],
    ...
    [1.14000000e+002, 1.13000000e+002, 1.08000000e+002 ... 1.29000000e+002, 1.04000000e+002, 9.10000000e+001],
    [1.14000000e+002, 1.17000000e+002, 1.18000000e+002 ... 1.19000000e+002, 1.13000000e+002, 1.07000000e+002],
    [1.05000000e+002, 1.07000000e+002, 1.18000000e+002 ... 9.40000000e+001, 1.11000000e+002, 1.06000000e+002]],
   [[4.00000000e+000, 1.80000000e+001, 3.30000000e+001 ... 1.35000000e+002, 1.40000000e+002, 1.52000000e+002],
    [6.00000000e+000, 1.90000000e+001, 2.60000000e+001 ... 1.10000000e+002, 1.18000000e+002, 1.36000000e+002],
    [6.00000000e+000, 1.60000000e+001, 2.00000000e+001 ... 9.70000000e+001, 9.40000000e+001, 1.17000000e+002],
    ...
    [1.18000000e+002, 1.21000000e+002, 1.22000000e+002 ... 1.18000000e+002, 9.20000000e+001, 8.30000000e+001],
    [1.18000000e+002, 1.23000000e+002, 1.26000000e+002 ... 9.60000000e+001, 9.30000000e+001, 9.30000000e+001],
    [1.11000000e+002, 1.13000000e+002, 1.21000000e+002 ... 6.80000000e+001, 9.20000000e+001, 9.60000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:358

analyse the exceptions in iter:437
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],

         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]],

         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.]]]], grad_fn=<PowBackward0>)]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 3, 32, 100] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 100], dtype=Float32, value=
[[[[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],
  [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   ...
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],
   [1.00000000e+000, 1.00000000e+000, 1.00000000e+000 ... 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:365

analyse the exceptions in iter:443
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[232., 229., 226.,  ..., 238., 238., 239.],
           [232., 232., 229.,  ..., 235., 237., 239.],
           [232., 232., 234.,  ..., 232., 236., 239.],
           ...,
           [166., 148., 125.,  ..., 207., 210., 214.],
           [165., 151., 137.,  ..., 206., 210., 213.],
           [170., 157., 145.,  ..., 210., 211., 215.]],

          [[215., 212., 209.,  ..., 227., 227., 228.],
           [215., 215., 212.,  ..., 225., 226., 229.],
           [215., 215., 217.,  ..., 223., 226., 229.],
           ...,
           [135., 121., 100.,  ..., 201., 204., 208.],
           [134., 124., 111.,  ..., 200., 204., 207.],
           [140., 130., 119.,  ..., 204., 205., 209.]],

          [[187., 184., 181.,  ..., 208., 210., 209.],
           [187., 187., 184.,  ..., 201., 205., 203.],
           [187., 187., 189.,  ..., 194., 200., 202.],
           ...,
           [ 92.,  84.,  69.,  ..., 188., 192., 196.],
           [ 91.,  86.,  80.,  ..., 188., 192., 195.],
           [ 96.,  93.,  88.,  ..., 192., 193., 197.]]]]])}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[2.32000000e+002, 2.29000000e+002, 2.26000000e+002 ... 2.38000000e+002, 2.38000000e+002, 2.39000000e+002],
    [2.32000000e+002, 2.32000000e+002, 2.29000000e+002 ... 2.35000000e+002, 2.37000000e+002, 2.39000000e+002],
    [2.32000000e+002, 2.32000000e+002, 2.34000000e+002 ... 2.32000000e+002, 2.36000000e+002, 2.39000000e+002],
    ...
    [1.66000000e+002, 1.48000000e+002, 1.25000000e+002 ... 2.07000000e+002, 2.10000000e+002, 2.14000000e+002],
    [1.65000000e+002, 1.51000000e+002, 1.37000000e+002 ... 2.06000000e+002, 2.10000000e+002, 2.13000000e+002],
    [1.70000000e+002, 1.57000000e+002, 1.45000000e+002 ... 2.10000000e+002, 2.11000000e+002, 2.15000000e+002]],
   [[2.15000000e+002, 2.12000000e+002, 2.09000000e+002 ... 2.27000000e+002, 2.27000000e+002, 2.28000000e+002],
    [2.15000000e+002, 2.15000000e+002, 2.12000000e+002 ... 2.25000000e+002, 2.26000000e+002, 2.29000000e+002],
    [2.15000000e+002, 2.15000000e+002, 2.17000000e+002 ... 2.23000000e+002, 2.26000000e+002, 2.29000000e+002],
    ...
    [1.35000000e+002, 1.21000000e+002, 1.00000000e+002 ... 2.01000000e+002, 2.04000000e+002, 2.08000000e+002],
    [1.34000000e+002, 1.24000000e+002, 1.11000000e+002 ... 2.00000000e+002, 2.04000000e+002, 2.07000000e+002],
    [1.40000000e+002, 1.30000000e+002, 1.19000000e+002 ... 2.04000000e+002, 2.05000000e+002, 2.09000000e+002]],
   [[1.87000000e+002, 1.84000000e+002, 1.81000000e+002 ... 2.08000000e+002, 2.10000000e+002, 2.09000000e+002],
    [1.87000000e+002, 1.87000000e+002, 1.84000000e+002 ... 2.01000000e+002, 2.05000000e+002, 2.03000000e+002],
    [1.87000000e+002, 1.87000000e+002, 1.89000000e+002 ... 1.94000000e+002, 2.00000000e+002, 2.02000000e+002],
    ...
    [9.20000000e+001, 8.40000000e+001, 6.90000000e+001 ... 1.88000000e+002, 1.92000000e+002, 1.96000000e+002],
    [9.10000000e+001, 8.60000000e+001, 8.00000000e+001 ... 1.88000000e+002, 1.92000000e+002, 1.95000000e+002],
    [9.60000000e+001, 9.30000000e+001, 8.80000000e+001 ... 1.92000000e+002, 1.93000000e+002, 1.97000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:369

analyse the exceptions in iter:446
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[ 14.,  14.,  13.,  ...,  13.,  13.,  13.],
          [ 13.,  13.,  12.,  ...,  13.,  13.,  12.],
          [ 13.,  13.,  12.,  ...,  13.,  13.,  12.],
          ...,
          [231., 227., 216.,  ..., 122., 131., 140.],
          [245., 240., 224.,  ..., 142., 143., 144.],
          [213., 237., 227.,  ..., 154., 153., 146.]],

         [[ 14.,  14.,  13.,  ...,  13.,  13.,  13.],
          [ 13.,  13.,  12.,  ...,  13.,  13.,  12.],
          [ 13.,  13.,  12.,  ...,  13.,  13.,  12.],
          ...,
          [197., 186., 173.,  ...,  82.,  84.,  93.],
          [204., 195., 178.,  ...,  93.,  92.,  89.],
          [183., 200., 188.,  ...,  97., 100.,  98.]],

         [[ 14.,  14.,  13.,  ...,  13.,  13.,  13.],
          [ 13.,  13.,  12.,  ...,  13.,  13.,  12.],
          [ 13.,  13.,  12.,  ...,  13.,  13.,  12.],
          ...,
          [159., 149., 139.,  ...,  70.,  76.,  85.],
          [165., 155., 142.,  ...,  77.,  79.,  81.],
          [156., 170., 156.,  ...,  77.,  80.,  80.]]]])]}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[1.40000000e+001, 1.40000000e+001, 1.30000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.30000000e+001],
   [1.30000000e+001, 1.30000000e+001, 1.20000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.20000000e+001],
   [1.30000000e+001, 1.30000000e+001, 1.20000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.20000000e+001],
   ...
   [2.31000000e+002, 2.27000000e+002, 2.16000000e+002 ... 1.22000000e+002, 1.31000000e+002, 1.40000000e+002],
   [2.45000000e+002, 2.40000000e+002, 2.24000000e+002 ... 1.42000000e+002, 1.43000000e+002, 1.44000000e+002],
   [2.13000000e+002, 2.37000000e+002, 2.27000000e+002 ... 1.54000000e+002, 1.53000000e+002, 1.46000000e+002]],
  [[1.40000000e+001, 1.40000000e+001, 1.30000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.30000000e+001],
   [1.30000000e+001, 1.30000000e+001, 1.20000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.20000000e+001],
   [1.30000000e+001, 1.30000000e+001, 1.20000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.20000000e+001],
   ...
   [1.97000000e+002, 1.86000000e+002, 1.73000000e+002 ... 8.20000000e+001, 8.40000000e+001, 9.30000000e+001],
   [2.04000000e+002, 1.95000000e+002, 1.78000000e+002 ... 9.30000000e+001, 9.20000000e+001, 8.90000000e+001],
   [1.83000000e+002, 2.00000000e+002, 1.88000000e+002 ... 9.70000000e+001, 1.00000000e+002, 9.80000000e+001]],
  [[1.40000000e+001, 1.40000000e+001, 1.30000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.30000000e+001],
   [1.30000000e+001, 1.30000000e+001, 1.20000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.20000000e+001],
   [1.30000000e+001, 1.30000000e+001, 1.20000000e+001 ... 1.30000000e+001, 1.30000000e+001, 1.20000000e+001],
   ...
   [1.59000000e+002, 1.49000000e+002, 1.39000000e+002 ... 7.00000000e+001, 7.60000000e+001, 8.50000000e+001],
   [1.65000000e+002, 1.55000000e+002, 1.42000000e+002 ... 7.70000000e+001, 7.90000000e+001, 8.10000000e+001],
   [1.56000000e+002, 1.70000000e+002, 1.56000000e+002 ... 7.70000000e+001, 8.00000000e+001, 8.00000000e+001]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:372

analyse output arrays in iter:449

pre layer res:
14:cos
{'name': 'cos', 'output': array([[[[-0.5549378 , -0.5549378 , -0.5549378 , ..., -0.5549378 ,
          -0.5549378 , -0.5549378 ],
         [ 0.24075425,  0.24075425,  0.24075425, ...,  0.24075425,
           0.24075425,  0.24075425],
         [-0.6994017 , -0.6994017 , -0.6994017 , ..., -0.6994017 ,
          -0.6994017 , -0.6994017 ],
         ...,
         [-0.22350591, -0.22350591, -0.22350591, ..., -0.22350591,
          -0.22350591, -0.22350591],
         [ 0.8533459 ,  0.8533459 ,  0.8533459 , ...,  0.8533459 ,
           0.8533459 ,  0.8533459 ],
         [-0.6534611 , -0.6534611 , -0.6534611 , ..., -0.6534611 ,
          -0.6534611 , -0.6534611 ]],

        [[ 0.24116383,  0.24116383,  0.24116383, ...,  0.24116383,
           0.24116383,  0.24116383],
         [-0.00463671, -0.00463671, -0.00463671, ..., -0.00463671,
          -0.00463671, -0.00463671],
         [ 0.65380335,  0.65380335,  0.65380335, ...,  0.65380335,
           0.65380335,  0.65380335],
         ...,
         [-0.6927219 , -0.6927219 , -0.6927219 , ..., -0.6927219 ,
          -0.6927219 , -0.6927219 ],
         [-0.7178172 , -0.7178172 , -0.7178172 , ..., -0.7178172 ,
          -0.7178172 , -0.7178172 ],
         [ 0.92522764,  0.92522764,  0.92522764, ...,  0.92522764,
           0.92522764,  0.92522764]],

        [[ 0.24087128,  0.24087128,  0.24087128, ...,  0.24087128,
           0.24087128,  0.24087128],
         [ 0.98591673,  0.98591673,  0.98591673, ...,  0.98591673,
           0.98591673,  0.98591673],
         [ 0.9887227 ,  0.9887227 ,  0.9887227 , ...,  0.9887227 ,
           0.9887227 ,  0.9887227 ],
         ...,
         [ 0.89994574,  0.89994574,  0.89994574, ...,  0.89994574,
           0.89994574,  0.89994574],
         [-0.9811405 , -0.9811405 , -0.9811405 , ..., -0.9811405 ,
          -0.9811405 , -0.9811405 ],
         [ 0.3426364 ,  0.3426364 ,  0.3426364 , ...,  0.3426364 ,
           0.3426364 ,  0.3426364 ]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 100]), 'from': [2], 'to': [11]}
tf node:
{'name': 'log', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-1.4239786 , -1.4239786 , -1.4239786 , ..., -1.4239786 ,
          -1.4239786 , -1.4239786 ],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.15859033, -0.15859033, -0.15859033, ..., -0.15859033,
          -0.15859033, -0.15859033],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[-1.4222788 , -1.4222788 , -1.4222788 , ..., -1.4222788 ,
          -1.4222788 , -1.4222788 ],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.42494866, -0.42494866, -0.42494866, ..., -0.42494866,
          -0.42494866, -0.42494866],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.07771547, -0.07771547, -0.07771547, ..., -0.07771547,
          -0.07771547, -0.07771547]],

        [[-1.4234926 , -1.4234926 , -1.4234926 , ..., -1.4234926 ,
          -1.4234926 , -1.4234926 ],
         [-0.01418338, -0.01418338, -0.01418338, ..., -0.01418338,
          -0.01418338, -0.01418338],
         [-0.01134139, -0.01134139, -0.01134139, ..., -0.01134139,
          -0.01134139, -0.01134139],
         ...,
         [-0.10542081, -0.10542081, -0.10542081, ..., -0.10542081,
          -0.10542081, -0.10542081],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-1.0710855 , -1.0710855 , -1.0710855 , ..., -1.0710855 ,
          -1.0710855 , -1.0710855 ]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 100]), 'from': [14], 'to': [3]}
ms node:
{'name': 'log', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-1.4239786 , -1.4239786 , -1.4239786 , ..., -1.4239786 ,
          -1.4239786 , -1.4239786 ],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.15859362, -0.15859362, -0.15859362, ..., -0.15859362,
          -0.15859362, -0.15859362],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[-1.4222788 , -1.4222788 , -1.4222788 , ..., -1.4222788 ,
          -1.4222788 , -1.4222788 ],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.42494595, -0.42494595, -0.42494595, ..., -0.42494595,
          -0.42494595, -0.42494595],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.07771545, -0.07771545, -0.07771545, ..., -0.07771545,
          -0.07771545, -0.07771545]],

        [[-1.4234926 , -1.4234926 , -1.4234926 , ..., -1.4234926 ,
          -1.4234926 , -1.4234926 ],
         [-0.01418481, -0.01418481, -0.01418481, ..., -0.01418481,
          -0.01418481, -0.01418481],
         [-0.01134282, -0.01134282, -0.01134282, ..., -0.01134282,
          -0.01134282, -0.01134282],
         ...,
         [-0.10542186, -0.10542186, -0.10542186, ..., -0.10542186,
          -0.10542186, -0.10542186],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-1.0710875 , -1.0710875 , -1.0710875 , ..., -1.0710875 ,
          -1.0710875 , -1.0710875 ]]]], dtype=float32), 'output_shape': (1, 3, 32, 100), 'from': [14], 'to': [3]}
torch node:
{'name': 'log', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-1.4239786 , -1.4239786 , -1.4239786 , ..., -1.4239786 ,
          -1.4239786 , -1.4239786 ],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.15859033, -0.15859033, -0.15859033, ..., -0.15859033,
          -0.15859033, -0.15859033],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[-1.4222788 , -1.4222788 , -1.4222788 , ..., -1.4222788 ,
          -1.4222788 , -1.4222788 ],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.42494875, -0.42494875, -0.42494875, ..., -0.42494875,
          -0.42494875, -0.42494875],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.07771547, -0.07771547, -0.07771547, ..., -0.07771547,
          -0.07771547, -0.07771547]],

        [[-1.4234926 , -1.4234926 , -1.4234926 , ..., -1.4234926 ,
          -1.4234926 , -1.4234926 ],
         [-0.01418338, -0.01418338, -0.01418338, ..., -0.01418338,
          -0.01418338, -0.01418338],
         [-0.01134139, -0.01134139, -0.01134139, ..., -0.01134139,
          -0.01134139, -0.01134139],
         ...,
         [-0.10542088, -0.10542088, -0.10542088, ..., -0.10542088,
          -0.10542088, -0.10542088],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-1.0710855 , -1.0710855 , -1.0710855 , ..., -1.0710855 ,
          -1.0710855 , -1.0710855 ]]]], dtype=float32), 'output_shape': torch.Size([1, 3, 32, 100]), 'from': [14], 'to': [3]}

generate models:375

analyse the exceptions in iter:456
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 94.,  88.,  97.,  ..., 143., 137., 127.],
           [ 94.,  92., 107.,  ..., 147., 153., 133.],
           [ 84.,  86., 105.,  ..., 142., 149., 133.],
           ...,
           [ 98., 102., 105.,  ..., 107., 106., 106.],
           [101., 103., 105.,  ..., 110., 110., 108.],
           [100., 101., 101.,  ..., 109., 109., 108.]],

          [[118., 112., 120.,  ..., 157., 152., 144.],
           [121., 118., 130.,  ..., 162., 165., 151.],
           [115., 112., 127.,  ..., 159., 161., 151.],
           ...,
           [146., 149., 153.,  ..., 153., 152., 151.],
           [151., 152., 155.,  ..., 156., 156., 155.],
           [151., 152., 153.,  ..., 155., 155., 155.]],

          [[150., 138., 140.,  ..., 176., 174., 168.],
           [149., 141., 149.,  ..., 185., 191., 180.],
           [137., 133., 147.,  ..., 184., 190., 185.],
           ...,
           [154., 157., 161.,  ..., 166., 165., 165.],
           [158., 159., 162.,  ..., 169., 169., 169.],
           [158., 158., 159.,  ..., 168., 167., 168.]]]]])}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[9.40000000e+001, 8.80000000e+001, 9.70000000e+001 ... 1.43000000e+002, 1.37000000e+002, 1.27000000e+002],
    [9.40000000e+001, 9.20000000e+001, 1.07000000e+002 ... 1.47000000e+002, 1.53000000e+002, 1.33000000e+002],
    [8.40000000e+001, 8.60000000e+001, 1.05000000e+002 ... 1.42000000e+002, 1.49000000e+002, 1.33000000e+002],
    ...
    [9.80000000e+001, 1.02000000e+002, 1.05000000e+002 ... 1.07000000e+002, 1.06000000e+002, 1.06000000e+002],
    [1.01000000e+002, 1.03000000e+002, 1.05000000e+002 ... 1.10000000e+002, 1.10000000e+002, 1.08000000e+002],
    [1.00000000e+002, 1.01000000e+002, 1.01000000e+002 ... 1.09000000e+002, 1.09000000e+002, 1.08000000e+002]],
   [[1.18000000e+002, 1.12000000e+002, 1.20000000e+002 ... 1.57000000e+002, 1.52000000e+002, 1.44000000e+002],
    [1.21000000e+002, 1.18000000e+002, 1.30000000e+002 ... 1.62000000e+002, 1.65000000e+002, 1.51000000e+002],
    [1.15000000e+002, 1.12000000e+002, 1.27000000e+002 ... 1.59000000e+002, 1.61000000e+002, 1.51000000e+002],
    ...
    [1.46000000e+002, 1.49000000e+002, 1.53000000e+002 ... 1.53000000e+002, 1.52000000e+002, 1.51000000e+002],
    [1.51000000e+002, 1.52000000e+002, 1.55000000e+002 ... 1.56000000e+002, 1.56000000e+002, 1.55000000e+002],
    [1.51000000e+002, 1.52000000e+002, 1.53000000e+002 ... 1.55000000e+002, 1.55000000e+002, 1.55000000e+002]],
   [[1.50000000e+002, 1.38000000e+002, 1.40000000e+002 ... 1.76000000e+002, 1.74000000e+002, 1.68000000e+002],
    [1.49000000e+002, 1.41000000e+002, 1.49000000e+002 ... 1.85000000e+002, 1.91000000e+002, 1.80000000e+002],
    [1.37000000e+002, 1.33000000e+002, 1.47000000e+002 ... 1.84000000e+002, 1.90000000e+002, 1.85000000e+002],
    ...
    [1.54000000e+002, 1.57000000e+002, 1.61000000e+002 ... 1.66000000e+002, 1.65000000e+002, 1.65000000e+002],
    [1.58000000e+002, 1.59000000e+002, 1.62000000e+002 ... 1.69000000e+002, 1.69000000e+002, 1.69000000e+002],
    [1.58000000e+002, 1.58000000e+002, 1.59000000e+002 ... 1.68000000e+002, 1.67000000e+002, 1.68000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:381

analyse output arrays in iter:458

pre layer res:
16:sum
{'name': 'sum', 'output': array([[[4.5622480e+11, 4.5074560e+11, 4.4877388e+11, ...,
         4.4368698e+11, 4.4445798e+11, 4.4055010e+11],
        [4.5622480e+11, 4.5074560e+11, 4.4877388e+11, ...,
         4.4368698e+11, 4.4445798e+11, 4.4055010e+11],
        [4.5622480e+11, 4.5074560e+11, 4.4877388e+11, ...,
         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
        ...,
        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32), 'output_shape': TensorShape([1, 128, 16]), 'from': [12], 'to': [22]}
tf node:
{'name': 'cos', 'output': array([[[-0.5481165 ,  0.98553276,  0.87823915, ..., -0.62339824,
         -0.97048205, -0.7630276 ],
        [-0.5481165 ,  0.98553276,  0.87823915, ..., -0.62339824,
         -0.97048205, -0.7630276 ],
        [-0.5481165 ,  0.98553276,  0.87823915, ...,  1.        ,
          1.        ,  1.        ],
        ...,
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ]]], dtype=float32), 'output_shape': TensorShape([1, 128, 16]), 'from': [16], 'to': [17]}
ms node:
{'name': 'cos', 'output': array([[[ 0.5716475 ,  0.52480006, -0.11619246, ..., -0.9579838 ,
         -0.13815516,  0.31517282],
        [ 0.5716475 ,  0.52480006, -0.11619246, ..., -0.9579838 ,
         -0.13815516,  0.31517282],
        [ 0.5716475 ,  0.52480006, -0.11619246, ...,  1.        ,
          1.        ,  1.        ],
        ...,
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ]]], dtype=float32), 'output_shape': (1, 128, 16), 'from': [16], 'to': [17]}
torch node:
{'name': 'cos', 'output': array([[[ 0.97449446,  0.98553276, -0.11619246, ..., -0.62339824,
         -0.13815516,  0.31517282],
        [ 0.97449446,  0.98553276, -0.11619246, ..., -0.62339824,
         -0.13815516,  0.31517282],
        [ 0.97449446,  0.98553276, -0.11619246, ...,  1.        ,
          1.        ,  1.        ],
        ...,
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 1.        ,  1.        ,  1.        , ...,  1.        ,
          1.        ,  1.        ]]], dtype=float32), 'output_shape': torch.Size([1, 128, 16]), 'from': [16], 'to': [17]}

generate models:383

analyse the exceptions in iter:469
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 18.,  20.,  24.,  ...,  69.,  68.,  71.],
           [100.,  71.,  57.,  ...,  43.,  45.,  54.],
           [192., 173., 103.,  ...,  37.,  37.,  43.],
           ...,
           [105., 126., 150.,  ..., 104., 107., 106.],
           [ 96., 130., 141.,  ..., 100.,  98.,  93.],
           [ 93., 110., 101.,  ...,  92.,  92.,  95.]],

          [[ 39.,  37.,  39.,  ...,  90.,  91.,  93.],
           [104.,  81.,  72.,  ...,  64.,  69.,  75.],
           [177., 170., 111.,  ...,  55.,  57.,  61.],
           ...,
           [127., 139., 154.,  ..., 132., 136., 140.],
           [116., 138., 146.,  ..., 133., 131., 129.],
           [118., 122., 112.,  ..., 127., 127., 127.]],

          [[ 13.,  13.,  17.,  ...,  43.,  36.,  32.],
           [ 87.,  56.,  38.,  ...,  31.,  29.,  29.],
           [155., 140.,  73.,  ...,  28.,  24.,  27.],
           ...,
           [ 54.,  83., 120.,  ...,  50.,  53.,  52.],
           [ 48.,  84., 107.,  ...,  46.,  43.,  38.],
           [ 47.,  61.,  63.,  ...,  37.,  37.,  40.]]]]])}
Given groups=1, weight of size [512, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.80000000e+001, 2.00000000e+001, 2.40000000e+001 ... 6.90000000e+001, 6.80000000e+001, 7.10000000e+001],
    [1.00000000e+002, 7.10000000e+001, 5.70000000e+001 ... 4.30000000e+001, 4.50000000e+001, 5.40000000e+001],
    [1.92000000e+002, 1.73000000e+002, 1.03000000e+002 ... 3.70000000e+001, 3.70000000e+001, 4.30000000e+001],
    ...
    [1.05000000e+002, 1.26000000e+002, 1.50000000e+002 ... 1.04000000e+002, 1.07000000e+002, 1.06000000e+002],
    [9.60000000e+001, 1.30000000e+002, 1.41000000e+002 ... 1.00000000e+002, 9.80000000e+001, 9.30000000e+001],
    [9.30000000e+001, 1.10000000e+002, 1.01000000e+002 ... 9.20000000e+001, 9.20000000e+001, 9.50000000e+001]],
   [[3.90000000e+001, 3.70000000e+001, 3.90000000e+001 ... 9.00000000e+001, 9.10000000e+001, 9.30000000e+001],
    [1.04000000e+002, 8.10000000e+001, 7.20000000e+001 ... 6.40000000e+001, 6.90000000e+001, 7.50000000e+001],
    [1.77000000e+002, 1.70000000e+002, 1.11000000e+002 ... 5.50000000e+001, 5.70000000e+001, 6.10000000e+001],
    ...
    [1.27000000e+002, 1.39000000e+002, 1.54000000e+002 ... 1.32000000e+002, 1.36000000e+002, 1.40000000e+002],
    [1.16000000e+002, 1.38000000e+002, 1.46000000e+002 ... 1.33000000e+002, 1.31000000e+002, 1.29000000e+002],
    [1.18000000e+002, 1.22000000e+002, 1.12000000e+002 ... 1.27000000e+002, 1.27000000e+002, 1.27000000e+002]],
   [[1.30000000e+001, 1.30000000e+001, 1.70000000e+001 ... 4.30000000e+001, 3.60000000e+001, 3.20000000e+001],
    [8.70000000e+001, 5.60000000e+001, 3.80000000e+001 ... 3.10000000e+001, 2.90000000e+001, 2.90000000e+001],
    [1.55000000e+002, 1.40000000e+002, 7.30000000e+001 ... 2.80000000e+001, 2.40000000e+001, 2.70000000e+001],
    ...
    [5.40000000e+001, 8.30000000e+001, 1.20000000e+002 ... 5.00000000e+001, 5.30000000e+001, 5.20000000e+001],
    [4.80000000e+001, 8.40000000e+001, 1.07000000e+002 ... 4.60000000e+001, 4.30000000e+001, 3.80000000e+001],
    [4.70000000e+001, 6.10000000e+001, 6.30000000e+001 ... 3.70000000e+001, 3.70000000e+001, 4.00000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:393

analyse output arrays in iter:486

pre layer res:
16:add
{'name': 'add', 'output': array([[[[          inf,           inf, 8.1879937e+35, ...,
                    inf,           inf,           inf],
         [          inf,           inf, 4.4704931e+37, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
          8.6224636e+15, 4.1833192e+24, 5.5170271e+33],
         [          inf,           inf,           inf, ...,
          1.4033471e+21, 1.6876714e+27, 2.0296007e+33],
         [          inf,           inf,           inf, ...,
          8.4024209e+25, 2.5047266e+29, 7.4664845e+32]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
          3.8146933e+21, 1.3675342e+31,           inf],
         [          inf,           inf,           inf, ...,
          4.5875665e+27, 5.5170271e+33,           inf],
         [          inf,           inf,           inf, ...,
          1.4996834e+34, 8.1879937e+35,           inf]],

        [[          inf,           inf, 1.2152061e+38, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
          3.8146933e+21, 2.5047266e+29, 1.2152061e+38],
         [          inf,           inf,           inf, ...,
          1.2470298e+28, 2.0296007e+33, 3.3032725e+38],
         [          inf,           inf,           inf, ...,
          1.4996834e+34, 2.2257275e+36,           inf]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [15, 3], 'to': [9]}
tf node:
{'name': 'log', 'output': array([[[[      inf,       inf, 82.693146, ...,       inf,       inf,
                inf],
         [      inf,       inf, 86.693146, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         ...,
         [      inf,       inf,       inf, ..., 36.693146, 56.693146,
          77.693146],
         [      inf,       inf,       inf, ..., 48.693146, 62.693146,
          76.693146],
         [      inf,       inf,       inf, ..., 59.693146, 67.693146,
          75.693146]],

        [[      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         ...,
         [      inf,       inf,       inf, ..., 49.693146, 71.693146,
                inf],
         [      inf,       inf,       inf, ..., 63.693146, 77.693146,
                inf],
         [      inf,       inf,       inf, ..., 78.693146, 82.693146,
                inf]],

        [[      inf,       inf, 87.693146, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         ...,
         [      inf,       inf,       inf, ..., 49.693146, 67.693146,
          87.693146],
         [      inf,       inf,       inf, ..., 64.693146, 76.693146,
          88.693146],
         [      inf,       inf,       inf, ..., 78.693146, 83.693146,
                inf]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [16], 'to': [5]}
ms node:
{'name': 'log', 'output': array([[[[88.72284 , 88.72284 , 82.693146, ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 86.693146, ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 36.69315 , 56.693146,
          77.693146],
         [88.72284 , 88.72284 , 88.72284 , ..., 48.693146, 62.693146,
          76.693146],
         [88.72284 , 88.72284 , 88.72284 , ..., 59.693146, 67.693146,
          75.693146]],

        [[88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 49.693146, 71.693146,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 63.693146, 77.693146,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 78.693146, 82.693146,
          88.72284 ]],

        [[88.72284 , 88.72284 , 87.693146, ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         [88.72284 , 88.72284 , 88.72284 , ..., 88.72284 , 88.72284 ,
          88.72284 ],
         ...,
         [88.72284 , 88.72284 , 88.72284 , ..., 49.693146, 67.693146,
          87.693146],
         [88.72284 , 88.72284 , 88.72284 , ..., 64.693146, 76.693146,
          88.693146],
         [88.72284 , 88.72284 , 88.72284 , ..., 78.693146, 83.693146,
          88.72284 ]]]], dtype=float32), 'output_shape': (1, 3, 32, 32), 'from': [16], 'to': [5]}
torch node:
{'name': 'log', 'output': array([[[[      inf,       inf, 82.693146, ...,       inf,       inf,
                inf],
         [      inf,       inf, 86.693146, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         ...,
         [      inf,       inf,       inf, ..., 36.693146, 56.693146,
          77.693146],
         [      inf,       inf,       inf, ..., 48.693146, 62.693146,
          76.693146],
         [      inf,       inf,       inf, ..., 59.693146, 67.693146,
          75.693146]],

        [[      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         ...,
         [      inf,       inf,       inf, ..., 49.693146, 71.693146,
                inf],
         [      inf,       inf,       inf, ..., 63.693146, 77.693146,
                inf],
         [      inf,       inf,       inf, ..., 78.693146, 82.693146,
                inf]],

        [[      inf,       inf, 87.693146, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         [      inf,       inf,       inf, ...,       inf,       inf,
                inf],
         ...,
         [      inf,       inf,       inf, ..., 49.693146, 67.693146,
          87.693146],
         [      inf,       inf,       inf, ..., 64.693146, 76.693146,
          88.693146],
         [      inf,       inf,       inf, ..., 78.693146, 83.693146,
                inf]]]], dtype=float32), 'output_shape': torch.Size([1, 3, 32, 32]), 'from': [16], 'to': [5]}

generate models:408

analyse the exceptions in iter:487
torch exception:
{'id': 3, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[277504., 277504., 255488.,  ...,  87040.,  81920.,  87552.],
          [264192., 250368., 248832.,  ...,  97280.,  94720., 100864.],
          [276480., 254976., 235008.,  ..., 105984.,  95232., 116224.],
          ...,
          [ 59904.,  63488.,  59904.,  ..., 193024., 215040., 233472.],
          [ 49152.,  44544.,  50688.,  ..., 180224., 204800., 227328.],
          [ 42496.,  35840.,  43520.,  ..., 154112., 182784., 200192.]],

         [[277504., 277504., 255488.,  ...,  87040.,  81920.,  87552.],
          [264192., 250368., 248832.,  ...,  97280.,  94720., 100864.],
          [276480., 254976., 235008.,  ..., 105984.,  95232., 116224.],
          ...,
          [ 59904.,  63488.,  59904.,  ..., 193024., 215040., 233472.],
          [ 49152.,  44544.,  50688.,  ..., 180224., 204800., 227328.],
          [ 42496.,  35840.,  43520.,  ..., 154112., 182784., 200192.]],

         [[277504., 277504., 255488.,  ...,  87040.,  81920.,  87552.],
          [264192., 250368., 248832.,  ...,  97280.,  94720., 100864.],
          [276480., 254976., 235008.,  ..., 105984.,  95232., 116224.],
          ...,
          [ 59904.,  63488.,  59904.,  ..., 193024., 215040., 233472.],
          [ 49152.,  44544.,  50688.,  ..., 180224., 204800., 227328.],
          [ 42496.,  35840.,  43520.,  ..., 154112., 182784., 200192.]],

         ...,

         [[277504., 277504., 255488.,  ...,  87040.,  81920.,  87552.],
          [264192., 250368., 248832.,  ...,  97280.,  94720., 100864.],
          [276480., 254976., 235008.,  ..., 105984.,  95232., 116224.],
          ...,
          [ 59904.,  63488.,  59904.,  ..., 193024., 215040., 233472.],
          [ 49152.,  44544.,  50688.,  ..., 180224., 204800., 227328.],
          [ 42496.,  35840.,  43520.,  ..., 154112., 182784., 200192.]],

         [[277504., 277504., 255488.,  ...,  87040.,  81920.,  87552.],
          [264192., 250368., 248832.,  ...,  97280.,  94720., 100864.],
          [276480., 254976., 235008.,  ..., 105984.,  95232., 116224.],
          ...,
          [ 59904.,  63488.,  59904.,  ..., 193024., 215040., 233472.],
          [ 49152.,  44544.,  50688.,  ..., 180224., 204800., 227328.],
          [ 42496.,  35840.,  43520.,  ..., 154112., 182784., 200192.]],

         [[277504., 277504., 255488.,  ...,  87040.,  81920.,  87552.],
          [264192., 250368., 248832.,  ...,  97280.,  94720., 100864.],
          [276480., 254976., 235008.,  ..., 105984.,  95232., 116224.],
          ...,
          [ 59904.,  63488.,  59904.,  ..., 193024., 215040., 233472.],
          [ 49152.,  44544.,  50688.,  ..., 180224., 204800., 227328.],
          [ 42496.,  35840.,  43520.,  ..., 154112., 182784., 200192.]]]],
       grad_fn=<ReluBackward0>)]}
Given groups=1, weight of size [128, 128, 1, 1], expected input[1, 512, 32, 32] to have 128 channels, but got 512 channels instead
mindspore exception:
{'id': 3, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 512, 32, 32], dtype=Float32, value=
[[[[2.77504000e+005, 2.77504000e+005, 2.55488000e+005 ... 8.70400000e+004, 8.19200000e+004, 8.75520000e+004],
   [2.64192000e+005, 2.50368000e+005, 2.48832000e+005 ... 9.72800000e+004, 9.47200000e+004, 1.00864000e+005],
   [2.76480000e+005, 2.54976000e+005, 2.35008000e+005 ... 1.05984000e+005, 9.52320000e+004, 1.16224000e+005],
   ...
   [5.99040000e+004, 6.34880000e+004, 5.99040000e+004 ... 1.93024000e+005, 2.15040000e+005, 2.33472000e+005],
   [4.91520000e+004, 4.45440000e+004, 5.06880000e+004 ... 1.80224000e+005, 2.04800000e+005, 2.27328000e+005],
   [4.24960000e+004, 3.58400000e+004, 4.35200000e+004 ... 1.54112000e+005, 1.82784000e+005, 2.00192000e+005]],
  [[2.77504000e+005, 2.77504000e+005, 2.55488000e+005 ... 8.70400000e+004, 8.19200000e+004, 8.75520000e+004],
   [2.64192000e+005, 2.50368000e+005, 2.48832000e+005 ... 9.72800000e+004, 9.47200000e+004, 1.00864000e+005],
   [2.76480000e+005, 2.54976000e+005, 2.35008000e+005 ... 1.05984000e+005, 9.52320000e+004, 1.16224000e+005],
   ...
   [5.99040000e+004, 6.34880000e+004, 5.99040000e+004 ... 1.93024000e+005, 2.15040000e+005, 2.33472000e+005],
   [4.91520000e+004, 4.45440000e+004, 5.06880000e+004 ... 1.80224000e+005, 2.04800000e+005, 2.27328000e+005],
   [4.24960000e+004, 3.58400000e+004, 4.35200000e+004 ... 1.54112000e+005, 1.82784000e+005, 2.00192000e+005]],
  [[2.77504000e+005, 2.77504000e+005, 2.55488000e+005 ... 8.70400000e+004, 8.19200000e+004, 8.75520000e+004],
   [2.64192000e+005, 2.50368000e+005, 2.48832000e+005 ... 9.72800000e+004, 9.47200000e+004, 1.00864000e+005],
   [2.76480000e+005, 2.54976000e+005, 2.35008000e+005 ... 1.05984000e+005, 9.52320000e+004, 1.16224000e+005],
   ...
   [5.99040000e+004, 6.34880000e+004, 5.99040000e+004 ... 1.93024000e+005, 2.15040000e+005, 2.33472000e+005],
   [4.91520000e+004, 4.45440000e+004, 5.06880000e+004 ... 1.80224000e+005, 2.04800000e+005, 2.27328000e+005],
   [4.24960000e+004, 3.58400000e+004, 4.35200000e+004 ... 1.54112000e+005, 1.82784000e+005, 2.00192000e+005]],
  ...
  [[2.77504000e+005, 2.77504000e+005, 2.55488000e+005 ... 8.70400000e+004, 8.19200000e+004, 8.75520000e+004],
   [2.64192000e+005, 2.50368000e+005, 2.48832000e+005 ... 9.72800000e+004, 9.47200000e+004, 1.00864000e+005],
   [2.76480000e+005, 2.54976000e+005, 2.35008000e+005 ... 1.05984000e+005, 9.52320000e+004, 1.16224000e+005],
   ...
   [5.99040000e+004, 6.34880000e+004, 5.99040000e+004 ... 1.93024000e+005, 2.15040000e+005, 2.33472000e+005],
   [4.91520000e+004, 4.45440000e+004, 5.06880000e+004 ... 1.80224000e+005, 2.04800000e+005, 2.27328000e+005],
   [4.24960000e+004, 3.58400000e+004, 4.35200000e+004 ... 1.54112000e+005, 1.82784000e+005, 2.00192000e+005]],
  [[2.77504000e+005, 2.77504000e+005, 2.55488000e+005 ... 8.70400000e+004, 8.19200000e+004, 8.75520000e+004],
   [2.64192000e+005, 2.50368000e+005, 2.48832000e+005 ... 9.72800000e+004, 9.47200000e+004, 1.00864000e+005],
   [2.76480000e+005, 2.54976000e+005, 2.35008000e+005 ... 1.05984000e+005, 9.52320000e+004, 1.16224000e+005],
   ...
   [5.99040000e+004, 6.34880000e+004, 5.99040000e+004 ... 1.93024000e+005, 2.15040000e+005, 2.33472000e+005],
   [4.91520000e+004, 4.45440000e+004, 5.06880000e+004 ... 1.80224000e+005, 2.04800000e+005, 2.27328000e+005],
   [4.24960000e+004, 3.58400000e+004, 4.35200000e+004 ... 1.54112000e+005, 1.82784000e+005, 2.00192000e+005]],
  [[2.77504000e+005, 2.77504000e+005, 2.55488000e+005 ... 8.70400000e+004, 8.19200000e+004, 8.75520000e+004],
   [2.64192000e+005, 2.50368000e+005, 2.48832000e+005 ... 9.72800000e+004, 9.47200000e+004, 1.00864000e+005],
   [2.76480000e+005, 2.54976000e+005, 2.35008000e+005 ... 1.05984000e+005, 9.52320000e+004, 1.16224000e+005],
   ...
   [5.99040000e+004, 6.34880000e+004, 5.99040000e+004 ... 1.93024000e+005, 2.15040000e+005, 2.33472000e+005],
   [4.91520000e+004, 4.45440000e+004, 5.06880000e+004 ... 1.80224000e+005, 2.04800000e+005, 2.27328000e+005],
   [4.24960000e+004, 3.58400000e+004, 4.35200000e+004 ... 1.54112000e+005, 1.82784000e+005, 2.00192000e+005]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 512, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:409

analyse the exceptions in iter:488
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[142., 167., 174.,  ..., 128., 129., 138.],
           [176., 186., 190.,  ..., 121., 124., 125.],
           [191., 187., 187.,  ..., 129., 127., 121.],
           ...,
           [232., 208., 225.,  ..., 232., 220., 201.],
           [231., 214., 226.,  ..., 228., 229., 201.],
           [216., 231., 230.,  ..., 237., 242., 220.]],

          [[142., 161., 170.,  ..., 124., 125., 134.],
           [176., 181., 186.,  ..., 121., 120., 121.],
           [192., 183., 184.,  ..., 132., 123., 117.],
           ...,
           [230., 206., 222.,  ..., 231., 221., 198.],
           [229., 212., 224.,  ..., 226., 230., 198.],
           [214., 229., 227.,  ..., 236., 243., 216.]],

          [[126., 142., 151.,  ...,  99., 100., 109.],
           [157., 158., 164.,  ...,  99.,  95.,  96.],
           [168., 156., 158.,  ..., 113.,  98.,  92.],
           ...,
           [191., 168., 186.,  ..., 200., 186., 159.],
           [191., 174., 187.,  ..., 196., 197., 161.],
           [175., 191., 190.,  ..., 206., 213., 183.]]]]])}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.42000000e+002, 1.67000000e+002, 1.74000000e+002 ... 1.28000000e+002, 1.29000000e+002, 1.38000000e+002],
    [1.76000000e+002, 1.86000000e+002, 1.90000000e+002 ... 1.21000000e+002, 1.24000000e+002, 1.25000000e+002],
    [1.91000000e+002, 1.87000000e+002, 1.87000000e+002 ... 1.29000000e+002, 1.27000000e+002, 1.21000000e+002],
    ...
    [2.32000000e+002, 2.08000000e+002, 2.25000000e+002 ... 2.32000000e+002, 2.20000000e+002, 2.01000000e+002],
    [2.31000000e+002, 2.14000000e+002, 2.26000000e+002 ... 2.28000000e+002, 2.29000000e+002, 2.01000000e+002],
    [2.16000000e+002, 2.31000000e+002, 2.30000000e+002 ... 2.37000000e+002, 2.42000000e+002, 2.20000000e+002]],
   [[1.42000000e+002, 1.61000000e+002, 1.70000000e+002 ... 1.24000000e+002, 1.25000000e+002, 1.34000000e+002],
    [1.76000000e+002, 1.81000000e+002, 1.86000000e+002 ... 1.21000000e+002, 1.20000000e+002, 1.21000000e+002],
    [1.92000000e+002, 1.83000000e+002, 1.84000000e+002 ... 1.32000000e+002, 1.23000000e+002, 1.17000000e+002],
    ...
    [2.30000000e+002, 2.06000000e+002, 2.22000000e+002 ... 2.31000000e+002, 2.21000000e+002, 1.98000000e+002],
    [2.29000000e+002, 2.12000000e+002, 2.24000000e+002 ... 2.26000000e+002, 2.30000000e+002, 1.98000000e+002],
    [2.14000000e+002, 2.29000000e+002, 2.27000000e+002 ... 2.36000000e+002, 2.43000000e+002, 2.16000000e+002]],
   [[1.26000000e+002, 1.42000000e+002, 1.51000000e+002 ... 9.90000000e+001, 1.00000000e+002, 1.09000000e+002],
    [1.57000000e+002, 1.58000000e+002, 1.64000000e+002 ... 9.90000000e+001, 9.50000000e+001, 9.60000000e+001],
    [1.68000000e+002, 1.56000000e+002, 1.58000000e+002 ... 1.13000000e+002, 9.80000000e+001, 9.20000000e+001],
    ...
    [1.91000000e+002, 1.68000000e+002, 1.86000000e+002 ... 2.00000000e+002, 1.86000000e+002, 1.59000000e+002],
    [1.91000000e+002, 1.74000000e+002, 1.87000000e+002 ... 1.96000000e+002, 1.97000000e+002, 1.61000000e+002],
    [1.75000000e+002, 1.91000000e+002, 1.90000000e+002 ... 2.06000000e+002, 2.13000000e+002, 1.83000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:410

analyse the exceptions in iter:491
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 74.,  73.,  71.,  ..., 172., 164., 166.],
           [ 84.,  78.,  84.,  ..., 178., 177., 174.],
           [104.,  99.,  98.,  ..., 174., 172., 169.],
           ...,
           [187., 195., 202.,  ..., 178., 175., 172.],
           [196., 197., 198.,  ..., 188., 178., 175.],
           [196., 191., 189.,  ..., 185., 178., 174.]],

          [[ 74.,  73.,  71.,  ..., 172., 164., 166.],
           [ 84.,  78.,  84.,  ..., 178., 177., 174.],
           [104.,  99.,  98.,  ..., 174., 172., 169.],
           ...,
           [187., 195., 202.,  ..., 178., 175., 172.],
           [196., 197., 198.,  ..., 188., 178., 175.],
           [196., 191., 189.,  ..., 185., 178., 174.]],

          [[ 74.,  73.,  71.,  ..., 172., 164., 166.],
           [ 84.,  78.,  84.,  ..., 178., 177., 174.],
           [104.,  99.,  98.,  ..., 174., 172., 169.],
           ...,
           [187., 195., 202.,  ..., 178., 175., 172.],
           [196., 197., 198.,  ..., 188., 178., 175.],
           [196., 191., 189.,  ..., 185., 178., 174.]]]]])}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[7.40000000e+001, 7.30000000e+001, 7.10000000e+001 ... 1.72000000e+002, 1.64000000e+002, 1.66000000e+002],
    [8.40000000e+001, 7.80000000e+001, 8.40000000e+001 ... 1.78000000e+002, 1.77000000e+002, 1.74000000e+002],
    [1.04000000e+002, 9.90000000e+001, 9.80000000e+001 ... 1.74000000e+002, 1.72000000e+002, 1.69000000e+002],
    ...
    [1.87000000e+002, 1.95000000e+002, 2.02000000e+002 ... 1.78000000e+002, 1.75000000e+002, 1.72000000e+002],
    [1.96000000e+002, 1.97000000e+002, 1.98000000e+002 ... 1.88000000e+002, 1.78000000e+002, 1.75000000e+002],
    [1.96000000e+002, 1.91000000e+002, 1.89000000e+002 ... 1.85000000e+002, 1.78000000e+002, 1.74000000e+002]],
   [[7.40000000e+001, 7.30000000e+001, 7.10000000e+001 ... 1.72000000e+002, 1.64000000e+002, 1.66000000e+002],
    [8.40000000e+001, 7.80000000e+001, 8.40000000e+001 ... 1.78000000e+002, 1.77000000e+002, 1.74000000e+002],
    [1.04000000e+002, 9.90000000e+001, 9.80000000e+001 ... 1.74000000e+002, 1.72000000e+002, 1.69000000e+002],
    ...
    [1.87000000e+002, 1.95000000e+002, 2.02000000e+002 ... 1.78000000e+002, 1.75000000e+002, 1.72000000e+002],
    [1.96000000e+002, 1.97000000e+002, 1.98000000e+002 ... 1.88000000e+002, 1.78000000e+002, 1.75000000e+002],
    [1.96000000e+002, 1.91000000e+002, 1.89000000e+002 ... 1.85000000e+002, 1.78000000e+002, 1.74000000e+002]],
   [[7.40000000e+001, 7.30000000e+001, 7.10000000e+001 ... 1.72000000e+002, 1.64000000e+002, 1.66000000e+002],
    [8.40000000e+001, 7.80000000e+001, 8.40000000e+001 ... 1.78000000e+002, 1.77000000e+002, 1.74000000e+002],
    [1.04000000e+002, 9.90000000e+001, 9.80000000e+001 ... 1.74000000e+002, 1.72000000e+002, 1.69000000e+002],
    ...
    [1.87000000e+002, 1.95000000e+002, 2.02000000e+002 ... 1.78000000e+002, 1.75000000e+002, 1.72000000e+002],
    [1.96000000e+002, 1.97000000e+002, 1.98000000e+002 ... 1.88000000e+002, 1.78000000e+002, 1.75000000e+002],
    [1.96000000e+002, 1.91000000e+002, 1.89000000e+002 ... 1.85000000e+002, 1.78000000e+002, 1.74000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:412

final statics:
total operators:28
tensorflow --> nums:20,distinct_bugs:5
mindspore --> nums:76,distinct_bugs:6
torch --> nums:75,distinct_bugs:7
tensorflow --> 
cos:11
conv2d:3
log:3
softmax:2
sin:1
mindspore --> 
conv2d:50
linear:9
log:6
cos:8
softmax:2
sin:1
torch --> 
conv2d:49
linear:9
cos:8
log:3
softmax:2
maxpool2d:3
sin:1

generate models:420
