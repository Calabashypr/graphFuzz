
final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:3

analyse the exceptions in iter:14
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])]}
Given groups=1, weight of size [256, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:7

analyse the exceptions in iter:28
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[128., 121., 138.,  ..., 130., 101., 122.],
           [133., 125., 136.,  ..., 131., 106., 127.],
           [141., 126., 141.,  ..., 132., 114., 126.],
           ...,
           [191., 186., 175.,  ..., 190., 182., 195.],
           [210., 207., 198.,  ..., 194., 184., 192.],
           [209., 206., 207.,  ..., 201., 193., 196.]],

          [[141., 134., 151.,  ..., 150., 121., 141.],
           [146., 138., 149.,  ..., 151., 126., 147.],
           [155., 139., 154.,  ..., 152., 134., 146.],
           ...,
           [178., 174., 160.,  ..., 179., 175., 188.],
           [195., 197., 179.,  ..., 179., 178., 186.],
           [194., 195., 189.,  ..., 187., 187., 190.]],

          [[123., 116., 133.,  ..., 138., 109., 129.],
           [128., 120., 131.,  ..., 139., 114., 135.],
           [136., 121., 136.,  ..., 140., 122., 134.],
           ...,
           [126., 124., 112.,  ..., 138., 137., 145.],
           [143., 144., 129.,  ..., 138., 133., 142.],
           [142., 143., 138.,  ..., 145., 142., 146.]]]]])}
Given groups=1, weight of size [2048, 512, 1, 1], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.28000000e+002, 1.21000000e+002, 1.38000000e+002 ... 1.30000000e+002, 1.01000000e+002, 1.22000000e+002],
    [1.33000000e+002, 1.25000000e+002, 1.36000000e+002 ... 1.31000000e+002, 1.06000000e+002, 1.27000000e+002],
    [1.41000000e+002, 1.26000000e+002, 1.41000000e+002 ... 1.32000000e+002, 1.14000000e+002, 1.26000000e+002],
    ...
    [1.91000000e+002, 1.86000000e+002, 1.75000000e+002 ... 1.90000000e+002, 1.82000000e+002, 1.95000000e+002],
    [2.10000000e+002, 2.07000000e+002, 1.98000000e+002 ... 1.94000000e+002, 1.84000000e+002, 1.92000000e+002],
    [2.09000000e+002, 2.06000000e+002, 2.07000000e+002 ... 2.01000000e+002, 1.93000000e+002, 1.96000000e+002]],
   [[1.41000000e+002, 1.34000000e+002, 1.51000000e+002 ... 1.50000000e+002, 1.21000000e+002, 1.41000000e+002],
    [1.46000000e+002, 1.38000000e+002, 1.49000000e+002 ... 1.51000000e+002, 1.26000000e+002, 1.47000000e+002],
    [1.55000000e+002, 1.39000000e+002, 1.54000000e+002 ... 1.52000000e+002, 1.34000000e+002, 1.46000000e+002],
    ...
    [1.78000000e+002, 1.74000000e+002, 1.60000000e+002 ... 1.79000000e+002, 1.75000000e+002, 1.88000000e+002],
    [1.95000000e+002, 1.97000000e+002, 1.79000000e+002 ... 1.79000000e+002, 1.78000000e+002, 1.86000000e+002],
    [1.94000000e+002, 1.95000000e+002, 1.89000000e+002 ... 1.87000000e+002, 1.87000000e+002, 1.90000000e+002]],
   [[1.23000000e+002, 1.16000000e+002, 1.33000000e+002 ... 1.38000000e+002, 1.09000000e+002, 1.29000000e+002],
    [1.28000000e+002, 1.20000000e+002, 1.31000000e+002 ... 1.39000000e+002, 1.14000000e+002, 1.35000000e+002],
    [1.36000000e+002, 1.21000000e+002, 1.36000000e+002 ... 1.40000000e+002, 1.22000000e+002, 1.34000000e+002],
    ...
    [1.26000000e+002, 1.24000000e+002, 1.12000000e+002 ... 1.38000000e+002, 1.37000000e+002, 1.45000000e+002],
    [1.43000000e+002, 1.44000000e+002, 1.29000000e+002 ... 1.38000000e+002, 1.33000000e+002, 1.42000000e+002],
    [1.42000000e+002, 1.43000000e+002, 1.38000000e+002 ... 1.45000000e+002, 1.42000000e+002, 1.46000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:14

analyse the exceptions in iter:34
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])]}
Given groups=1, weight of size [64, 256, 7, 7], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:15

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:3,distinct_bugs:1
torch --> nums:3,distinct_bugs:1
tensorflow --> 
mindspore --> 
conv2d:3
torch --> 
conv2d:3

generate models:17

analyse output arrays in iter:54

pre layer res:
9:empty_seq_operator
{'name': 'empty_seq_operator', 'output': array([[ 0.525322  , -0.9923355 , -0.64014435, ...,  1.        ,
         1.        ,  1.        ]], dtype=float32), 'output_shape': TensorShape([1, 524288]), 'from': [10], 'to': [16]}
tf node:
{'name': 'log', 'output': array([[-0.6437438,        nan,        nan, ...,  0.       ,  0.       ,
         0.       ]], dtype=float32), 'output_shape': TensorShape([1, 524288]), 'from': [9], 'to': [15]}
ms node:
{'name': 'log', 'output': array([[-6.4374053e-01,            nan,            nan, ...,
        -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]], dtype=float32), 'output_shape': (1, 524288), 'from': [9], 'to': [15]}
torch node:
{'name': 'log', 'output': array([[-0.6437438,        nan,        nan, ...,  0.       ,  0.       ,
         0.       ]], dtype=float32), 'output_shape': torch.Size([1, 524288]), 'from': [9], 'to': [15]}

generate models:20

analyse the exceptions in iter:65
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[148., 132., 134.,  ..., 124., 108., 124.],
           [197., 168., 176.,  ..., 176., 162., 141.],
           [199., 199., 213.,  ..., 182., 178., 153.],
           ...,
           [179., 183., 182.,  ..., 164., 147., 136.],
           [162., 146., 127.,  ..., 118., 118., 132.],
           [150., 143., 123.,  ..., 124., 126., 157.]],

          [[141., 128., 135.,  ..., 131., 109., 127.],
           [181., 151., 166.,  ..., 178., 157., 133.],
           [194., 191., 209.,  ..., 186., 175., 141.],
           ...,
           [170., 165., 166.,  ..., 144., 127., 119.],
           [156., 133., 116.,  ..., 100.,  99., 116.],
           [148., 141., 125.,  ..., 119., 121., 154.]],

          [[174., 173., 187.,  ..., 186., 166., 171.],
           [214., 185., 199.,  ..., 213., 191., 162.],
           [207., 193., 209.,  ..., 193., 178., 156.],
           ...,
           [170., 148., 145.,  ..., 121., 106., 130.],
           [173., 140., 122.,  ..., 106., 108., 138.],
           [184., 176., 161.,  ..., 162., 162., 186.]]]]])}
Given groups=1, weight of size [256, 256, 3, 3], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.48000000e+002, 1.32000000e+002, 1.34000000e+002 ... 1.24000000e+002, 1.08000000e+002, 1.24000000e+002],
    [1.97000000e+002, 1.68000000e+002, 1.76000000e+002 ... 1.76000000e+002, 1.62000000e+002, 1.41000000e+002],
    [1.99000000e+002, 1.99000000e+002, 2.13000000e+002 ... 1.82000000e+002, 1.78000000e+002, 1.53000000e+002],
    ...
    [1.79000000e+002, 1.83000000e+002, 1.82000000e+002 ... 1.64000000e+002, 1.47000000e+002, 1.36000000e+002],
    [1.62000000e+002, 1.46000000e+002, 1.27000000e+002 ... 1.18000000e+002, 1.18000000e+002, 1.32000000e+002],
    [1.50000000e+002, 1.43000000e+002, 1.23000000e+002 ... 1.24000000e+002, 1.26000000e+002, 1.57000000e+002]],
   [[1.41000000e+002, 1.28000000e+002, 1.35000000e+002 ... 1.31000000e+002, 1.09000000e+002, 1.27000000e+002],
    [1.81000000e+002, 1.51000000e+002, 1.66000000e+002 ... 1.78000000e+002, 1.57000000e+002, 1.33000000e+002],
    [1.94000000e+002, 1.91000000e+002, 2.09000000e+002 ... 1.86000000e+002, 1.75000000e+002, 1.41000000e+002],
    ...
    [1.70000000e+002, 1.65000000e+002, 1.66000000e+002 ... 1.44000000e+002, 1.27000000e+002, 1.19000000e+002],
    [1.56000000e+002, 1.33000000e+002, 1.16000000e+002 ... 1.00000000e+002, 9.90000000e+001, 1.16000000e+002],
    [1.48000000e+002, 1.41000000e+002, 1.25000000e+002 ... 1.19000000e+002, 1.21000000e+002, 1.54000000e+002]],
   [[1.74000000e+002, 1.73000000e+002, 1.87000000e+002 ... 1.86000000e+002, 1.66000000e+002, 1.71000000e+002],
    [2.14000000e+002, 1.85000000e+002, 1.99000000e+002 ... 2.13000000e+002, 1.91000000e+002, 1.62000000e+002],
    [2.07000000e+002, 1.93000000e+002, 2.09000000e+002 ... 1.93000000e+002, 1.78000000e+002, 1.56000000e+002],
    ...
    [1.70000000e+002, 1.48000000e+002, 1.45000000e+002 ... 1.21000000e+002, 1.06000000e+002, 1.30000000e+002],
    [1.73000000e+002, 1.40000000e+002, 1.22000000e+002 ... 1.06000000e+002, 1.08000000e+002, 1.38000000e+002],
    [1.84000000e+002, 1.76000000e+002, 1.61000000e+002 ... 1.62000000e+002, 1.62000000e+002, 1.86000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:24

analyse output arrays in iter:72

pre layer res:
0:relu
{'name': 'relu', 'output': array([[[[229., 227., 208., ..., 230., 230., 213.],
         [221., 214., 145., ..., 236., 231., 201.],
         [213., 173.,  64., ..., 242., 222., 187.],
         ...,
         [224., 218., 229., ..., 190., 159., 176.],
         [224., 207., 226., ..., 162., 132., 170.],
         [233., 217., 221., ..., 153., 141., 167.]],

        [[232., 232., 214., ..., 231., 232., 218.],
         [226., 221., 150., ..., 238., 233., 207.],
         [223., 181.,  67., ..., 243., 225., 195.],
         ...,
         [224., 218., 229., ..., 193., 163., 183.],
         [224., 207., 226., ..., 165., 136., 178.],
         [233., 217., 221., ..., 156., 145., 175.]],

        [[235., 232., 219., ..., 231., 236., 223.],
         [234., 225., 157., ..., 237., 237., 214.],
         [232., 187.,  69., ..., 243., 229., 203.],
         ...,
         [222., 217., 229., ..., 199., 173., 194.],
         [223., 207., 226., ..., 173., 147., 189.],
         [233., 217., 221., ..., 164., 154., 184.]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [], 'to': [8]}
tf node:
{'name': 'log', 'output': array([[[[5.433722 , 5.42495  , 5.3375382, ..., 5.4380794, 5.4380794,
          5.3612924],
         [5.398163 , 5.365976 , 4.9767337, ..., 5.463832 , 5.4424176,
          5.303305 ],
         [5.3612924, 5.1532917, 4.158883 , ..., 5.488938 , 5.4026775,
          5.2311087],
         ...,
         [5.411646 , 5.3844953, 5.433722 , ..., 5.247024 , 5.0689044,
          5.170484 ],
         [5.411646 , 5.332719 , 5.420535 , ..., 5.0875964, 4.882802 ,
          5.1357985],
         [5.4510384, 5.3798976, 5.398163 , ..., 5.030438 , 4.94876  ,
          5.117994 ]],

        [[5.4467373, 5.4467373, 5.365976 , ..., 5.4424176, 5.4467373,
          5.3844953],
         [5.420535 , 5.398163 , 5.0106354, ..., 5.4722705, 5.4510384,
          5.332719 ],
         [5.4071717, 5.198497 , 4.204693 , ..., 5.4930615, 5.4161005,
          5.273    ],
         ...,
         [5.411646 , 5.3844953, 5.433722 , ..., 5.26269  , 5.09375  ,
          5.209486 ],
         [5.411646 , 5.332719 , 5.420535 , ..., 5.1059456, 4.912655 ,
          5.1817837],
         [5.4510384, 5.3798976, 5.398163 , ..., 5.049856 , 4.9767337,
          5.164786 ]],

        [[5.4595857, 5.4467373, 5.389072 , ..., 5.4424176, 5.463832 ,
          5.4071717],
         [5.4553213, 5.4161005, 5.056246 , ..., 5.46806  , 5.46806  ,
          5.365976 ],
         [5.4467373, 5.2311087, 4.2341065, ..., 5.4930615, 5.433722 ,
          5.313206 ],
         ...,
         [5.4026775, 5.3798976, 5.433722 , ..., 5.293305 , 5.1532917,
          5.267858 ],
         [5.4071717, 5.332719 , 5.420535 , ..., 5.1532917, 4.9904327,
          5.241747 ],
         [5.4510384, 5.3798976, 5.398163 , ..., 5.0998664, 5.0369525,
          5.214936 ]]]], dtype=float32), 'output_shape': TensorShape([1, 3, 32, 32]), 'from': [0], 'to': [1]}
ms node:
{'name': 'log', 'output': array([[[[5.433721 , 5.424949 , 5.337536 , ..., 5.4380784, 5.4380784,
          5.361289 ],
         [5.398162 , 5.3659725, 4.976731 , ..., 5.463832 , 5.4424167,
          5.3033023],
         [5.361289 , 5.15329  , 4.1588817, ..., 5.488938 , 5.4026766,
          5.2311087],
         ...,
         [5.411645 , 5.384492 , 5.433721 , ..., 5.247024 , 5.068905 ,
          5.170487 ],
         [5.411645 , 5.3327165, 5.420534 , ..., 5.0875993, 4.8828053,
          5.1357965],
         [5.4510374, 5.3798943, 5.398162 , ..., 5.0304365, 4.9487605,
          5.1179967]],

        [[5.4467363, 5.4467363, 5.3659725, ..., 5.4424167, 5.4467363,
          5.384492 ],
         [5.420534 , 5.398162 , 5.010634 , ..., 5.4722705, 5.4510374,
          5.3327165],
         [5.407171 , 5.1984997, 4.204696 , ..., 5.4930615, 5.4160995,
          5.2729974],
         ...,
         [5.411645 , 5.384492 , 5.433721 , ..., 5.262688 , 5.093753 ,
          5.209489 ],
         [5.411645 , 5.3327165, 5.420534 , ..., 5.1059484, 4.912652 ,
          5.1817865],
         [5.4510374, 5.3798943, 5.398162 , ..., 5.0498567, 4.976731 ,
          5.164784 ]],

        [[5.4595847, 5.4467363, 5.3890686, ..., 5.4424167, 5.463832 ,
          5.407171 ],
         [5.4553204, 5.4160995, 5.0562468, ..., 5.46806  , 5.46806  ,
          5.3659725],
         [5.4467363, 5.2311087, 4.2341037, ..., 5.4930615, 5.433721 ,
          5.313204 ],
         ...,
         [5.4026766, 5.3798943, 5.433721 , ..., 5.2933025, 5.15329  ,
          5.267856 ],
         [5.407171 , 5.3327165, 5.420534 , ..., 5.15329  , 4.9904294,
          5.241747 ],
         [5.4510374, 5.3798943, 5.398162 , ..., 5.0998693, 5.036951 ,
          5.214936 ]]]], dtype=float32), 'output_shape': (1, 3, 32, 32), 'from': [0], 'to': [1]}
torch node:
{'name': 'log', 'output': array([[[[5.433722 , 5.42495  , 5.3375382, ..., 5.4380794, 5.4380794,
          5.3612924],
         [5.398163 , 5.365976 , 4.9767337, ..., 5.463832 , 5.4424176,
          5.3033047],
         [5.3612924, 5.1532917, 4.158883 , ..., 5.488938 , 5.4026775,
          5.2311087],
         ...,
         [5.411646 , 5.3844953, 5.433722 , ..., 5.247024 , 5.0689044,
          5.170484 ],
         [5.411646 , 5.332719 , 5.420535 , ..., 5.0875964, 4.882802 ,
          5.1357985],
         [5.4510384, 5.379897 , 5.398163 , ..., 5.030438 , 4.94876  ,
          5.117994 ]],

        [[5.4467373, 5.4467373, 5.365976 , ..., 5.4424176, 5.4467373,
          5.3844953],
         [5.420535 , 5.398163 , 5.0106354, ..., 5.4722705, 5.4510384,
          5.332719 ],
         [5.4071717, 5.198497 , 4.204693 , ..., 5.4930615, 5.4161005,
          5.273    ],
         ...,
         [5.411646 , 5.3844953, 5.433722 , ..., 5.26269  , 5.09375  ,
          5.209486 ],
         [5.411646 , 5.332719 , 5.420535 , ..., 5.1059456, 4.912655 ,
          5.1817837],
         [5.4510384, 5.379897 , 5.398163 , ..., 5.049856 , 4.9767337,
          5.164786 ]],

        [[5.4595857, 5.4467373, 5.389072 , ..., 5.4424176, 5.463832 ,
          5.4071717],
         [5.4553213, 5.4161005, 5.056246 , ..., 5.46806  , 5.46806  ,
          5.365976 ],
         [5.4467373, 5.2311087, 4.2341065, ..., 5.4930615, 5.433722 ,
          5.313206 ],
         ...,
         [5.4026775, 5.379897 , 5.433722 , ..., 5.293305 , 5.1532917,
          5.267858 ],
         [5.4071717, 5.332719 , 5.420535 , ..., 5.1532917, 4.9904327,
          5.241747 ],
         [5.4510384, 5.379897 , 5.398163 , ..., 5.0998664, 5.0369525,
          5.214936 ]]]], dtype=float32), 'output_shape': torch.Size([1, 3, 32, 32]), 'from': [0], 'to': [1]}

pre layer res:
4:pad
{'name': 'pad', 'output': array([[52441.004, 51529.01 , 43264.016, ...,     0.   ,     0.   ,
            0.   ]], dtype=float32), 'output_shape': TensorShape([1, 262144]), 'from': [6], 'to': [9]}
tf node:
{'name': 'sin', 'output': array([[ 0.99950504,  0.5720595 , -0.909962  , ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': TensorShape([1, 262144]), 'from': [4], 'to': [10]}
ms node:
{'name': 'sin', 'output': array([[ 0.9906394 ,  0.48595196, -0.8052881 , ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': (1, 262144), 'from': [4], 'to': [10]}
torch node:
{'name': 'sin', 'output': array([[ 0.99937457,  0.57205945, -0.909962  , ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [4], 'to': [10]}

generate models:26

analyse the exceptions in iter:84
torch exception:
{'id': 4, 'name': 'dense', 'frame_work': 'torch', 'input_datas': [tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5481e-34,
           3.7917e-21, 9.7875e-01],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3549e-27,
           1.1724e-28, 3.3189e-05],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1105e-04,
           5.2381e-22, 7.5757e-10],
          ...,
          [2.6893e-01, 1.5068e-09, 1.1134e-08,  ..., 4.0357e-42,
           4.2039e-45, 0.0000e+00],
          [8.7565e-27, 8.7565e-27, 1.1548e-17,  ..., 2.4426e-36,
           2.1151e-19, 2.0612e-09],
          [1.0089e-43, 2.2271e-39, 3.0140e-40,  ..., 1.0529e-20,
           1.3886e-11, 1.2339e-04]],

         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5481e-34,
           3.7917e-21, 9.7875e-01],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3549e-27,
           1.1724e-28, 3.3189e-05],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1105e-04,
           5.2381e-22, 7.5757e-10],
          ...,
          [2.6893e-01, 1.5068e-09, 1.1134e-08,  ..., 4.0357e-42,
           4.2039e-45, 0.0000e+00],
          [8.7565e-27, 8.7565e-27, 1.1548e-17,  ..., 2.4426e-36,
           2.1151e-19, 2.0612e-09],
          [1.0089e-43, 2.2271e-39, 3.0140e-40,  ..., 1.0529e-20,
           1.3886e-11, 1.2339e-04]],

         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5481e-34,
           3.7917e-21, 9.7875e-01],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3549e-27,
           1.1724e-28, 3.3189e-05],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1105e-04,
           5.2381e-22, 7.5757e-10],
          ...,
          [2.6893e-01, 1.5068e-09, 1.1134e-08,  ..., 4.0357e-42,
           4.2039e-45, 0.0000e+00],
          [8.7565e-27, 8.7565e-27, 1.1548e-17,  ..., 2.4426e-36,
           2.1151e-19, 2.0612e-09],
          [1.0089e-43, 2.2271e-39, 3.0140e-40,  ..., 1.0529e-20,
           1.3886e-11, 1.2339e-04]],

         ...,

         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5481e-34,
           3.7917e-21, 9.7875e-01],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3549e-27,
           1.1724e-28, 3.3189e-05],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1105e-04,
           5.2381e-22, 7.5757e-10],
          ...,
          [2.6893e-01, 1.5068e-09, 1.1134e-08,  ..., 4.0357e-42,
           4.2039e-45, 0.0000e+00],
          [8.7565e-27, 8.7565e-27, 1.1548e-17,  ..., 2.4426e-36,
           2.1151e-19, 2.0612e-09],
          [1.0089e-43, 2.2271e-39, 3.0140e-40,  ..., 1.0529e-20,
           1.3886e-11, 1.2339e-04]],

         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5481e-34,
           3.7917e-21, 9.7875e-01],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3549e-27,
           1.1724e-28, 3.3189e-05],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1105e-04,
           5.2381e-22, 7.5757e-10],
          ...,
          [2.6893e-01, 1.5068e-09, 1.1134e-08,  ..., 4.0357e-42,
           4.2039e-45, 0.0000e+00],
          [8.7565e-27, 8.7565e-27, 1.1548e-17,  ..., 2.4426e-36,
           2.1151e-19, 2.0612e-09],
          [1.0089e-43, 2.2271e-39, 3.0140e-40,  ..., 1.0529e-20,
           1.3886e-11, 1.2339e-04]],

         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5481e-34,
           3.7917e-21, 9.7875e-01],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3549e-27,
           1.1724e-28, 3.3189e-05],
          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1105e-04,
           5.2381e-22, 7.5757e-10],
          ...,
          [2.6893e-01, 1.5068e-09, 1.1134e-08,  ..., 4.0357e-42,
           4.2039e-45, 0.0000e+00],
          [8.7565e-27, 8.7565e-27, 1.1548e-17,  ..., 2.4426e-36,
           2.1151e-19, 2.0612e-09],
          [1.0089e-43, 2.2271e-39, 3.0140e-40,  ..., 1.0529e-20,
           1.3886e-11, 1.2339e-04]]]], grad_fn=<ReluBackward0>)]}
'weight'

generate models:30

analyse the exceptions in iter:97
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0.0078, 0.0338, 0.0550,  ..., 0.0092, 0.0580, 0.0096],
          [0.0128, 0.0094, 0.0247,  ..., 0.0090, 0.0090, 0.0166],
          [0.0112, 0.0475, 0.0342,  ..., 0.0421, 0.0076, 0.0371],
          ...,
          [0.0333, 0.0129, 0.0098,  ..., 0.0713, 0.0673, 0.0097],
          [0.0141, 0.0792, 0.0122,  ..., 0.0144, 0.0146, 0.0145],
          [0.0104, 0.0519, 0.0080,  ..., 0.0482, 0.0533, 0.0233]],

         [[0.0078, 0.0338, 0.0550,  ..., 0.0092, 0.0580, 0.0096],
          [0.0128, 0.0094, 0.0247,  ..., 0.0090, 0.0090, 0.0166],
          [0.0112, 0.0475, 0.0342,  ..., 0.0421, 0.0076, 0.0371],
          ...,
          [0.0333, 0.0129, 0.0098,  ..., 0.0713, 0.0673, 0.0097],
          [0.0141, 0.0792, 0.0122,  ..., 0.0144, 0.0146, 0.0145],
          [0.0104, 0.0519, 0.0080,  ..., 0.0482, 0.0533, 0.0233]],

         [[0.0078, 0.0338, 0.0550,  ..., 0.0092, 0.0580, 0.0096],
          [0.0128, 0.0094, 0.0247,  ..., 0.0090, 0.0090, 0.0166],
          [0.0112, 0.0475, 0.0342,  ..., 0.0421, 0.0076, 0.0371],
          ...,
          [0.0333, 0.0129, 0.0098,  ..., 0.0713, 0.0673, 0.0097],
          [0.0141, 0.0792, 0.0122,  ..., 0.0144, 0.0146, 0.0145],
          [0.0104, 0.0519, 0.0080,  ..., 0.0482, 0.0533, 0.0233]],

         ...,

         [[0.0078, 0.0338, 0.0550,  ..., 0.0092, 0.0580, 0.0096],
          [0.0128, 0.0094, 0.0247,  ..., 0.0090, 0.0090, 0.0166],
          [0.0112, 0.0475, 0.0342,  ..., 0.0421, 0.0076, 0.0371],
          ...,
          [0.0333, 0.0129, 0.0098,  ..., 0.0713, 0.0673, 0.0097],
          [0.0141, 0.0792, 0.0122,  ..., 0.0144, 0.0146, 0.0145],
          [0.0104, 0.0519, 0.0080,  ..., 0.0482, 0.0533, 0.0233]],

         [[0.0078, 0.0338, 0.0550,  ..., 0.0092, 0.0580, 0.0096],
          [0.0128, 0.0094, 0.0247,  ..., 0.0090, 0.0090, 0.0166],
          [0.0112, 0.0475, 0.0342,  ..., 0.0421, 0.0076, 0.0371],
          ...,
          [0.0333, 0.0129, 0.0098,  ..., 0.0713, 0.0673, 0.0097],
          [0.0141, 0.0792, 0.0122,  ..., 0.0144, 0.0146, 0.0145],
          [0.0104, 0.0519, 0.0080,  ..., 0.0482, 0.0533, 0.0233]],

         [[0.0078, 0.0338, 0.0550,  ..., 0.0092, 0.0580, 0.0096],
          [0.0128, 0.0094, 0.0247,  ..., 0.0090, 0.0090, 0.0166],
          [0.0112, 0.0475, 0.0342,  ..., 0.0421, 0.0076, 0.0371],
          ...,
          [0.0333, 0.0129, 0.0098,  ..., 0.0713, 0.0673, 0.0097],
          [0.0141, 0.0792, 0.0122,  ..., 0.0144, 0.0146, 0.0145],
          [0.0104, 0.0519, 0.0080,  ..., 0.0482, 0.0533, 0.0233]]]],
       grad_fn=<ReluBackward0>)]}
Given groups=1, weight of size [2048, 2048, 1, 1], expected input[1, 256, 32, 32] to have 2048 channels, but got 256 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 256, 32, 32], dtype=Float32, value=
[[[[7.84578361e-003, 3.37755680e-002, 5.50470948e-002 ... 9.19426419e-003, 5.79540059e-002, 9.56994109e-003],
   [1.27796503e-002, 9.38617345e-003, 2.47080605e-002 ... 9.01287887e-003, 9.04024020e-003, 1.66125093e-002],
   [1.12160351e-002, 4.75105904e-002, 3.42364758e-002 ... 4.21268009e-002, 7.62499403e-003, 3.71208899e-002],
   ...
   [3.33051905e-002, 1.28603019e-002, 9.84709803e-003 ... 7.13448226e-002, 6.72655031e-002, 9.69880261e-003],
   [1.40514299e-002, 7.91686773e-002, 1.22475019e-002 ... 1.43893957e-002, 1.46071389e-002, 1.44600291e-002],
   [1.03625990e-002, 5.18889017e-002, 7.96898920e-003 ... 4.82237227e-002, 5.32848202e-002, 2.32774876e-002]],
  [[7.84578361e-003, 3.37755680e-002, 5.50470948e-002 ... 9.19426419e-003, 5.79540059e-002, 9.56994109e-003],
   [1.27796503e-002, 9.38617345e-003, 2.47080605e-002 ... 9.01287887e-003, 9.04024020e-003, 1.66125093e-002],
   [1.12160351e-002, 4.75105904e-002, 3.42364758e-002 ... 4.21268009e-002, 7.62499403e-003, 3.71208899e-002],
   ...
   [3.33051905e-002, 1.28603019e-002, 9.84709803e-003 ... 7.13448226e-002, 6.72655031e-002, 9.69880261e-003],
   [1.40514299e-002, 7.91686773e-002, 1.22475019e-002 ... 1.43893957e-002, 1.46071389e-002, 1.44600291e-002],
   [1.03625990e-002, 5.18889017e-002, 7.96898920e-003 ... 4.82237227e-002, 5.32848202e-002, 2.32774876e-002]],
  [[7.84578361e-003, 3.37755680e-002, 5.50470948e-002 ... 9.19426419e-003, 5.79540059e-002, 9.56994109e-003],
   [1.27796503e-002, 9.38617345e-003, 2.47080605e-002 ... 9.01287887e-003, 9.04024020e-003, 1.66125093e-002],
   [1.12160351e-002, 4.75105904e-002, 3.42364758e-002 ... 4.21268009e-002, 7.62499403e-003, 3.71208899e-002],
   ...
   [3.33051905e-002, 1.28603019e-002, 9.84709803e-003 ... 7.13448226e-002, 6.72655031e-002, 9.69880261e-003],
   [1.40514299e-002, 7.91686773e-002, 1.22475019e-002 ... 1.43893957e-002, 1.46071389e-002, 1.44600291e-002],
   [1.03625990e-002, 5.18889017e-002, 7.96898920e-003 ... 4.82237227e-002, 5.32848202e-002, 2.32774876e-002]],
  ...
  [[7.84578361e-003, 3.37755680e-002, 5.50470948e-002 ... 9.19426419e-003, 5.79540059e-002, 9.56994109e-003],
   [1.27796503e-002, 9.38617345e-003, 2.47080605e-002 ... 9.01287887e-003, 9.04024020e-003, 1.66125093e-002],
   [1.12160351e-002, 4.75105904e-002, 3.42364758e-002 ... 4.21268009e-002, 7.62499403e-003, 3.71208899e-002],
   ...
   [3.33051905e-002, 1.28603019e-002, 9.84709803e-003 ... 7.13448226e-002, 6.72655031e-002, 9.69880261e-003],
   [1.40514299e-002, 7.91686773e-002, 1.22475019e-002 ... 1.43893957e-002, 1.46071389e-002, 1.44600291e-002],
   [1.03625990e-002, 5.18889017e-002, 7.96898920e-003 ... 4.82237227e-002, 5.32848202e-002, 2.32774876e-002]],
  [[7.84578361e-003, 3.37755680e-002, 5.50470948e-002 ... 9.19426419e-003, 5.79540059e-002, 9.56994109e-003],
   [1.27796503e-002, 9.38617345e-003, 2.47080605e-002 ... 9.01287887e-003, 9.04024020e-003, 1.66125093e-002],
   [1.12160351e-002, 4.75105904e-002, 3.42364758e-002 ... 4.21268009e-002, 7.62499403e-003, 3.71208899e-002],
   ...
   [3.33051905e-002, 1.28603019e-002, 9.84709803e-003 ... 7.13448226e-002, 6.72655031e-002, 9.69880261e-003],
   [1.40514299e-002, 7.91686773e-002, 1.22475019e-002 ... 1.43893957e-002, 1.46071389e-002, 1.44600291e-002],
   [1.03625990e-002, 5.18889017e-002, 7.96898920e-003 ... 4.82237227e-002, 5.32848202e-002, 2.32774876e-002]],
  [[7.84578361e-003, 3.37755680e-002, 5.50470948e-002 ... 9.19426419e-003, 5.79540059e-002, 9.56994109e-003],
   [1.27796503e-002, 9.38617345e-003, 2.47080605e-002 ... 9.01287887e-003, 9.04024020e-003, 1.66125093e-002],
   [1.12160351e-002, 4.75105904e-002, 3.42364758e-002 ... 4.21268009e-002, 7.62499403e-003, 3.71208899e-002],
   ...
   [3.33051905e-002, 1.28603019e-002, 9.84709803e-003 ... 7.13448226e-002, 6.72655031e-002, 9.69880261e-003],
   [1.40514299e-002, 7.91686773e-002, 1.22475019e-002 ... 1.43893957e-002, 1.46071389e-002, 1.44600291e-002],
   [1.03625990e-002, 5.18889017e-002, 7.96898920e-003 ... 4.82237227e-002, 5.32848202e-002, 2.32774876e-002]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 2048, but got 'C_in' of input 'x' shape: 256, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:34

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:2
mindspore --> nums:8,distinct_bugs:3
torch --> nums:8,distinct_bugs:4
tensorflow --> 
log:1
sin:1
mindspore --> 
conv2d:5
log:2
sin:1
torch --> 
conv2d:5
log:1
sin:1
dense:1

generate models:35

analyse the exceptions in iter:113
torch exception:
{'id': 3, 'name': 'dense', 'frame_work': 'torch', 'input_datas': [tensor([[450., 454., 452.,  ..., 190., 164., 130.]])]}
'weight'

generate models:40

analyse output arrays in iter:114

pre layer res:
14:arctan
{'name': 'arctan', 'output': array([[[[1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         ...,
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964]],

        [[1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         ...,
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964]],

        [[1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         ...,
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964],
         [1.5707964, 1.5707964, 1.5707964, ..., 1.5707964, 1.5707964,
          1.5707964]],

        ...,

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]],

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]],

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [8], 'to': [3]}
tf node:
{'name': 'conv2d', 'output': array([[[[42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         ...,
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [28.274338, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          18.849556]],

        [[42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         ...,
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [28.274338, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          18.849556]],

        [[42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         ...,
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [28.274338, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          18.849556]],

        ...,

        [[42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         ...,
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [28.274338, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          18.849556]],

        [[42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         ...,
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [28.274338, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          18.849556]],

        [[42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         ...,
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [42.41151 , 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          28.274338],
         [28.274338, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          18.849556]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 16, 16]), 'from': [14], 'to': [4]}
ms node:
{'name': 'conv2d', 'output': array([[[[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        ...,

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]]]], dtype=float32), 'output_shape': (1, 256, 16, 16), 'from': [14], 'to': [4]}
torch node:
{'name': 'conv2d', 'output': array([[[[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        ...,

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]],

        [[18.849556, 28.274338, 28.274338, ..., 28.274338, 28.274338,
          28.274338],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         ...,
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ],
         [28.274338, 42.41151 , 42.41151 , ..., 42.41151 , 42.41151 ,
          42.41151 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 16, 16]), 'from': [14], 'to': [4]}

generate models:41

analyse output arrays in iter:131

pre layer res:
8:sin
{'name': 'sin', 'output': array([[[[-0.04436314, -0.32173657, -0.32173657, ..., -0.32173657,
          -0.32173657, -0.32173657],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.04436314],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.7270597 ],
         ...,
         [ 0.02649089, -0.67025155,  0.7024293 , ...,  0.28778785,
           0.01782248,  0.73310834],
         [ 0.04418245, -0.4201944 ,  0.41214597, ..., -0.5441223 ,
          -0.7332723 ,  0.9956758 ],
         [-0.8414873 , -0.0972119 , -0.30486804, ...,  0.56620705,
           0.9268638 ,  0.994839  ]],

        [[-0.04436314, -0.32173657, -0.32173657, ..., -0.32173657,
          -0.32173657, -0.32173657],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.04436314],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.7270597 ],
         ...,
         [ 0.02649089, -0.67025155,  0.7024293 , ...,  0.28778785,
           0.01782248,  0.73310834],
         [ 0.04418245, -0.4201944 ,  0.41214597, ..., -0.5441223 ,
          -0.7332723 ,  0.9956758 ],
         [-0.8414873 , -0.0972119 , -0.30486804, ...,  0.56620705,
           0.9268638 ,  0.994839  ]],

        [[-0.04436314, -0.32173657, -0.32173657, ..., -0.32173657,
          -0.32173657, -0.32173657],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.04436314],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.7270597 ],
         ...,
         [ 0.02649089, -0.67025155,  0.7024293 , ...,  0.28778785,
           0.01782248,  0.73310834],
         [ 0.04418245, -0.4201944 ,  0.41214597, ..., -0.5441223 ,
          -0.7332723 ,  0.9956758 ],
         [-0.8414873 , -0.0972119 , -0.30486804, ...,  0.56620705,
           0.9268638 ,  0.994839  ]],

        ...,

        [[-0.04436314, -0.32173657, -0.32173657, ..., -0.32173657,
          -0.32173657, -0.32173657],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.04436314],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.7270597 ],
         ...,
         [ 0.02649089, -0.67025155,  0.7024293 , ...,  0.28778785,
           0.01782248,  0.73310834],
         [ 0.04418245, -0.4201944 ,  0.41214597, ..., -0.5441223 ,
          -0.7332723 ,  0.9956758 ],
         [-0.8414873 , -0.0972119 , -0.30486804, ...,  0.56620705,
           0.9268638 ,  0.994839  ]],

        [[-0.04436314, -0.32173657, -0.32173657, ..., -0.32173657,
          -0.32173657, -0.32173657],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.04436314],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.7270597 ],
         ...,
         [ 0.02649089, -0.67025155,  0.7024293 , ...,  0.28778785,
           0.01782248,  0.73310834],
         [ 0.04418245, -0.4201944 ,  0.41214597, ..., -0.5441223 ,
          -0.7332723 ,  0.9956758 ],
         [-0.8414873 , -0.0972119 , -0.30486804, ...,  0.56620705,
           0.9268638 ,  0.994839  ]],

        [[-0.04436314, -0.32173657, -0.32173657, ..., -0.32173657,
          -0.32173657, -0.32173657],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.04436314],
         [-0.04436314, -0.04436314, -0.04436314, ..., -0.04436314,
          -0.04436314, -0.7270597 ],
         ...,
         [ 0.02649089, -0.67025155,  0.7024293 , ...,  0.28778785,
           0.01782248,  0.73310834],
         [ 0.04418245, -0.4201944 ,  0.41214597, ..., -0.5441223 ,
          -0.7332723 ,  0.9956758 ],
         [-0.8414873 , -0.0972119 , -0.30486804, ...,  0.56620705,
           0.9268638 ,  0.994839  ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 16, 16]), 'from': [4], 'to': [5]}
tf node:
{'name': 'log', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321054, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.8863777 , ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321054, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.8863777 , ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321054, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.8863777 , ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321054, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.8863777 , ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321054, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.8863777 , ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321054, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.8863777 , ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 16, 16]), 'from': [8], 'to': [6, 7]}
ms node:
{'name': 'log', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309578 ,         nan, -0.35320777, ..., -1.2455349 ,
          -4.0272975 , -0.31046185],
         [-3.1194248 ,         nan, -0.8863802 , ...,         nan,
                  nan, -0.004335  ],
         [        nan,         nan,         nan, ..., -0.5687986 ,
          -0.07594864, -0.00517578]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309578 ,         nan, -0.35320777, ..., -1.2455349 ,
          -4.0272975 , -0.31046185],
         [-3.1194248 ,         nan, -0.8863802 , ...,         nan,
                  nan, -0.004335  ],
         [        nan,         nan,         nan, ..., -0.5687986 ,
          -0.07594864, -0.00517578]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309578 ,         nan, -0.35320777, ..., -1.2455349 ,
          -4.0272975 , -0.31046185],
         [-3.1194248 ,         nan, -0.8863802 , ...,         nan,
                  nan, -0.004335  ],
         [        nan,         nan,         nan, ..., -0.5687986 ,
          -0.07594864, -0.00517578]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309578 ,         nan, -0.35320777, ..., -1.2455349 ,
          -4.0272975 , -0.31046185],
         [-3.1194248 ,         nan, -0.8863802 , ...,         nan,
                  nan, -0.004335  ],
         [        nan,         nan,         nan, ..., -0.5687986 ,
          -0.07594864, -0.00517578]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309578 ,         nan, -0.35320777, ..., -1.2455349 ,
          -4.0272975 , -0.31046185],
         [-3.1194248 ,         nan, -0.8863802 , ...,         nan,
                  nan, -0.004335  ],
         [        nan,         nan,         nan, ..., -0.5687986 ,
          -0.07594864, -0.00517578]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309578 ,         nan, -0.35320777, ..., -1.2455349 ,
          -4.0272975 , -0.31046185],
         [-3.1194248 ,         nan, -0.8863802 , ...,         nan,
                  nan, -0.004335  ],
         [        nan,         nan,         nan, ..., -0.5687986 ,
          -0.07594864, -0.00517578]]]], dtype=float32), 'output_shape': (1, 1024, 16, 16), 'from': [8], 'to': [6, 7]}
torch node:
{'name': 'log', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321063, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.88637775, ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321063, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.88637775, ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321063, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.88637775, ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321063, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.88637775, ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321063, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.88637775, ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [-3.6309545 ,         nan, -0.35321063, ..., -1.2455317 ,
          -4.0272946 , -0.3104618 ],
         [-3.1194277 ,         nan, -0.88637775, ...,         nan,
                  nan, -0.00433357],
         [        nan,         nan,         nan, ..., -0.56879544,
          -0.07594866, -0.00517435]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 16, 16]), 'from': [8], 'to': [6, 7]}

generate models:46

analyse output arrays in iter:134

pre layer res:
3:relu
{'name': 'relu', 'output': array([[[[13760.773, 13760.773, 13934.707, ..., 14705.056, 14001.221,
          13760.773],
         [13760.773, 13760.773, 13760.773, ..., 14706.277, 14023.005,
          13898.276],
         [13760.773, 13760.773, 13760.773, ..., 14704.069, 14087.996,
          13964.941],
         ...,
         [13229.768, 13229.768, 13229.768, ..., 14589.002, 13375.985,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14559.785, 13229.768,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14517.002, 13229.768,
          13229.768]],

        [[13760.773, 13760.773, 13934.707, ..., 14705.056, 14001.221,
          13760.773],
         [13760.773, 13760.773, 13760.773, ..., 14706.277, 14023.005,
          13898.276],
         [13760.773, 13760.773, 13760.773, ..., 14704.069, 14087.996,
          13964.941],
         ...,
         [13229.768, 13229.768, 13229.768, ..., 14589.002, 13375.985,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14559.785, 13229.768,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14517.002, 13229.768,
          13229.768]],

        [[13760.773, 13760.773, 13934.707, ..., 14705.056, 14001.221,
          13760.773],
         [13760.773, 13760.773, 13760.773, ..., 14706.277, 14023.005,
          13898.276],
         [13760.773, 13760.773, 13760.773, ..., 14704.069, 14087.996,
          13964.941],
         ...,
         [13229.768, 13229.768, 13229.768, ..., 14589.002, 13375.985,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14559.785, 13229.768,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14517.002, 13229.768,
          13229.768]],

        ...,

        [[13760.773, 13760.773, 13934.707, ..., 14705.056, 14001.221,
          13760.773],
         [13760.773, 13760.773, 13760.773, ..., 14706.277, 14023.005,
          13898.276],
         [13760.773, 13760.773, 13760.773, ..., 14704.069, 14087.996,
          13964.941],
         ...,
         [13229.768, 13229.768, 13229.768, ..., 14589.002, 13375.985,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14559.785, 13229.768,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14517.002, 13229.768,
          13229.768]],

        [[13760.773, 13760.773, 13934.707, ..., 14705.056, 14001.221,
          13760.773],
         [13760.773, 13760.773, 13760.773, ..., 14706.277, 14023.005,
          13898.276],
         [13760.773, 13760.773, 13760.773, ..., 14704.069, 14087.996,
          13964.941],
         ...,
         [13229.768, 13229.768, 13229.768, ..., 14589.002, 13375.985,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14559.785, 13229.768,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14517.002, 13229.768,
          13229.768]],

        [[13760.773, 13760.773, 13934.707, ..., 14705.056, 14001.221,
          13760.773],
         [13760.773, 13760.773, 13760.773, ..., 14706.277, 14023.005,
          13898.276],
         [13760.773, 13760.773, 13760.773, ..., 14704.069, 14087.996,
          13964.941],
         ...,
         [13229.768, 13229.768, 13229.768, ..., 14589.002, 13375.985,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14559.785, 13229.768,
          13229.768],
         [13229.768, 13229.768, 13229.768, ..., 14517.002, 13229.768,
          13229.768]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 16]), 'from': [2], 'to': [8]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.56267226,  0.56267226, -0.9851044 , ...,  0.6739536 ,
           0.75637525,  0.56267226],
         [ 0.56267226,  0.56267226,  0.56267226, ..., -0.46366945,
          -0.8746546 , -0.12917037],
         [ 0.56267226,  0.56267226,  0.56267226, ...,  0.9879993 ,
           0.88876104, -0.5329313 ],
         ...,
         [-0.49767298, -0.49767298, -0.49767298, ..., -0.5263739 ,
          -0.7932739 , -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.997263  ,
          -0.49767298, -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.2933213 ,
          -0.49767298, -0.49767298]],

        [[ 0.56267226,  0.56267226, -0.9851044 , ...,  0.6739536 ,
           0.75637525,  0.56267226],
         [ 0.56267226,  0.56267226,  0.56267226, ..., -0.46366945,
          -0.8746546 , -0.12917037],
         [ 0.56267226,  0.56267226,  0.56267226, ...,  0.9879993 ,
           0.88876104, -0.5329313 ],
         ...,
         [-0.49767298, -0.49767298, -0.49767298, ..., -0.5263739 ,
          -0.7932739 , -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.997263  ,
          -0.49767298, -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.2933213 ,
          -0.49767298, -0.49767298]],

        [[ 0.56267226,  0.56267226, -0.9851044 , ...,  0.6739536 ,
           0.75637525,  0.56267226],
         [ 0.56267226,  0.56267226,  0.56267226, ..., -0.46366945,
          -0.8746546 , -0.12917037],
         [ 0.56267226,  0.56267226,  0.56267226, ...,  0.9879993 ,
           0.88876104, -0.5329313 ],
         ...,
         [-0.49767298, -0.49767298, -0.49767298, ..., -0.5263739 ,
          -0.7932739 , -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.997263  ,
          -0.49767298, -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.2933213 ,
          -0.49767298, -0.49767298]],

        ...,

        [[ 0.56267226,  0.56267226, -0.9851044 , ...,  0.6739536 ,
           0.75637525,  0.56267226],
         [ 0.56267226,  0.56267226,  0.56267226, ..., -0.46366945,
          -0.8746546 , -0.12917037],
         [ 0.56267226,  0.56267226,  0.56267226, ...,  0.9879993 ,
           0.88876104, -0.5329313 ],
         ...,
         [-0.49767298, -0.49767298, -0.49767298, ..., -0.5263739 ,
          -0.7932739 , -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.997263  ,
          -0.49767298, -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.2933213 ,
          -0.49767298, -0.49767298]],

        [[ 0.56267226,  0.56267226, -0.9851044 , ...,  0.6739536 ,
           0.75637525,  0.56267226],
         [ 0.56267226,  0.56267226,  0.56267226, ..., -0.46366945,
          -0.8746546 , -0.12917037],
         [ 0.56267226,  0.56267226,  0.56267226, ...,  0.9879993 ,
           0.88876104, -0.5329313 ],
         ...,
         [-0.49767298, -0.49767298, -0.49767298, ..., -0.5263739 ,
          -0.7932739 , -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.997263  ,
          -0.49767298, -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.2933213 ,
          -0.49767298, -0.49767298]],

        [[ 0.56267226,  0.56267226, -0.9851044 , ...,  0.6739536 ,
           0.75637525,  0.56267226],
         [ 0.56267226,  0.56267226,  0.56267226, ..., -0.46366945,
          -0.8746546 , -0.12917037],
         [ 0.56267226,  0.56267226,  0.56267226, ...,  0.9879993 ,
           0.88876104, -0.5329313 ],
         ...,
         [-0.49767298, -0.49767298, -0.49767298, ..., -0.5263739 ,
          -0.7932739 , -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.997263  ,
          -0.49767298, -0.49767298],
         [-0.49767298, -0.49767298, -0.49767298, ...,  0.2933213 ,
          -0.49767298, -0.49767298]]]], dtype=float32), 'output_shape': TensorShape([1, 512, 16, 16]), 'from': [3], 'to': [4]}
ms node:
{'name': 'sin', 'output': array([[[[ 0.5183158 ,  0.5183158 , -0.9996252 , ...,  0.59792876,
           0.7322508 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6411528 ,
          -0.8585814 , -0.03187064],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9998242 ,
           0.8768375 , -0.4461436 ],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52221596,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996252 , ...,  0.59792876,
           0.7322508 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6411528 ,
          -0.8585814 , -0.03187064],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9998242 ,
           0.8768375 , -0.4461436 ],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52221596,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996252 , ...,  0.59792876,
           0.7322508 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6411528 ,
          -0.8585814 , -0.03187064],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9998242 ,
           0.8768375 , -0.4461436 ],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52221596,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        ...,

        [[ 0.5183158 ,  0.5183158 , -0.9996252 , ...,  0.59792876,
           0.7322508 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6411528 ,
          -0.8585814 , -0.03187064],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9998242 ,
           0.8768375 , -0.4461436 ],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52221596,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996252 , ...,  0.59792876,
           0.7322508 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6411528 ,
          -0.8585814 , -0.03187064],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9998242 ,
           0.8768375 , -0.4461436 ],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52221596,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996252 , ...,  0.59792876,
           0.7322508 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6411528 ,
          -0.8585814 , -0.03187064],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9998242 ,
           0.8768375 , -0.4461436 ],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52221596,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]]]], dtype=float32), 'output_shape': (1, 512, 16, 16), 'from': [3], 'to': [4]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.5183158 ,  0.5183158 , -0.9996515 , ...,  0.59792876,
           0.7315854 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6426504 ,
          -0.8585814 , -0.03089456],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9997208 ,
           0.8768375 , -0.44876364],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52054936,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996515 , ...,  0.59792876,
           0.7315854 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6426504 ,
          -0.8585814 , -0.03089456],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9997208 ,
           0.8768375 , -0.44876364],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52054936,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996515 , ...,  0.59792876,
           0.7315854 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6426504 ,
          -0.8585814 , -0.03089456],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9997208 ,
           0.8768375 , -0.44876364],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52054936,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        ...,

        [[ 0.5183158 ,  0.5183158 , -0.9996515 , ...,  0.59792876,
           0.7315854 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6426504 ,
          -0.8585814 , -0.03089456],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9997208 ,
           0.8768375 , -0.44876364],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52054936,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996515 , ...,  0.59792876,
           0.7315854 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6426504 ,
          -0.8585814 , -0.03089456],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9997208 ,
           0.8768375 , -0.44876364],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52054936,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]],

        [[ 0.5183158 ,  0.5183158 , -0.9996515 , ...,  0.59792876,
           0.7315854 ,  0.5183158 ],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ..., -0.6426504 ,
          -0.8585814 , -0.03089456],
         [ 0.5183158 ,  0.5183158 ,  0.5183158 , ...,  0.9997208 ,
           0.8768375 , -0.44876364],
         ...,
         [-0.48149458, -0.48149458, -0.48149458, ..., -0.52054936,
          -0.8357019 , -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.9999544 ,
          -0.48149458, -0.48149458],
         [-0.48149458, -0.48149458, -0.48149458, ...,  0.28677925,
          -0.48149458, -0.48149458]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [3], 'to': [4]}

generate models:47

analyse output arrays in iter:144

pre layer res:
14:log
{'name': 'log', 'output': array([[[[8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         ...,
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf]],

        [[8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         ...,
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf]],

        [[8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         ...,
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf]],

        ...,

        [[8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         ...,
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf]],

        [[8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         ...,
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf]],

        [[8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         ...,
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.481359, 8.886824, 8.481359, ...,     -inf,     -inf,
              -inf],
         [8.075893, 8.481359, 8.075893, ...,     -inf,     -inf,
              -inf]]]], dtype=float32), 'output_shape': TensorShape([1, 128, 32, 32]), 'from': [3], 'to': [7]}
tf node:
{'name': 'sin', 'output': array([[[[0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         ...,
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan]],

        [[0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         ...,
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan]],

        [[0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         ...,
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan]],

        ...,

        [[0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         ...,
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan]],

        [[0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         ...,
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan]],

        [[0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         ...,
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.80957013, 0.5123803 , 0.80957013, ...,        nan,
                 nan,        nan],
         [0.9754785 , 0.80957013, 0.9754785 , ...,        nan,
                 nan,        nan]]]], dtype=float32), 'output_shape': TensorShape([1, 128, 32, 32]), 'from': [14], 'to': [12]}
ms node:
{'name': 'sin', 'output': array([[[[0.9754308 , 0.8094419 , 0.9754308 , ...,        nan,
                 nan,        nan],
         [0.8094436 , 0.51219356, 0.8094436 , ...,        nan,
                 nan,        nan],
         [0.8094464 , 0.5121993 , 0.80944747, ...,        nan,
                 nan,        nan],
         ...,
         [0.8094794 , 0.51227385, 0.8095057 , ...,        nan,
                 nan,        nan],
         [0.8094811 , 0.5122771 , 0.8095085 , ...,        nan,
                 nan,        nan],
         [0.9754453 , 0.8095007 , 0.9754556 , ...,        nan,
                 nan,        nan]],

        [[0.9754308 , 0.8094419 , 0.9754308 , ...,        nan,
                 nan,        nan],
         [0.8094436 , 0.51219356, 0.8094436 , ...,        nan,
                 nan,        nan],
         [0.8094464 , 0.5121993 , 0.80944747, ...,        nan,
                 nan,        nan],
         ...,
         [0.8094794 , 0.51227385, 0.8095057 , ...,        nan,
                 nan,        nan],
         [0.8094811 , 0.5122771 , 0.8095085 , ...,        nan,
                 nan,        nan],
         [0.9754453 , 0.8095007 , 0.9754556 , ...,        nan,
                 nan,        nan]],

        [[0.9754308 , 0.8094419 , 0.9754308 , ...,        nan,
                 nan,        nan],
         [0.8094436 , 0.51219356, 0.8094436 , ...,        nan,
                 nan,        nan],
         [0.8094464 , 0.5121993 , 0.80944747, ...,        nan,
                 nan,        nan],
         ...,
         [0.8094794 , 0.51227385, 0.8095057 , ...,        nan,
                 nan,        nan],
         [0.8094811 , 0.5122771 , 0.8095085 , ...,        nan,
                 nan,        nan],
         [0.9754453 , 0.8095007 , 0.9754556 , ...,        nan,
                 nan,        nan]],

        ...,

        [[0.9754308 , 0.8094419 , 0.9754308 , ...,        nan,
                 nan,        nan],
         [0.8094436 , 0.51219356, 0.8094436 , ...,        nan,
                 nan,        nan],
         [0.8094464 , 0.5121993 , 0.80944747, ...,        nan,
                 nan,        nan],
         ...,
         [0.8094794 , 0.51227385, 0.8095057 , ...,        nan,
                 nan,        nan],
         [0.8094811 , 0.5122771 , 0.8095085 , ...,        nan,
                 nan,        nan],
         [0.9754453 , 0.8095007 , 0.9754556 , ...,        nan,
                 nan,        nan]],

        [[0.9754308 , 0.8094419 , 0.9754308 , ...,        nan,
                 nan,        nan],
         [0.8094436 , 0.51219356, 0.8094436 , ...,        nan,
                 nan,        nan],
         [0.8094464 , 0.5121993 , 0.80944747, ...,        nan,
                 nan,        nan],
         ...,
         [0.8094794 , 0.51227385, 0.8095057 , ...,        nan,
                 nan,        nan],
         [0.8094811 , 0.5122771 , 0.8095085 , ...,        nan,
                 nan,        nan],
         [0.9754453 , 0.8095007 , 0.9754556 , ...,        nan,
                 nan,        nan]],

        [[0.9754308 , 0.8094419 , 0.9754308 , ...,        nan,
                 nan,        nan],
         [0.8094436 , 0.51219356, 0.8094436 , ...,        nan,
                 nan,        nan],
         [0.8094464 , 0.5121993 , 0.80944747, ...,        nan,
                 nan,        nan],
         ...,
         [0.8094794 , 0.51227385, 0.8095057 , ...,        nan,
                 nan,        nan],
         [0.8094811 , 0.5122771 , 0.8095085 , ...,        nan,
                 nan,        nan],
         [0.9754453 , 0.8095007 , 0.9754556 , ...,        nan,
                 nan,        nan]]]], dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [14], 'to': [12]}
torch node:
{'name': 'sin', 'output': array([[[[0.97543395, 0.8094464 , 0.97543395, ...,        nan,
                 nan,        nan],
         [0.80944693, 0.51217145, 0.80944747, ...,        nan,
                 nan,        nan],
         [0.80944806, 0.5121723 , 0.8094486 , ...,        nan,
                 nan,        nan],
         ...,
         [0.8094788 , 0.5122853 , 0.80950797, ...,        nan,
                 nan,        nan],
         [0.8094788 , 0.5122853 , 0.8095091 , ...,        nan,
                 nan,        nan],
         [0.97544426, 0.8095035 , 0.97545666, ...,        nan,
                 nan,        nan]],

        [[0.97543395, 0.8094464 , 0.97543395, ...,        nan,
                 nan,        nan],
         [0.80944693, 0.51217145, 0.80944747, ...,        nan,
                 nan,        nan],
         [0.80944806, 0.5121723 , 0.8094486 , ...,        nan,
                 nan,        nan],
         ...,
         [0.8094788 , 0.5122853 , 0.80950797, ...,        nan,
                 nan,        nan],
         [0.8094788 , 0.5122853 , 0.8095091 , ...,        nan,
                 nan,        nan],
         [0.97544426, 0.8095035 , 0.97545666, ...,        nan,
                 nan,        nan]],

        [[0.97543395, 0.8094464 , 0.97543395, ...,        nan,
                 nan,        nan],
         [0.80944693, 0.51217145, 0.80944747, ...,        nan,
                 nan,        nan],
         [0.80944806, 0.5121723 , 0.8094486 , ...,        nan,
                 nan,        nan],
         ...,
         [0.8094788 , 0.5122853 , 0.80950797, ...,        nan,
                 nan,        nan],
         [0.8094788 , 0.5122853 , 0.8095091 , ...,        nan,
                 nan,        nan],
         [0.97544426, 0.8095035 , 0.97545666, ...,        nan,
                 nan,        nan]],

        ...,

        [[0.97543395, 0.8094464 , 0.97543395, ...,        nan,
                 nan,        nan],
         [0.80944693, 0.51217145, 0.80944747, ...,        nan,
                 nan,        nan],
         [0.80944806, 0.5121723 , 0.8094486 , ...,        nan,
                 nan,        nan],
         ...,
         [0.8094788 , 0.5122853 , 0.80950797, ...,        nan,
                 nan,        nan],
         [0.8094788 , 0.5122853 , 0.8095091 , ...,        nan,
                 nan,        nan],
         [0.97544426, 0.8095035 , 0.97545666, ...,        nan,
                 nan,        nan]],

        [[0.97543395, 0.8094464 , 0.97543395, ...,        nan,
                 nan,        nan],
         [0.80944693, 0.51217145, 0.80944747, ...,        nan,
                 nan,        nan],
         [0.80944806, 0.5121723 , 0.8094486 , ...,        nan,
                 nan,        nan],
         ...,
         [0.8094788 , 0.5122853 , 0.80950797, ...,        nan,
                 nan,        nan],
         [0.8094788 , 0.5122853 , 0.8095091 , ...,        nan,
                 nan,        nan],
         [0.97544426, 0.8095035 , 0.97545666, ...,        nan,
                 nan,        nan]],

        [[0.97543395, 0.8094464 , 0.97543395, ...,        nan,
                 nan,        nan],
         [0.80944693, 0.51217145, 0.80944747, ...,        nan,
                 nan,        nan],
         [0.80944806, 0.5121723 , 0.8094486 , ...,        nan,
                 nan,        nan],
         ...,
         [0.8094788 , 0.5122853 , 0.80950797, ...,        nan,
                 nan,        nan],
         [0.8094788 , 0.5122853 , 0.8095091 , ...,        nan,
                 nan,        nan],
         [0.97544426, 0.8095035 , 0.97545666, ...,        nan,
                 nan,        nan]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [14], 'to': [12]}

generate models:51

analyse the exceptions in iter:167
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[170., 169., 170.,  ..., 148., 136., 100.],
           [165., 165., 172.,  ..., 143., 130.,  93.],
           [160., 173., 177.,  ..., 141., 126.,  99.],
           ...,
           [113., 130., 173.,  ..., 128., 128., 126.],
           [104., 112., 168.,  ..., 118., 120., 121.],
           [115., 130., 181.,  ..., 114., 113., 118.]],

          [[162., 160., 159.,  ..., 116., 116.,  86.],
           [155., 152., 159.,  ..., 111., 111.,  82.],
           [151., 162., 165.,  ..., 109., 107.,  91.],
           ...,
           [114., 130., 173.,  ..., 115., 113., 109.],
           [107., 114., 169.,  ..., 105., 106., 106.],
           [118., 132., 183.,  ..., 100.,  98., 103.]],

          [[126., 123., 122.,  ...,  70.,  78.,  54.],
           [120., 118., 124.,  ...,  66.,  74.,  52.],
           [116., 127., 129.,  ...,  63.,  72.,  62.],
           ...,
           [ 97., 110., 150.,  ...,  85.,  83.,  80.],
           [ 93.,  97., 148.,  ...,  75.,  77.,  77.],
           [103., 115., 162.,  ...,  70.,  69.,  74.]]]]])}
Given groups=1, weight of size [128, 512, 3, 3], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.70000000e+002, 1.69000000e+002, 1.70000000e+002 ... 1.48000000e+002, 1.36000000e+002, 1.00000000e+002],
    [1.65000000e+002, 1.65000000e+002, 1.72000000e+002 ... 1.43000000e+002, 1.30000000e+002, 9.30000000e+001],
    [1.60000000e+002, 1.73000000e+002, 1.77000000e+002 ... 1.41000000e+002, 1.26000000e+002, 9.90000000e+001],
    ...
    [1.13000000e+002, 1.30000000e+002, 1.73000000e+002 ... 1.28000000e+002, 1.28000000e+002, 1.26000000e+002],
    [1.04000000e+002, 1.12000000e+002, 1.68000000e+002 ... 1.18000000e+002, 1.20000000e+002, 1.21000000e+002],
    [1.15000000e+002, 1.30000000e+002, 1.81000000e+002 ... 1.14000000e+002, 1.13000000e+002, 1.18000000e+002]],
   [[1.62000000e+002, 1.60000000e+002, 1.59000000e+002 ... 1.16000000e+002, 1.16000000e+002, 8.60000000e+001],
    [1.55000000e+002, 1.52000000e+002, 1.59000000e+002 ... 1.11000000e+002, 1.11000000e+002, 8.20000000e+001],
    [1.51000000e+002, 1.62000000e+002, 1.65000000e+002 ... 1.09000000e+002, 1.07000000e+002, 9.10000000e+001],
    ...
    [1.14000000e+002, 1.30000000e+002, 1.73000000e+002 ... 1.15000000e+002, 1.13000000e+002, 1.09000000e+002],
    [1.07000000e+002, 1.14000000e+002, 1.69000000e+002 ... 1.05000000e+002, 1.06000000e+002, 1.06000000e+002],
    [1.18000000e+002, 1.32000000e+002, 1.83000000e+002 ... 1.00000000e+002, 9.80000000e+001, 1.03000000e+002]],
   [[1.26000000e+002, 1.23000000e+002, 1.22000000e+002 ... 7.00000000e+001, 7.80000000e+001, 5.40000000e+001],
    [1.20000000e+002, 1.18000000e+002, 1.24000000e+002 ... 6.60000000e+001, 7.40000000e+001, 5.20000000e+001],
    [1.16000000e+002, 1.27000000e+002, 1.29000000e+002 ... 6.30000000e+001, 7.20000000e+001, 6.20000000e+001],
    ...
    [9.70000000e+001, 1.10000000e+002, 1.50000000e+002 ... 8.50000000e+001, 8.30000000e+001, 8.00000000e+001],
    [9.30000000e+001, 9.70000000e+001, 1.48000000e+002 ... 7.50000000e+001, 7.70000000e+001, 7.70000000e+001],
    [1.03000000e+002, 1.15000000e+002, 1.62000000e+002 ... 7.00000000e+001, 6.90000000e+001, 7.40000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:61

analyse the exceptions in iter:195
torch exception:
{'id': 3, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[2.8407e-21, 2.8407e-21, 7.7217e-21,  ..., 7.7217e-21,
           4.3263e-29, 0.0000e+00],
          [3.8359e-20, 3.8359e-20, 5.6929e-18,  ..., 1.0427e-19,
           2.9847e-39, 0.0000e+00],
          [4.4809e-13, 1.6484e-13, 3.3110e-12,  ..., 1.0394e-28,
           0.0000e+00, 9.7250e-42],
          ...,
          [5.5465e-07, 1.1141e-05, 2.2376e-04,  ..., 4.4944e-03,
           6.0825e-04, 8.2318e-05],
          [1.2395e-06, 1.2395e-06, 1.8395e-04,  ..., 2.0173e-01,
           2.0173e-01, 1.0043e-02],
          [1.5302e-05, 4.1596e-05, 2.2711e-03,  ..., 1.6781e-02,
           6.1734e-03, 1.2400e-01]],

         [[3.0925e-19, 1.5397e-20, 1.5397e-20,  ..., 6.3741e-28,
           2.6389e-35, 0.0000e+00],
          [2.2706e-17, 3.0729e-18, 6.1721e-17,  ..., 6.9458e-24,
           1.0854e-41, 0.0000e+00],
          [4.0937e-09, 5.5402e-10, 1.5060e-09,  ..., 8.6587e-28,
           2.0179e-43, 1.3187e-35],
          ...,
          [1.7687e-03, 4.8078e-03, 3.5525e-02,  ..., 2.6250e-01,
           3.5525e-02, 3.5525e-02],
          [3.4599e-04, 4.6825e-05, 9.4050e-04,  ..., 3.7942e-01,
           1.3958e-01, 1.3958e-01],
          [4.3292e-04, 1.5926e-04, 1.1768e-03,  ..., 2.3636e-02,
           8.6954e-03, 1.7465e-01]],

         [[9.5618e-25, 3.5176e-25, 3.5176e-25,  ..., 3.6097e-35,
           3.0016e-41, 0.0000e+00],
          [1.4191e-22, 5.2206e-23, 1.0486e-21,  ..., 1.4563e-32,
           7.5670e-44, 0.0000e+00],
          [7.3176e-11, 9.9033e-12, 7.3176e-11,  ..., 1.4114e-32,
           2.9091e-41, 7.7059e-31],
          ...,
          [2.9149e-08, 7.9236e-08, 1.1760e-05,  ..., 4.7442e-03,
           8.6893e-05, 1.1760e-05],
          [7.1962e-07, 1.9561e-06, 2.9031e-04,  ..., 1.5851e-02,
           5.8311e-03, 7.8915e-04],
          [4.1210e-05, 3.0450e-04, 4.5192e-02,  ..., 2.2500e-03,
           8.2773e-04, 6.1161e-03]]]])]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 3, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[2.84066626e-021, 2.84066626e-021, 7.72173183e-021 ... 7.72173183e-021, 4.32632898e-029, 0.00000000e+000],
   [3.83585234e-020, 3.83585234e-020, 5.69290927e-018 ... 1.04269270e-019, 0.00000000e+000, 0.00000000e+000],
   [4.48090593e-013, 1.64843318e-013, 3.31096674e-012 ... 1.03935650e-028, 0.00000000e+000, 0.00000000e+000],
   ...
   [5.54654548e-007, 1.11405352e-005, 2.23763651e-004 ... 4.49441234e-003, 6.08252594e-004, 8.23180380e-005],
   [1.23945165e-006, 1.23945165e-006, 1.83950964e-004 ... 2.01726720e-001, 2.01726720e-001, 1.00433808e-002],
   [1.53023448e-005, 4.15960931e-005, 2.27106968e-003 ... 1.67810582e-002, 6.17340626e-003, 1.23996191e-001]],
  [[3.09251424e-019, 1.53967215e-020, 1.53967215e-020 ... 6.37414682e-028, 2.63885740e-035, 0.00000000e+000],
   [2.27058630e-017, 3.07290442e-018, 6.17209351e-017 ... 6.94577670e-024, 0.00000000e+000, 0.00000000e+000],
   [4.09371204e-009, 5.54023716e-010, 1.50599255e-009 ... 8.65873933e-028, 0.00000000e+000, 1.31872429e-035],
   ...
   [1.76868564e-003, 4.80778562e-003, 3.55249979e-002 ... 2.62496263e-001, 3.55249979e-002, 3.55249979e-002],
   [3.45989596e-004, 4.68246035e-005, 9.40497208e-004 ... 3.79423678e-001, 1.39582157e-001, 1.39582157e-001],
   [4.32917557e-004, 1.59261457e-004, 1.17679185e-003 ... 2.36364938e-002, 8.69538076e-003, 1.74651399e-001]],
  [[9.56178599e-025, 3.51758476e-025, 3.51758476e-025 ... 3.60970381e-035, 0.00000000e+000, 0.00000000e+000],
   [1.41909514e-022, 5.22055904e-023, 1.04857724e-021 ... 1.45625824e-032, 0.00000000e+000, 0.00000000e+000],
   [7.31763122e-011, 9.90333596e-012, 7.31763122e-011 ... 1.41138800e-032, 0.00000000e+000, 7.70591748e-031],
   ...
   [2.91493372e-008, 7.92361092e-008, 1.17596819e-005 ... 4.74419398e-003, 8.68929492e-005, 1.17596819e-005],
   [7.19614945e-007, 1.95611619e-006, 2.90313415e-004 ... 1.58505738e-002, 5.83110005e-003, 7.89153681e-004],
   [4.12101726e-005, 3.04504269e-004, 4.51924354e-002 ... 2.24999897e-003, 8.27728363e-004, 6.11613085e-003]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:73

analyse output arrays in iter:203

pre layer res:
11:add
{'name': 'add', 'output': array([[[[764.4936, 764.4936, 764.4936, ..., 764.4936, 764.4936,
          764.4936],
         [764.4936, 759.9948, 759.9948, ..., 759.9948, 759.9948,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 759.9948,
          764.4936],
         ...,
         [764.4936, 759.9948, 762.452 , ..., 763.452 , 760.9948,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 760.9948,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 759.9948,
          764.4936]],

        [[764.4936, 764.4936, 764.4936, ..., 764.4936, 764.4936,
          764.4936],
         [764.4936, 759.9948, 759.9948, ..., 759.9948, 759.9948,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 759.9948,
          764.4936],
         ...,
         [764.4936, 759.9948, 762.452 , ..., 763.452 , 760.9948,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 760.9948,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 759.9948,
          764.4936]],

        [[764.4936, 764.4936, 764.4936, ..., 764.4936, 764.4936,
          764.4936],
         [764.4936, 759.9948, 759.9948, ..., 759.9948, 759.9948,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 759.9948,
          764.4936],
         ...,
         [764.4936, 759.9948, 762.452 , ..., 762.4936, 760.452 ,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 760.452 ,
          764.4936],
         [764.4936, 759.9948, 762.452 , ..., 762.452 , 759.9948,
          764.4936]],

        ...,

        [[765.    , 765.    , 765.    , ..., 765.    , 765.    ,
          765.    ],
         [765.    , 759.    , 759.    , ..., 759.    , 759.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 759.    ,
          765.    ],
         ...,
         [765.    , 759.    , 762.    , ..., 763.    , 760.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 760.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 759.    ,
          765.    ]],

        [[765.    , 765.    , 765.    , ..., 765.    , 765.    ,
          765.    ],
         [765.    , 759.    , 759.    , ..., 759.    , 759.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 759.    ,
          765.    ],
         ...,
         [765.    , 759.    , 762.    , ..., 763.    , 760.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 760.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 759.    ,
          765.    ]],

        [[765.    , 765.    , 765.    , ..., 765.    , 765.    ,
          765.    ],
         [765.    , 759.    , 759.    , ..., 759.    , 759.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 759.    ,
          765.    ],
         ...,
         [765.    , 759.    , 762.    , ..., 763.    , 760.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 760.    ,
          765.    ],
         [765.    , 759.    , 762.    , ..., 762.    , 759.    ,
          765.    ]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [4, 14], 'to': [3]}
tf node:
{'name': 'conv2d', 'output': array([[[[1757187. , 1757188.5, 1747198.5, ..., 1754626. , 1755657. ,
          1171968. ],
         [1756678.5, 1739267. , 1656572.5, ..., 1691392. , 1747984. ,
          1171202. ],
         [1744894.5, 1654012. , 1507327. , ..., 1537788.5, 1686790.5,
          1168380. ],
         ...,
         [1749511.5, 1704958.5, 1682686.5, ..., 1621253.5, 1731085.5,
          1171202. ],
         [1755657. , 1752585. , 1728000. , ..., 1722376.5, 1753614. ,
          1171203. ],
         [1170438. , 1170441. , 1167364.5, ..., 1169417. , 1169163.5,
           780546.5]],

        [[1757187. , 1757188.5, 1747198.5, ..., 1754626. , 1755657. ,
          1171968. ],
         [1756678.5, 1739267. , 1656572.5, ..., 1691392. , 1747984. ,
          1171202. ],
         [1744894.5, 1654012. , 1507327. , ..., 1537788.5, 1686790.5,
          1168380. ],
         ...,
         [1749511.5, 1704958.5, 1682686.5, ..., 1621253.5, 1731085.5,
          1171202. ],
         [1755657. , 1752585. , 1728000. , ..., 1722376.5, 1753614. ,
          1171203. ],
         [1170438. , 1170441. , 1167364.5, ..., 1169417. , 1169163.5,
           780546.5]],

        [[1757187. , 1757188.5, 1747198.5, ..., 1754626. , 1755657. ,
          1171968. ],
         [1756678.5, 1739267. , 1656572.5, ..., 1691392. , 1747984. ,
          1171202. ],
         [1744894.5, 1654012. , 1507327. , ..., 1537788.5, 1686790.5,
          1168380. ],
         ...,
         [1749511.5, 1704958.5, 1682686.5, ..., 1621253.5, 1731085.5,
          1171202. ],
         [1755657. , 1752585. , 1728000. , ..., 1722376.5, 1753614. ,
          1171203. ],
         [1170438. , 1170441. , 1167364.5, ..., 1169417. , 1169163.5,
           780546.5]],

        ...,

        [[1757187. , 1757188.5, 1747198.5, ..., 1754626. , 1755657. ,
          1171968. ],
         [1756678.5, 1739267. , 1656572.5, ..., 1691392. , 1747984. ,
          1171202. ],
         [1744894.5, 1654012. , 1507327. , ..., 1537788.5, 1686790.5,
          1168380. ],
         ...,
         [1749511.5, 1704958.5, 1682686.5, ..., 1621253.5, 1731085.5,
          1171202. ],
         [1755657. , 1752585. , 1728000. , ..., 1722376.5, 1753614. ,
          1171203. ],
         [1170438. , 1170441. , 1167364.5, ..., 1169417. , 1169163.5,
           780546.5]],

        [[1757187. , 1757188.5, 1747198.5, ..., 1754626. , 1755657. ,
          1171968. ],
         [1756678.5, 1739267. , 1656572.5, ..., 1691392. , 1747984. ,
          1171202. ],
         [1744894.5, 1654012. , 1507327. , ..., 1537788.5, 1686790.5,
          1168380. ],
         ...,
         [1749511.5, 1704958.5, 1682686.5, ..., 1621253.5, 1731085.5,
          1171202. ],
         [1755657. , 1752585. , 1728000. , ..., 1722376.5, 1753614. ,
          1171203. ],
         [1170438. , 1170441. , 1167364.5, ..., 1169417. , 1169163.5,
           780546.5]],

        [[1757187. , 1757188.5, 1747198.5, ..., 1754626. , 1755657. ,
          1171968. ],
         [1756678.5, 1739267. , 1656572.5, ..., 1691392. , 1747984. ,
          1171202. ],
         [1744894.5, 1654012. , 1507327. , ..., 1537788.5, 1686790.5,
          1168380. ],
         ...,
         [1749511.5, 1704958.5, 1682686.5, ..., 1621253.5, 1731085.5,
          1171202. ],
         [1755657. , 1752585. , 1728000. , ..., 1722376.5, 1753614. ,
          1171203. ],
         [1170438. , 1170441. , 1167364.5, ..., 1169417. , 1169163.5,
           780546.5]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 16, 16]), 'from': [11], 'to': []}
ms node:
{'name': 'conv2d', 'output': array([[[[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.8 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.8 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.8 , 1756422.5 ]],

        ...,

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.8 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.8 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.8 , 1756422.5 ]]]], dtype=float32), 'output_shape': (1, 256, 16, 16), 'from': [11], 'to': []}
torch node:
{'name': 'conv2d', 'output': array([[[[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.9 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.9 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.9 , 1756422.5 ]],

        ...,

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.9 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.9 , 1756422.5 ]],

        [[ 781822.44, 1171202.8 , 1171969.1 , ..., 1168895.2 ,
          1171458.2 , 1171967.9 ],
         [1170436.4 , 1752594.8 , 1740809.2 , ..., 1698050.1 ,
          1750028.5 , 1755145.5 ],
         [1171202.8 , 1738505.2 , 1649408.2 , ..., 1544701.5 ,
          1688070.2 , 1750789.  ],
         ...,
         [1169410.  , 1700878.2 , 1654016.5 , ..., 1504259.4 ,
          1646079.9 , 1740796.5 ],
         [1170436.4 , 1744912.1 , 1723392.1 , ..., 1607174.9 ,
          1724169.  , 1757188.4 ],
         [1170436.4 , 1753361.1 , 1753353.9 , ..., 1733128.1 ,
          1755914.9 , 1756422.5 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 16, 16]), 'from': [11], 'to': []}

generate models:76

analyse output arrays in iter:252

pre layer res:
9:reshape
{'name': 'reshape', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.],
         [  0.,   0.,   0., ...,   0.,   0.,   0.]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 32, 32]), 'from': [8], 'to': [1]}
tf node:
{'name': 'conv2d', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [9], 'to': [2]}
ms node:
{'name': 'conv2d', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [9], 'to': [2]}
torch node:
{'name': 'conv2d', 'output': array([[[[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        ...,

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]],

        [[-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [9], 'to': [2]}

generate models:91

analyse output arrays in iter:259

pre layer res:
11:exp
{'name': 'exp', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [8], 'to': [19]}
tf node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [11], 'to': [21]}
ms node:
{'name': 'log', 'output': array([[[[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        ...,

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [11], 'to': [21]}
torch node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [11], 'to': [21]}

generate models:95

analyse the exceptions in iter:294
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])]}
Given groups=1, weight of size [512, 64, 1, 1], expected input[1, 3, 32, 32] to have 64 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 64, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:111

analyse the exceptions in iter:318
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[177., 187., 206.,  ..., 152., 148., 142.],
           [178., 162., 185.,  ..., 153., 147., 140.],
           [199., 181., 183.,  ..., 151., 146., 140.],
           ...,
           [ 82.,  81.,  84.,  ...,  11.,   9.,  19.],
           [ 77.,  78.,  81.,  ...,  29.,  25.,  24.],
           [ 75.,  75.,  79.,  ...,  37.,  32.,  28.]],

          [[160., 163., 196.,  ..., 161., 159., 156.],
           [148., 106., 137.,  ..., 162., 157., 155.],
           [184., 118.,  95.,  ..., 160., 157., 155.],
           ...,
           [141., 140., 143.,  ...,  36.,  40.,  65.],
           [138., 139., 142.,  ...,  78.,  79.,  80.],
           [140., 138., 142.,  ...,  91.,  88.,  86.]],

          [[168., 166., 192.,  ..., 176., 173., 169.],
           [149.,  92., 121.,  ..., 177., 171., 168.],
           [183., 105.,  80.,  ..., 175., 172., 168.],
           ...,
           [ 92.,  91.,  94.,  ...,  15.,  15.,  30.],
           [ 87.,  88.,  91.,  ...,  39.,  37.,  35.],
           [ 85.,  85.,  89.,  ...,  44.,  41.,  38.]]]]])}
Given groups=1, weight of size [512, 256, 1, 1], expected input[1, 3, 32, 32] to have 256 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[1.77000000e+002, 1.87000000e+002, 2.06000000e+002 ... 1.52000000e+002, 1.48000000e+002, 1.42000000e+002],
    [1.78000000e+002, 1.62000000e+002, 1.85000000e+002 ... 1.53000000e+002, 1.47000000e+002, 1.40000000e+002],
    [1.99000000e+002, 1.81000000e+002, 1.83000000e+002 ... 1.51000000e+002, 1.46000000e+002, 1.40000000e+002],
    ...
    [8.20000000e+001, 8.10000000e+001, 8.40000000e+001 ... 1.10000000e+001, 9.00000000e+000, 1.90000000e+001],
    [7.70000000e+001, 7.80000000e+001, 8.10000000e+001 ... 2.90000000e+001, 2.50000000e+001, 2.40000000e+001],
    [7.50000000e+001, 7.50000000e+001, 7.90000000e+001 ... 3.70000000e+001, 3.20000000e+001, 2.80000000e+001]],
   [[1.60000000e+002, 1.63000000e+002, 1.96000000e+002 ... 1.61000000e+002, 1.59000000e+002, 1.56000000e+002],
    [1.48000000e+002, 1.06000000e+002, 1.37000000e+002 ... 1.62000000e+002, 1.57000000e+002, 1.55000000e+002],
    [1.84000000e+002, 1.18000000e+002, 9.50000000e+001 ... 1.60000000e+002, 1.57000000e+002, 1.55000000e+002],
    ...
    [1.41000000e+002, 1.40000000e+002, 1.43000000e+002 ... 3.60000000e+001, 4.00000000e+001, 6.50000000e+001],
    [1.38000000e+002, 1.39000000e+002, 1.42000000e+002 ... 7.80000000e+001, 7.90000000e+001, 8.00000000e+001],
    [1.40000000e+002, 1.38000000e+002, 1.42000000e+002 ... 9.10000000e+001, 8.80000000e+001, 8.60000000e+001]],
   [[1.68000000e+002, 1.66000000e+002, 1.92000000e+002 ... 1.76000000e+002, 1.73000000e+002, 1.69000000e+002],
    [1.49000000e+002, 9.20000000e+001, 1.21000000e+002 ... 1.77000000e+002, 1.71000000e+002, 1.68000000e+002],
    [1.83000000e+002, 1.05000000e+002, 8.00000000e+001 ... 1.75000000e+002, 1.72000000e+002, 1.68000000e+002],
    ...
    [9.20000000e+001, 9.10000000e+001, 9.40000000e+001 ... 1.50000000e+001, 1.50000000e+001, 3.00000000e+001],
    [8.70000000e+001, 8.80000000e+001, 9.10000000e+001 ... 3.90000000e+001, 3.70000000e+001, 3.50000000e+001],
    [8.50000000e+001, 8.50000000e+001, 8.90000000e+001 ... 4.40000000e+001, 4.10000000e+001, 3.80000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:121

analyse the exceptions in iter:325
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 36.,  36.,  42.,  ...,  45.,  43.,  41.],
           [ 27.,  34.,  44.,  ...,  46.,  42.,  39.],
           [ 20.,  25.,  33.,  ...,  49.,  47.,  43.],
           ...,
           [ 53.,  47.,  44.,  ..., 109., 129., 147.],
           [ 60.,  57.,  54.,  ..., 145., 147., 127.],
           [ 67.,  67.,  66.,  ..., 131., 115., 114.]],

          [[ 50.,  50.,  56.,  ...,  65.,  62.,  60.],
           [ 37.,  43.,  55.,  ...,  66.,  62.,  59.],
           [ 27.,  32.,  43.,  ...,  69.,  67.,  63.],
           ...,
           [ 67.,  61.,  57.,  ..., 125., 145., 163.],
           [ 75.,  72.,  70.,  ..., 161., 163., 143.],
           [ 80.,  81.,  80.,  ..., 147., 131., 130.]],

          [[ 84.,  85.,  91.,  ...,  68.,  66.,  64.],
           [ 69.,  78.,  91.,  ...,  67.,  64.,  61.],
           [ 53.,  58.,  71.,  ...,  69.,  67.,  63.],
           ...,
           [109., 103.,  99.,  ..., 150., 170., 188.],
           [116., 113., 107.,  ..., 187., 188., 168.],
           [123., 121., 120.,  ..., 173., 157., 156.]]]]])}
Given groups=1, weight of size [256, 512, 3, 3], expected input[1, 3, 32, 32] to have 512 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[3.60000000e+001, 3.60000000e+001, 4.20000000e+001 ... 4.50000000e+001, 4.30000000e+001, 4.10000000e+001],
    [2.70000000e+001, 3.40000000e+001, 4.40000000e+001 ... 4.60000000e+001, 4.20000000e+001, 3.90000000e+001],
    [2.00000000e+001, 2.50000000e+001, 3.30000000e+001 ... 4.90000000e+001, 4.70000000e+001, 4.30000000e+001],
    ...
    [5.30000000e+001, 4.70000000e+001, 4.40000000e+001 ... 1.09000000e+002, 1.29000000e+002, 1.47000000e+002],
    [6.00000000e+001, 5.70000000e+001, 5.40000000e+001 ... 1.45000000e+002, 1.47000000e+002, 1.27000000e+002],
    [6.70000000e+001, 6.70000000e+001, 6.60000000e+001 ... 1.31000000e+002, 1.15000000e+002, 1.14000000e+002]],
   [[5.00000000e+001, 5.00000000e+001, 5.60000000e+001 ... 6.50000000e+001, 6.20000000e+001, 6.00000000e+001],
    [3.70000000e+001, 4.30000000e+001, 5.50000000e+001 ... 6.60000000e+001, 6.20000000e+001, 5.90000000e+001],
    [2.70000000e+001, 3.20000000e+001, 4.30000000e+001 ... 6.90000000e+001, 6.70000000e+001, 6.30000000e+001],
    ...
    [6.70000000e+001, 6.10000000e+001, 5.70000000e+001 ... 1.25000000e+002, 1.45000000e+002, 1.63000000e+002],
    [7.50000000e+001, 7.20000000e+001, 7.00000000e+001 ... 1.61000000e+002, 1.63000000e+002, 1.43000000e+002],
    [8.00000000e+001, 8.10000000e+001, 8.00000000e+001 ... 1.47000000e+002, 1.31000000e+002, 1.30000000e+002]],
   [[8.40000000e+001, 8.50000000e+001, 9.10000000e+001 ... 6.80000000e+001, 6.60000000e+001, 6.40000000e+001],
    [6.90000000e+001, 7.80000000e+001, 9.10000000e+001 ... 6.70000000e+001, 6.40000000e+001, 6.10000000e+001],
    [5.30000000e+001, 5.80000000e+001, 7.10000000e+001 ... 6.90000000e+001, 6.70000000e+001, 6.30000000e+001],
    ...
    [1.09000000e+002, 1.03000000e+002, 9.90000000e+001 ... 1.50000000e+002, 1.70000000e+002, 1.88000000e+002],
    [1.16000000e+002, 1.13000000e+002, 1.07000000e+002 ... 1.87000000e+002, 1.88000000e+002, 1.68000000e+002],
    [1.23000000e+002, 1.21000000e+002, 1.20000000e+002 ... 1.73000000e+002, 1.57000000e+002, 1.56000000e+002]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:123

analyse the exceptions in iter:326
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[-0.4616,  0.9123,  0.6440,  ...,  1.0000,  0.1870,  0.2251],
          [ 0.1137,  0.8542, -0.9371,  ...,  0.6321, -0.7772,  0.4850],
          [ 0.9896, -0.1007,  0.7087,  ..., -0.1049,  0.5054, -0.6020],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.4616,  0.9123,  0.6440,  ...,  1.0000,  0.1870,  0.2251],
          [ 0.1137,  0.8542, -0.9371,  ...,  0.6321, -0.7772,  0.4850],
          [ 0.9896, -0.1007,  0.7087,  ..., -0.1049,  0.5054, -0.6020],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.4616,  0.9123,  0.6440,  ...,  1.0000,  0.1870,  0.2251],
          [ 0.1137,  0.8542, -0.9371,  ...,  0.6321, -0.7772,  0.4850],
          [ 0.9896, -0.1007,  0.7087,  ..., -0.1049,  0.5054, -0.6020],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         ...,

         [[-0.4616,  0.9123,  0.6440,  ...,  1.0000,  0.1870,  0.2251],
          [ 0.1137,  0.8542, -0.9371,  ...,  0.6321, -0.7772,  0.4850],
          [ 0.9896, -0.1007,  0.7087,  ..., -0.1049,  0.5054, -0.6020],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.4616,  0.9123,  0.6440,  ...,  1.0000,  0.1870,  0.2251],
          [ 0.1137,  0.8542, -0.9371,  ...,  0.6321, -0.7772,  0.4850],
          [ 0.9896, -0.1007,  0.7087,  ..., -0.1049,  0.5054, -0.6020],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.4616,  0.9123,  0.6440,  ...,  1.0000,  0.1870,  0.2251],
          [ 0.1137,  0.8542, -0.9371,  ...,  0.6321, -0.7772,  0.4850],
          [ 0.9896, -0.1007,  0.7087,  ..., -0.1049,  0.5054, -0.6020],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],
       grad_fn=<TransposeBackward0>)]}
Given groups=1, weight of size [512, 512, 1, 1], expected input[1, 128, 32, 32] to have 512 channels, but got 128 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 128, 32, 32], dtype=Float32, value=
[[[[-4.61594373e-001, 9.12258208e-001, 6.43951356e-001 ... 9.99953330e-001, 1.86963439e-001, 2.25085959e-001],
   [1.13711834e-001, 8.54235709e-001, -9.37128544e-001 ... 6.32052958e-001, -7.77214944e-001, 4.85011309e-001],
   [9.89601314e-001, -1.00749828e-001, 7.08680391e-001 ... -1.04913481e-001, 5.05433977e-001, -6.02023959e-001],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[-4.61594373e-001, 9.12258208e-001, 6.43951356e-001 ... 9.99953330e-001, 1.86963439e-001, 2.25085959e-001],
   [1.13711834e-001, 8.54235709e-001, -9.37128544e-001 ... 6.32052958e-001, -7.77214944e-001, 4.85011309e-001],
   [9.89601314e-001, -1.00749828e-001, 7.08680391e-001 ... -1.04913481e-001, 5.05433977e-001, -6.02023959e-001],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[-4.61594373e-001, 9.12258208e-001, 6.43951356e-001 ... 9.99953330e-001, 1.86963439e-001, 2.25085959e-001],
   [1.13711834e-001, 8.54235709e-001, -9.37128544e-001 ... 6.32052958e-001, -7.77214944e-001, 4.85011309e-001],
   [9.89601314e-001, -1.00749828e-001, 7.08680391e-001 ... -1.04913481e-001, 5.05433977e-001, -6.02023959e-001],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  ...
  [[-4.61594373e-001, 9.12258208e-001, 6.43951356e-001 ... 9.99953330e-001, 1.86963439e-001, 2.25085959e-001],
   [1.13711834e-001, 8.54235709e-001, -9.37128544e-001 ... 6.32052958e-001, -7.77214944e-001, 4.85011309e-001],
   [9.89601314e-001, -1.00749828e-001, 7.08680391e-001 ... -1.04913481e-001, 5.05433977e-001, -6.02023959e-001],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[-4.61594373e-001, 9.12258208e-001, 6.43951356e-001 ... 9.99953330e-001, 1.86963439e-001, 2.25085959e-001],
   [1.13711834e-001, 8.54235709e-001, -9.37128544e-001 ... 6.32052958e-001, -7.77214944e-001, 4.85011309e-001],
   [9.89601314e-001, -1.00749828e-001, 7.08680391e-001 ... -1.04913481e-001, 5.05433977e-001, -6.02023959e-001],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[-4.61594373e-001, 9.12258208e-001, 6.43951356e-001 ... 9.99953330e-001, 1.86963439e-001, 2.25085959e-001],
   [1.13711834e-001, 8.54235709e-001, -9.37128544e-001 ... 6.32052958e-001, -7.77214944e-001, 4.85011309e-001],
   [9.89601314e-001, -1.00749828e-001, 7.08680391e-001 ... -1.04913481e-001, 5.05433977e-001, -6.02023959e-001],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 128, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:124

analyse the exceptions in iter:333
torch exception:
{'id': 0, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[216., 202., 176.,  ..., 131., 139., 144.],
           [174., 192., 171.,  ..., 149., 175., 165.],
           [153., 216., 212.,  ..., 176., 155., 173.],
           ...,
           [110.,  91.,  95.,  ...,  42.,  56.,  76.],
           [128.,  95.,  84.,  ...,  39.,  52.,  60.],
           [ 98.,  85.,  83.,  ...,  41.,  45.,  53.]],

          [[216., 204., 181.,  ..., 133., 141., 148.],
           [177., 194., 175.,  ..., 148., 175., 166.],
           [158., 218., 216.,  ..., 172., 153., 172.],
           ...,
           [104.,  93., 102.,  ...,  47.,  61.,  80.],
           [130., 101.,  91.,  ...,  44.,  57.,  65.],
           [108.,  92.,  89.,  ...,  45.,  50.,  58.]],

          [[216., 205., 176.,  ..., 117., 126., 131.],
           [160., 194., 178.,  ..., 137., 164., 156.],
           [130., 215., 219.,  ..., 166., 144., 169.],
           ...,
           [ 81.,  53.,  66.,  ...,  48.,  61.,  82.],
           [105.,  61.,  53.,  ...,  47.,  59.,  69.],
           [ 79.,  57.,  52.,  ...,  49.,  54.,  62.]]]]])}
Given groups=1, weight of size [512, 128, 1, 1], expected input[1, 3, 32, 32] to have 128 channels, but got 3 channels instead
mindspore exception:
{'id': 0, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': Tensor(shape=[1, 1, 3, 32, 32], dtype=Float32, value=
[[[[[2.16000000e+002, 2.02000000e+002, 1.76000000e+002 ... 1.31000000e+002, 1.39000000e+002, 1.44000000e+002],
    [1.74000000e+002, 1.92000000e+002, 1.71000000e+002 ... 1.49000000e+002, 1.75000000e+002, 1.65000000e+002],
    [1.53000000e+002, 2.16000000e+002, 2.12000000e+002 ... 1.76000000e+002, 1.55000000e+002, 1.73000000e+002],
    ...
    [1.10000000e+002, 9.10000000e+001, 9.50000000e+001 ... 4.20000000e+001, 5.60000000e+001, 7.60000000e+001],
    [1.28000000e+002, 9.50000000e+001, 8.40000000e+001 ... 3.90000000e+001, 5.20000000e+001, 6.00000000e+001],
    [9.80000000e+001, 8.50000000e+001, 8.30000000e+001 ... 4.10000000e+001, 4.50000000e+001, 5.30000000e+001]],
   [[2.16000000e+002, 2.04000000e+002, 1.81000000e+002 ... 1.33000000e+002, 1.41000000e+002, 1.48000000e+002],
    [1.77000000e+002, 1.94000000e+002, 1.75000000e+002 ... 1.48000000e+002, 1.75000000e+002, 1.66000000e+002],
    [1.58000000e+002, 2.18000000e+002, 2.16000000e+002 ... 1.72000000e+002, 1.53000000e+002, 1.72000000e+002],
    ...
    [1.04000000e+002, 9.30000000e+001, 1.02000000e+002 ... 4.70000000e+001, 6.10000000e+001, 8.00000000e+001],
    [1.30000000e+002, 1.01000000e+002, 9.10000000e+001 ... 4.40000000e+001, 5.70000000e+001, 6.50000000e+001],
    [1.08000000e+002, 9.20000000e+001, 8.90000000e+001 ... 4.50000000e+001, 5.00000000e+001, 5.80000000e+001]],
   [[2.16000000e+002, 2.05000000e+002, 1.76000000e+002 ... 1.17000000e+002, 1.26000000e+002, 1.31000000e+002],
    [1.60000000e+002, 1.94000000e+002, 1.78000000e+002 ... 1.37000000e+002, 1.64000000e+002, 1.56000000e+002],
    [1.30000000e+002, 2.15000000e+002, 2.19000000e+002 ... 1.66000000e+002, 1.44000000e+002, 1.69000000e+002],
    ...
    [8.10000000e+001, 5.30000000e+001, 6.60000000e+001 ... 4.80000000e+001, 6.10000000e+001, 8.20000000e+001],
    [1.05000000e+002, 6.10000000e+001, 5.30000000e+001 ... 4.70000000e+001, 5.90000000e+001, 6.90000000e+001],
    [7.90000000e+001, 5.70000000e+001, 5.20000000e+001 ... 4.90000000e+001, 5.40000000e+001, 6.20000000e+001]]]]])}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 128, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:127

analyse the exceptions in iter:345
torch exception:
{'id': 2, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])]}
Given groups=1, weight of size [512, 1024, 1, 1], expected input[1, 64, 32, 32] to have 1024 channels, but got 64 channels instead
mindspore exception:
{'id': 2, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 64, 32, 32], dtype=Float32, value=
[[[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  ...
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],
  [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   ...
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
   [0.00000000e+000, 0.00000000e+000, 0.00000000e+000 ... 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 1024, but got 'C_in' of input 'x' shape: 64, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:133

analyse output arrays in iter:367

pre layer res:
21:pad
{'name': 'pad', 'output': array([[1.0401667e+10, 1.0401668e+10, 1.0401608e+10, ..., 0.0000000e+00,
        0.0000000e+00, 0.0000000e+00]], dtype=float32), 'output_shape': TensorShape([1, 131072]), 'from': [20], 'to': [23]}
tf node:
{'name': 'cos', 'output': array([[ 0.8270862 ,  0.72751886, -0.705423  , ...,  1.        ,
         1.        ,  1.        ]], dtype=float32), 'output_shape': TensorShape([1, 131072]), 'from': [21], 'to': [22]}
ms node:
{'name': 'cos', 'output': array([[ 0.82708615,  0.82708615, -0.705423  , ...,  1.        ,
         1.        ,  1.        ]], dtype=float32), 'output_shape': (1, 131072), 'from': [21], 'to': [22]}
torch node:
{'name': 'cos', 'output': array([[ 0.82708615,  0.82708615, -0.705423  , ...,  1.        ,
         1.        ,  1.        ]], dtype=float32), 'output_shape': torch.Size([1, 131072]), 'from': [21], 'to': [22]}

generate models:141

analyse the exceptions in iter:426
torch exception:
{'id': 5, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          ...,
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],

         [[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          ...,
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],

         [[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          ...,
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],

         ...,

         [[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          ...,
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],

         [[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          ...,
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],

         [[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          ...,
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]]])]}
Given groups=1, weight of size [256, 256, 1, 1], expected input[1, 64, 32, 32] to have 256 channels, but got 64 channels instead
mindspore exception:
{'id': 5, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 64, 32, 32], dtype=Float32, value=
[[[[5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   ...
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001]],
  [[5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   ...
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001]],
  [[5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   ...
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001]],
  ...
  [[5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   ...
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001]],
  [[5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   ...
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001]],
  [[5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   ...
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001],
   [5.00000000e-001, 5.00000000e-001, 5.00000000e-001 ... 5.00000000e-001, 5.00000000e-001, 5.00000000e-001]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 256, but got 'C_in' of input 'x' shape: 64, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:166

analyse the exceptions in iter:432
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[ 689.,  986.,  940.,  ..., 1162., 1268.,  887.],
          [ 928., 1344., 1289.,  ..., 1940., 2228., 1610.],
          [ 741., 1088., 1055.,  ..., 2091., 2560., 1909.],
          ...,
          [1198., 1823., 1892.,  ..., 1610., 1702., 1168.],
          [1168., 1785., 1865.,  ..., 1713., 1813., 1243.],
          [ 770., 1181., 1240.,  ..., 1149., 1233.,  853.]],

         [[ 689.,  986.,  940.,  ..., 1162., 1268.,  887.],
          [ 928., 1344., 1289.,  ..., 1940., 2228., 1610.],
          [ 741., 1088., 1055.,  ..., 2091., 2560., 1909.],
          ...,
          [1198., 1823., 1892.,  ..., 1610., 1702., 1168.],
          [1168., 1785., 1865.,  ..., 1713., 1813., 1243.],
          [ 770., 1181., 1240.,  ..., 1149., 1233.,  853.]],

         [[ 689.,  986.,  940.,  ..., 1162., 1268.,  887.],
          [ 928., 1344., 1289.,  ..., 1940., 2228., 1610.],
          [ 741., 1088., 1055.,  ..., 2091., 2560., 1909.],
          ...,
          [1198., 1823., 1892.,  ..., 1610., 1702., 1168.],
          [1168., 1785., 1865.,  ..., 1713., 1813., 1243.],
          [ 770., 1181., 1240.,  ..., 1149., 1233.,  853.]],

         ...,

         [[ 689.,  986.,  940.,  ..., 1162., 1268.,  887.],
          [ 928., 1344., 1289.,  ..., 1940., 2228., 1610.],
          [ 741., 1088., 1055.,  ..., 2091., 2560., 1909.],
          ...,
          [1198., 1823., 1892.,  ..., 1610., 1702., 1168.],
          [1168., 1785., 1865.,  ..., 1713., 1813., 1243.],
          [ 770., 1181., 1240.,  ..., 1149., 1233.,  853.]],

         [[ 689.,  986.,  940.,  ..., 1162., 1268.,  887.],
          [ 928., 1344., 1289.,  ..., 1940., 2228., 1610.],
          [ 741., 1088., 1055.,  ..., 2091., 2560., 1909.],
          ...,
          [1198., 1823., 1892.,  ..., 1610., 1702., 1168.],
          [1168., 1785., 1865.,  ..., 1713., 1813., 1243.],
          [ 770., 1181., 1240.,  ..., 1149., 1233.,  853.]],

         [[ 689.,  986.,  940.,  ..., 1162., 1268.,  887.],
          [ 928., 1344., 1289.,  ..., 1940., 2228., 1610.],
          [ 741., 1088., 1055.,  ..., 2091., 2560., 1909.],
          ...,
          [1198., 1823., 1892.,  ..., 1610., 1702., 1168.],
          [1168., 1785., 1865.,  ..., 1713., 1813., 1243.],
          [ 770., 1181., 1240.,  ..., 1149., 1233.,  853.]]]],
       grad_fn=<ConvolutionBackward0>)]}
Given groups=1, weight of size [1024, 1024, 1, 1], expected input[1, 256, 32, 32] to have 1024 channels, but got 256 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 256, 32, 32], dtype=Float32, value=
[[[[6.89000000e+002, 9.86000000e+002, 9.40000000e+002 ... 1.16200000e+003, 1.26800000e+003, 8.87000000e+002],
   [9.28000000e+002, 1.34400000e+003, 1.28900000e+003 ... 1.94000000e+003, 2.22800000e+003, 1.61000000e+003],
   [7.41000000e+002, 1.08800000e+003, 1.05500000e+003 ... 2.09100000e+003, 2.56000000e+003, 1.90900000e+003],
   ...
   [1.19800000e+003, 1.82300000e+003, 1.89200000e+003 ... 1.61000000e+003, 1.70200000e+003, 1.16800000e+003],
   [1.16800000e+003, 1.78500000e+003, 1.86500000e+003 ... 1.71300000e+003, 1.81300000e+003, 1.24300000e+003],
   [7.70000000e+002, 1.18100000e+003, 1.24000000e+003 ... 1.14900000e+003, 1.23300000e+003, 8.53000000e+002]],
  [[6.89000000e+002, 9.86000000e+002, 9.40000000e+002 ... 1.16200000e+003, 1.26800000e+003, 8.87000000e+002],
   [9.28000000e+002, 1.34400000e+003, 1.28900000e+003 ... 1.94000000e+003, 2.22800000e+003, 1.61000000e+003],
   [7.41000000e+002, 1.08800000e+003, 1.05500000e+003 ... 2.09100000e+003, 2.56000000e+003, 1.90900000e+003],
   ...
   [1.19800000e+003, 1.82300000e+003, 1.89200000e+003 ... 1.61000000e+003, 1.70200000e+003, 1.16800000e+003],
   [1.16800000e+003, 1.78500000e+003, 1.86500000e+003 ... 1.71300000e+003, 1.81300000e+003, 1.24300000e+003],
   [7.70000000e+002, 1.18100000e+003, 1.24000000e+003 ... 1.14900000e+003, 1.23300000e+003, 8.53000000e+002]],
  [[6.89000000e+002, 9.86000000e+002, 9.40000000e+002 ... 1.16200000e+003, 1.26800000e+003, 8.87000000e+002],
   [9.28000000e+002, 1.34400000e+003, 1.28900000e+003 ... 1.94000000e+003, 2.22800000e+003, 1.61000000e+003],
   [7.41000000e+002, 1.08800000e+003, 1.05500000e+003 ... 2.09100000e+003, 2.56000000e+003, 1.90900000e+003],
   ...
   [1.19800000e+003, 1.82300000e+003, 1.89200000e+003 ... 1.61000000e+003, 1.70200000e+003, 1.16800000e+003],
   [1.16800000e+003, 1.78500000e+003, 1.86500000e+003 ... 1.71300000e+003, 1.81300000e+003, 1.24300000e+003],
   [7.70000000e+002, 1.18100000e+003, 1.24000000e+003 ... 1.14900000e+003, 1.23300000e+003, 8.53000000e+002]],
  ...
  [[6.89000000e+002, 9.86000000e+002, 9.40000000e+002 ... 1.16200000e+003, 1.26800000e+003, 8.87000000e+002],
   [9.28000000e+002, 1.34400000e+003, 1.28900000e+003 ... 1.94000000e+003, 2.22800000e+003, 1.61000000e+003],
   [7.41000000e+002, 1.08800000e+003, 1.05500000e+003 ... 2.09100000e+003, 2.56000000e+003, 1.90900000e+003],
   ...
   [1.19800000e+003, 1.82300000e+003, 1.89200000e+003 ... 1.61000000e+003, 1.70200000e+003, 1.16800000e+003],
   [1.16800000e+003, 1.78500000e+003, 1.86500000e+003 ... 1.71300000e+003, 1.81300000e+003, 1.24300000e+003],
   [7.70000000e+002, 1.18100000e+003, 1.24000000e+003 ... 1.14900000e+003, 1.23300000e+003, 8.53000000e+002]],
  [[6.89000000e+002, 9.86000000e+002, 9.40000000e+002 ... 1.16200000e+003, 1.26800000e+003, 8.87000000e+002],
   [9.28000000e+002, 1.34400000e+003, 1.28900000e+003 ... 1.94000000e+003, 2.22800000e+003, 1.61000000e+003],
   [7.41000000e+002, 1.08800000e+003, 1.05500000e+003 ... 2.09100000e+003, 2.56000000e+003, 1.90900000e+003],
   ...
   [1.19800000e+003, 1.82300000e+003, 1.89200000e+003 ... 1.61000000e+003, 1.70200000e+003, 1.16800000e+003],
   [1.16800000e+003, 1.78500000e+003, 1.86500000e+003 ... 1.71300000e+003, 1.81300000e+003, 1.24300000e+003],
   [7.70000000e+002, 1.18100000e+003, 1.24000000e+003 ... 1.14900000e+003, 1.23300000e+003, 8.53000000e+002]],
  [[6.89000000e+002, 9.86000000e+002, 9.40000000e+002 ... 1.16200000e+003, 1.26800000e+003, 8.87000000e+002],
   [9.28000000e+002, 1.34400000e+003, 1.28900000e+003 ... 1.94000000e+003, 2.22800000e+003, 1.61000000e+003],
   [7.41000000e+002, 1.08800000e+003, 1.05500000e+003 ... 2.09100000e+003, 2.56000000e+003, 1.90900000e+003],
   ...
   [1.19800000e+003, 1.82300000e+003, 1.89200000e+003 ... 1.61000000e+003, 1.70200000e+003, 1.16800000e+003],
   [1.16800000e+003, 1.78500000e+003, 1.86500000e+003 ... 1.71300000e+003, 1.81300000e+003, 1.24300000e+003],
   [7.70000000e+002, 1.18100000e+003, 1.24000000e+003 ... 1.14900000e+003, 1.23300000e+003, 8.53000000e+002]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 1024, but got 'C_in' of input 'x' shape: 256, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:170

analyse output arrays in iter:435

pre layer res:
9:add
{'name': 'add', 'output': array([[[[           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
          6.83767114e+30, 2.51543870e+30,            inf],
         ...,
         [           inf,            inf,            inf, ...,
          1.50609736e+35,            inf,            inf],
         [           inf,            inf,            inf, ...,
          1.95729621e+11, 7.49841698e+33,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf]],

        [[           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
          2.51543870e+30, 7.49841698e+33,            inf],
         ...,
         [           inf,            inf,            inf, ...,
          2.75851355e+33,            inf,            inf],
         [           inf,            inf,            inf, ...,
          2.64891228e+10, 7.49841698e+33,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf]],

        [[           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf],
         [           inf,            inf,            inf, ...,
          3.18559313e+16, 1.73927498e+18,            inf],
         ...,
         [           inf,            inf, 1.01480034e+33, ...,
          1.01480034e+33,            inf,            inf],
         [           inf,            inf,            inf, ...,
          2.64891228e+10, 1.37338306e+32,            inf],
         [           inf,            inf,            inf, ...,
                     inf,            inf,            inf]],

        ...,

        [[1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         ...,
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00]],

        [[1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         ...,
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00]],

        [[1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         ...,
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00],
         [1.03125000e+00, 1.03125000e+00, 1.03125000e+00, ...,
          1.03125000e+00, 1.03125000e+00, 1.03125000e+00]]]],
      dtype=float32), 'output_shape': TensorShape([1, 2048, 32, 32]), 'from': [4, 17], 'to': [18]}
tf node:
{'name': 'softmax', 'output': array([[[[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        [[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        [[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        ...,

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]],

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]],

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]]]],
      dtype=float32), 'output_shape': TensorShape([1, 2048, 32, 32]), 'from': [9], 'to': [13]}
ms node:
{'name': 'softmax', 'output': array([[[[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ..., 0.     , 0.     ,     nan],
         ...,
         [    nan,     nan,     nan, ..., 0.     ,     nan,     nan],
         [    nan,     nan,     nan, ..., 0.     , 0.     ,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        [[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ..., 0.     , 0.     ,     nan],
         ...,
         [    nan,     nan,     nan, ..., 0.     ,     nan,     nan],
         [    nan,     nan,     nan, ..., 0.     , 0.     ,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        [[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ..., 0.     , 0.     ,     nan],
         ...,
         [    nan,     nan, 0.     , ..., 0.     ,     nan,     nan],
         [    nan,     nan,     nan, ..., 0.     , 0.     ,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        ...,

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]],

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]],

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]]]],
      dtype=float32), 'output_shape': (1, 2048, 32, 32), 'from': [9], 'to': [13]}
torch node:
{'name': 'softmax', 'output': array([[[[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        [[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        [[    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         ...,
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan],
         [    nan,     nan,     nan, ...,     nan,     nan,     nan]],

        ...,

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]],

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]],

        [[0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         ...,
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125],
         [0.03125, 0.03125, 0.03125, ..., 0.03125, 0.03125, 0.03125]]]],
      dtype=float32), 'output_shape': torch.Size([1, 2048, 32, 32]), 'from': [9], 'to': [13]}

generate models:171

analyse the exceptions in iter:474
torch exception:
{'id': 1, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[27., 25., 32.,  ..., 11., 13., 15.],
          [20., 25., 31.,  ...,  9., 10., 11.],
          [15., 24., 31.,  ...,  8.,  9., 13.],
          ...,
          [15., 15., 12.,  ..., 14., 11., 12.],
          [12., 14., 14.,  ..., 10., 12., 11.],
          [14., 14., 14.,  ...,  5.,  6.,  6.]],

         [[21., 17., 24.,  ...,  5.,  6.,  9.],
          [15., 19., 24.,  ...,  3.,  4.,  5.],
          [12., 21., 26.,  ...,  2.,  3.,  7.],
          ...,
          [ 9.,  9.,  6.,  ..., 13., 10., 12.],
          [ 6.,  8.,  8.,  ..., 10., 11., 11.],
          [ 9.,  9.,  8.,  ...,  6.,  6.,  5.]],

         [[12.,  8., 14.,  ...,  5.,  6.,  9.],
          [ 9., 11., 15.,  ...,  3.,  4.,  5.],
          [ 7., 15., 19.,  ...,  2.,  3.,  7.],
          ...,
          [ 9.,  9.,  6.,  ..., 14., 13., 16.],
          [ 6.,  8.,  8.,  ..., 11., 14., 15.],
          [ 7.,  7.,  7.,  ...,  6.,  8.,  8.]]]])]}
Given groups=1, weight of size [1024, 1024, 1, 1], expected input[1, 3, 32, 32] to have 1024 channels, but got 3 channels instead
mindspore exception:
{'id': 1, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 3, 32, 32], dtype=Float32, value=
[[[[2.70000000e+001, 2.50000000e+001, 3.20000000e+001 ... 1.10000000e+001, 1.30000000e+001, 1.50000000e+001],
   [2.00000000e+001, 2.50000000e+001, 3.10000000e+001 ... 9.00000000e+000, 1.00000000e+001, 1.10000000e+001],
   [1.50000000e+001, 2.40000000e+001, 3.10000000e+001 ... 8.00000000e+000, 9.00000000e+000, 1.30000000e+001],
   ...
   [1.50000000e+001, 1.50000000e+001, 1.20000000e+001 ... 1.40000000e+001, 1.10000000e+001, 1.20000000e+001],
   [1.20000000e+001, 1.40000000e+001, 1.40000000e+001 ... 1.00000000e+001, 1.20000000e+001, 1.10000000e+001],
   [1.40000000e+001, 1.40000000e+001, 1.40000000e+001 ... 5.00000000e+000, 6.00000000e+000, 6.00000000e+000]],
  [[2.10000000e+001, 1.70000000e+001, 2.40000000e+001 ... 5.00000000e+000, 6.00000000e+000, 9.00000000e+000],
   [1.50000000e+001, 1.90000000e+001, 2.40000000e+001 ... 3.00000000e+000, 4.00000000e+000, 5.00000000e+000],
   [1.20000000e+001, 2.10000000e+001, 2.60000000e+001 ... 2.00000000e+000, 3.00000000e+000, 7.00000000e+000],
   ...
   [9.00000000e+000, 9.00000000e+000, 6.00000000e+000 ... 1.30000000e+001, 1.00000000e+001, 1.20000000e+001],
   [6.00000000e+000, 8.00000000e+000, 8.00000000e+000 ... 1.00000000e+001, 1.10000000e+001, 1.10000000e+001],
   [9.00000000e+000, 9.00000000e+000, 8.00000000e+000 ... 6.00000000e+000, 6.00000000e+000, 5.00000000e+000]],
  [[1.20000000e+001, 8.00000000e+000, 1.40000000e+001 ... 5.00000000e+000, 6.00000000e+000, 9.00000000e+000],
   [9.00000000e+000, 1.10000000e+001, 1.50000000e+001 ... 3.00000000e+000, 4.00000000e+000, 5.00000000e+000],
   [7.00000000e+000, 1.50000000e+001, 1.90000000e+001 ... 2.00000000e+000, 3.00000000e+000, 7.00000000e+000],
   ...
   [9.00000000e+000, 9.00000000e+000, 6.00000000e+000 ... 1.40000000e+001, 1.30000000e+001, 1.60000000e+001],
   [6.00000000e+000, 8.00000000e+000, 8.00000000e+000 ... 1.10000000e+001, 1.40000000e+001, 1.50000000e+001],
   [7.00000000e+000, 7.00000000e+000, 7.00000000e+000 ... 6.00000000e+000, 8.00000000e+000, 8.00000000e+000]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 1024, but got 'C_in' of input 'x' shape: 3, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:186

analyse the exceptions in iter:479
torch exception:
{'id': 4, 'name': 'conv2d', 'frame_work': 'torch', 'input_datas': [tensor([[[[inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         ...,

         [[inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf]]]], grad_fn=<ExpBackward0>)]}
Given groups=1, weight of size [1024, 512, 1, 1], expected input[1, 1024, 32, 32] to have 512 channels, but got 1024 channels instead
mindspore exception:
{'id': 4, 'name': 'conv2d', 'framework': 'mindspore', 'input_datas': [Tensor(shape=[1, 1024, 32, 32], dtype=Float32, value=
[[[[            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   ...
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf]],
  [[            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   ...
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf]],
  [[            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   ...
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf]],
  ...
  [[            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   ...
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf]],
  [[            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   ...
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf]],
  [[            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   ...
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf],
   [            inf,             inf,             inf ...             inf,             inf,             inf]]]])]}
For 'Conv2D', 'C_in' of input 'x' shape divide by parameter 'group' must be equal to 'C_in' of input 'weight' shape: 512, but got 'C_in' of input 'x' shape: 1024, and 'group': 1.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore\core\ops\conv2d.cc:214 Conv2dInferShape


generate models:187

analyse the exceptions in iter:487
torch exception:
{'id': 7, 'name': 'dense', 'frame_work': 'torch', 'input_datas': [tensor([[[[542.0438, 542.0438, 499.0438,  ..., 620.0438, 617.0438, 607.0438],
          [497.0438, 451.0438, 569.0438,  ..., 170.0438, 160.0438, 171.0438],
          [516.0438, 489.0438, 486.0438,  ..., 534.0438, 501.0438, 643.0438],
          ...,
          [454.0438, 516.0438, 525.0438,  ..., 534.0438, 513.0438, 503.0438],
          [448.0438, 439.0438, 406.0438,  ..., 376.0438, 294.0438, 496.0438],
          [390.0438, 508.0438, 540.0438,  ..., 537.0438, 540.0438, 550.0438]],

         [[445.0438, 433.0438, 424.0438,  ..., 385.0438, 332.0438, 427.0438],
          [329.0438, 496.0438, 553.0438,  ..., 513.0438, 516.0438, 560.0438],
          [441.0438, 394.0438, 415.0438,  ..., 281.0438, 472.0438, 411.0438],
          ...,
          [139.0438, 181.0438, 235.0438,  ..., 401.0438, 334.0438, 332.0438],
          [353.0438, 445.0438, 431.0438,  ..., 325.0438, 233.0438, 254.0438],
          [217.0438, 281.0438, 179.0438,  ..., 408.0438, 407.0438, 453.0438]],

         [[322.0438, 368.0438, 351.0438,  ..., 321.0438, 227.0438, 273.0438],
          [457.0438, 287.0438, 274.0438,  ..., 543.0438, 564.0438, 595.0438],
          [332.0438, 356.0438, 363.0438,  ..., 630.0438, 422.0438, 315.0438],
          ...,
          [208.0438, 239.0438, 174.0438,  ..., 374.0438, 353.0438, 392.0438],
          [219.0438, 208.0438, 212.0438,  ..., 126.0438, 116.0438, 153.0438],
          [158.0438, 180.0438, 246.0438,  ..., 406.0438, 419.0438, 437.0438]],

         ...,

         [[445.0000, 433.0000, 424.0000,  ..., 385.0000, 332.0000, 427.0000],
          [329.0000, 496.0000, 553.0000,  ..., 513.0000, 516.0000, 560.0000],
          [441.0000, 394.0000, 415.0000,  ..., 281.0000, 472.0000, 411.0000],
          ...,
          [139.0000, 181.0000, 235.0000,  ..., 401.0000, 334.0000, 332.0000],
          [353.0000, 445.0000, 431.0000,  ..., 325.0000, 233.0000, 254.0000],
          [217.0000, 281.0000, 179.0000,  ..., 408.0000, 407.0000, 453.0000]],

         [[322.0000, 368.0000, 351.0000,  ..., 321.0000, 227.0000, 273.0000],
          [457.0000, 287.0000, 274.0000,  ..., 543.0000, 564.0000, 595.0000],
          [332.0000, 356.0000, 363.0000,  ..., 630.0000, 422.0000, 315.0000],
          ...,
          [208.0000, 239.0000, 174.0000,  ..., 374.0000, 353.0000, 392.0000],
          [219.0000, 208.0000, 212.0000,  ..., 126.0000, 116.0000, 153.0000],
          [158.0000, 180.0000, 246.0000,  ..., 406.0000, 419.0000, 437.0000]],

         [[207.0000, 225.0000, 231.0000,  ..., 258.0000, 257.0000, 215.0000],
          [357.0000, 138.0000, 194.0000,  ..., 395.0000, 395.0000, 416.0000],
          [179.0000, 202.0000, 199.0000,  ..., 347.0000, 274.0000, 254.0000],
          ...,
          [ 20.0000,  22.0000,  23.0000,  ..., 352.0000, 400.0000, 444.0000],
          [ 83.0000,  70.0000,  85.0000,  ...,  74.0000,  35.0000,  41.0000],
          [ 30.0000,  30.0000,  27.0000,  ..., 301.0000, 357.0000, 391.0000]]]],
       grad_fn=<ReluBackward0>)]}
'weight'

generate models:192

final statics:
total operators:28
tensorflow --> nums:10,distinct_bugs:5
mindspore --> nums:26,distinct_bugs:5
torch --> nums:27,distinct_bugs:6
tensorflow --> 
log:2
sin:3
conv2d:3
cos:1
softmax:1
mindspore --> 
conv2d:17
log:4
sin:3
cos:1
softmax:1
torch --> 
conv2d:17
log:2
sin:3
dense:3
cos:1
softmax:1

generate models:197
